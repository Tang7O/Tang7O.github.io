{"meta":{"title":"Tang7O'S BLOG","subtitle":"","description":"Tang7O 的个人博客,主要记录学习的点滴，主要包括Java、后端、ACM等;求知若饥,虚心若愚，一入 IT 深似海,从此学习无绝期,记录毕生所学!","author":"Tang7O","url":"https://tang7o.cn","root":"/"},"pages":[{"title":"","date":"2022-04-13T13:31:50.432Z","updated":"2022-04-13T13:31:50.432Z","comments":true,"path":"about/index.html","permalink":"https://tang7o.cn/about/index.html","excerpt":"","text":""},{"title":"我的朋友们","date":"2022-04-13T13:31:50.464Z","updated":"2022-04-13T13:31:50.464Z","comments":true,"path":"friends/index.html","permalink":"https://tang7o.cn/friends/index.html","excerpt":"","text":"如何添加友链 请先添加本站链接 名称：`Tang7O` 链接：`https://tang7o.cn` 头像：`https://alioss.tang7o.cn/blog/logo_ce.png` 描述：`今日事，今日毕。` 标签：`Java，ACM` 博客截图（若有）：`https://7.dusays.com/2020/12/18/6fa5d656c8123.png` 下方评论区按此格式申请友链 1 2 3 4 5 6 COPY- title: # 名称 avatar: # 头像 url: # 链接 screenshot: # 截图 keywords: # 关键词 description: # 描述（可选） 为了提高图片加载速度，建议优化图片尺寸： 1. 将自己的头像图片尺寸调整到 `96px`。 2. 将压缩后的图片上传到图床并使用此图片链接作为头像。 3. 重复上述步骤，压缩网站截图并把尺寸调整到 `540x360` 以下。 等待本站添加贵站 友链原则 合法的、非营利性、无商业广告站点。 有实质性原创内容的个人博客或组织。 必须是 HTTPS 独立域名。 没有特殊要求，只要是 符合大众道德观念、符合普适价值观 的网站我们都欢迎！ &lt;/div&gt; 互添成功 已经添加的友链不会轻易删除。如果您已经移除本站，本站也将移除友链 感谢支持，鞠躬🙇"},{"title":"所有分类","date":"2022-04-13T13:31:50.447Z","updated":"2022-04-13T13:31:50.447Z","comments":true,"path":"categories/index.html","permalink":"https://tang7o.cn/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2022-04-13T13:31:50.479Z","updated":"2022-04-13T13:31:50.479Z","comments":true,"path":"tags/index.html","permalink":"https://tang7o.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MySQL order by limit同时使用的问题","slug":"MySQL-orderby-limit同时使用","date":"2022-04-23T02:30:49.000Z","updated":"2022-04-23T02:49:51.344Z","comments":true,"path":"2022/04/23/MySQL-orderby-limit同时使用/","link":"","permalink":"https://tang7o.cn/2022/04/23/MySQL-orderby-limit%E5%90%8C%E6%97%B6%E4%BD%BF%E7%94%A8/","excerpt":"","text":"MySQL文档原文 有一定英语阅读能力的读者，可以直接去读文档。 问题如果order by排序属性的值不唯一，order by与limit同时使用可能会出现查询结果不同的现象。例如： 1234567891011121314151617181920212223mysql&gt; SELECT * FROM ratings ORDER BY category;+----+----------+--------+| id | category | rating |+----+----------+--------+| 1 | 1 | 4.5 || 5 | 1 | 3.2 || 3 | 2 | 3.7 || 4 | 2 | 3.5 || 6 | 2 | 3.5 || 2 | 3 | 5.0 || 7 | 3 | 2.7 |+----+----------+--------+mysql&gt; SELECT * FROM ratings ORDER BY category LIMIT 5;+----+----------+--------+| id | category | rating |+----+----------+--------+| 1 | 1 | 4.5 || 5 | 1 | 3.2 || 4 | 2 | 3.5 || 3 | 2 | 3.7 || 6 | 2 | 3.5 |+----+----------+--------+ 原因文档原文如下： If you combine LIMIT *row_count* with ORDER BY, MySQL stops sorting as soon as it has found the first row_count rows of the sorted result, rather than sorting the entire result. If ordering is done by using an index, this is very fast. If a filesort must be done, all rows that match the query without the LIMIT clause are selected, and most or all of them are sorted, before the first row_count are found. After the initial rows have been found, MySQL does not sort any remainder of the result set. One manifestation of this behavior is that an ORDER BY query with and without LIMIT may return rows in different order, as described later in this section. 如果你将LIMIT row_count子句与ORDER BY子句组合在一起使用的话，MySQL会在找到排序结果的第一个row_count行后立即停止排序，而不是对整个结果进行排序。如果使用索引来完成排序，这将非常快。如果必须执行文件排序，则在找到第一个row_count行之前，选择所有与查询匹配但不包括LIMIT子句的行，并对其中大部分或所有行进行排序。一旦找到第一个row_count之后，MySQL不会对结果集的任何剩余部分进行排序。 这种行为的一种表现形式是，一个ORDER BY查询带或者不带LIMIT可能返回行的顺序是不一样的。 解决方法在order by子句中包含其他列以使顺序具有确定性。 例如，假如id的值是唯一的，你可以通过下面的方式解决此问题： 1234567891011121314151617181920212223mysql&gt; SELECT * FROM ratings ORDER BY category, id;+----+----------+--------+| id | category | rating |+----+----------+--------+| 1 | 1 | 4.5 || 5 | 1 | 3.2 || 3 | 2 | 3.7 || 4 | 2 | 3.5 || 6 | 2 | 3.5 || 2 | 3 | 5.0 || 7 | 3 | 2.7 |+----+----------+--------+mysql&gt; SELECT * FROM ratings ORDER BY category, id LIMIT 5;+----+----------+--------+| id | category | rating |+----+----------+--------+| 1 | 1 | 4.5 || 5 | 1 | 3.2 || 3 | 2 | 3.7 || 4 | 2 | 3.5 || 6 | 2 | 3.5 |+----+----------+--------+","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/tags/MySQL/"}]},{"title":"HTTPS解析","slug":"HTTPS解析","date":"2022-04-22T08:49:56.000Z","updated":"2022-04-22T13:51:12.145Z","comments":true,"path":"2022/04/22/HTTPS解析/","link":"","permalink":"https://tang7o.cn/2022/04/22/HTTPS%E8%A7%A3%E6%9E%90/","excerpt":"","text":"HTTPS是什么为什么需要HTTPS由于HTTP存在一些缺陷： 通信使用明文，内容可能被窃听 不验证通信方的身份，可能遭到伪装 无法验证报文的完整性，报文可能被篡改 为了解决这些问题HTTPS诞生了。 HTTPS的实质HTTP协议加上加密、认证机制和完整性验证就是HTTPS。 HTTPS并非一种新的协议。只是HTTP通信接口部分用SSL或TLS协议代替而已。所谓的HTTPS其实就是HTTP+SSL/TLS。 TLS以SSL为原型开发的协议，有时会统称该协议为SSL。 HTTPS的加密原理HTTPS加密过程中使用了非对称加密和对称加密结合的方式。 HTTPS加密过程 为什么不只用对称加密？ 采用单钥密码系统的加密方式，同一个密钥可以同时做信息的加密和解密，这种加密的方法称为对称加密，也称为单密钥加密。 缺点：以对称加密算法加密，必须将密钥发送给对方。这时候，假如通信被监听，密钥被攻击人获取，这个时候加密就是去了意义。 如何解决这个问题？使用两把密钥（非对称加密）。 为什么不只用非对称加密？ 与对称加密算法相反，非对称加密算法需要两个密钥来进行加密和解密，这两个密钥是配对的，分别是公开密钥（公钥）和私有密钥（私钥）。 一般情况下，公钥是公开的，私钥是服务器私有的。公钥加密后的密文只能通过对应的私钥来解密，而私钥加密的密文却可以通过对应的公钥来解密。 缺点：加密比对称加密复杂，效率低。 如何保证公钥的正确性与服务器进行通信时，如何才能保证你收到的公钥服务器发行的公钥，而不是被攻击者替换掉的呢？ 为了解决这个问题，可以使用数字证书认证机构（CA）颁发证书。 CA业务流程： CA会向申请者颁发一个证书，证书的内容有：签发者、证书用途、域名、证书到期时间、使用的HASH算法、签名使用的算法等。 将证书的内容做一次HASH，得到HASH值。 用CA的私钥对这个HASH值和使用的HASH算法加密，这样就完成了数字签名。 将数字签名附加在证书的末尾。 客户端检验证书流程： 用CA私钥对应的公钥，解密数字证书末尾的签名，得到HASH值和HASH算法。 用得到的HASH算法，对证书内容进行HASH运算。如果得到的HASH值与解密得到的HASH值相同，那么检验通过，否则失败。 上面提到的C公钥怎么来的呢？ CA除了给申请者颁发证书，它本身也有自己的证书。CA自身的证书（一般由它自己颁发）在我们系统安装好的时候，就被微软（或其他操作系统的开发机构）安装再操作系统中了。而CA的公钥包含在其中。这样CA就可以通过自身的是要对发布的数字证书进行签名，而客户端就能用相应的公钥来解密。 HTTPS通信的过程 客户端发送Client Hello报文开始SLL通信。报文中包括客户端支持的SSL版本、加密组件（Cipher Suite）列表以及一个随机数A。 服务器可以进行SSL通信时，发送Server Hello报文作为应答。和客户端一样，在报文中包括SSL版本、加密组件列表（从客户端接收到的加密组件筛选出来的）以及一个随机数B。 之后服务器发送Certificate报文。报文中包含公钥证书。 最后服务器发送Server Hello Done报文通知客户端，最初阶段的SSL握手协商部分结束。 SSL第一次握手结束后，客户端会对服务器发过来的证书进行验证，如果验证成功，解密出证书的公钥。接着客户端以Client Key Exchange报文作为回应。报文中包含通信加密使用的一种被称为Pre-master secret的随机密码串，报文使用解密出的公钥进行加密。 客户端继续发送Change Cipher Spec报文。用于告知服务端，客户端已经切换到之前协商好的加密套件（Cipher Suite）的状态，准备使用之前协商好的加密套件加密数据并传输了。 客户端发送Finished报文。该报文包含连接至今全部报文的整体校验值（也就是HASH值），用来供服务器校验。 服务器接收到客户端的请求之后，使用私钥解密报文，把Pre-master secret取出来。接着，服务器同样发送Change Cipher Spec报文。 服务器同样发送Finished报文，用来供客户端校验。 服务器和客户端的Finished报文交换完毕之后，SSL连接就算建立完成。当然，通信会受到SSL的保护。从此处开始进行应用层协议的通信，即发送HTTP请求。 应用层协议通信，即返回HTTP响应。 最后由客户端断开连接。断开连接时，发送close_notify报文。上图做了一些省略，这步之后再发送TCP FIN报文来关闭与TCP的通信。 Finish报文的作用？上面已经提及，Finish报文是对至今全部报文的整体校验值（也就是HASH值）。当客户端把这个值通过得到的公钥进行加密的时候，服务器得到之后对其进行解密，然后再对全部报文进行一个HASH求值。如果这个值跟解密得到的值相等的话，那么说明客户端是可信赖的。同样的，服务器发送这样的一个整体校验值，用来客户端验证服务器是否是真正要进行通信的那一个。综上，这个Finish报文就是用来校验双方的身份的。 三个随机数的作用？对于客户端：当其生成了Pre-master secret之后，会结合原来的A、B随机数，用DH算法计算出一个master secret，紧接着根据这个master secret推导出hash secret和session secret。 对于服务端：当其解密获得了Pre-master secret之后，会结合原来的A、B随机数，用DH算法计算出一个master secret，紧接着根据这个master secret推导出hash secret和session secret。 在客户端和服务端的master secret是依据三个随机数推导出来的，它是不会在网络上传输的，只有双方知道，不会有第三者知道。同时，客户端推导出来的session secret和hash secret与服务端也是完全一样的。 那么现在双方如果开始使用对称算法加密来进行通讯，使用哪个作为共享的密钥呢？过程是这样子的： 双方使用对称加密算法进行加密，用hash secret对HTTP报文做一次运算生成一个MAC，附在HTTP报文的后面，然后用session-secret加密所有数据（HTTP+MAC），然后发送。 接收方则先用session-secret解密数据，然后得到HTTP+MAC，再用相同的算法计算出自己的MAC，如果两个MAC相等，证明数据没有被篡改。 MAC(Message Authentication Code)称为报文摘要，能够查知报文是否遭到篡改，从而保护报文的完整性。 为什么使用三个随机数？客户端和服务器都需要生成随机数，以此来保证每次生成的秘钥都不相同。 使用三个随机数，是因为 SSL 的协议默认不信任每个主机都能产生完全随机的数，如果只使用一个伪随机的数来生成秘钥，就很容易被破解。 通过使用三个随机数的方式，增加了自由度，一个伪随机可能被破解，但是三个伪随机就很接近于随机了，因此可以使用这种方法来保持生成秘钥的随机性和安全性。 黑客拦截服务器证书并篡改，会出现什么情况？ 如果黑客只是单纯的篡改，由于有数字签名，客户端会很容易判断出报文被篡改过。 黑客不仅修改了证书内柔，还替换了数字签名，由于黑客不知道CA的私钥，于是客户端用CA公钥解密时，得不到正确的信息，也很容易判断出报文是否被修改。 黑客从相同的CA申请了一个数字证书。由于这个数字证书是真实存在的，所以客户端可以成功的用CA公钥进行解密。但是，由于数字证书绑定了域名，因此客户端很容易发现证书域名与访问域名的不一致，便会发出警告。警告如下图： 一定要用HTTPS吗当然不是，虽然HTTPS比HTTP要安全许多，但是由于加入了诸多的验证机制，导致它处理速度变慢。原因如下： 客户端和服务器协商的次数变多，整体处理通信量会不可避免的增加。 客户端和服务器需要进行额外的加密和解密的运算处理。会消耗更多的资源。 同时，使用HTTPS需要购买CA证书，需要额外的开销。 因此，大部分的Web网址都采用了一个折中的方法。对一些需要隐藏、私密的信息进行加密，而普通的信息不进行机密处理，以节省资源。","categories":[{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"},{"name":"HTTPS","slug":"网络/HTTPS","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/HTTPS/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/tags/%E7%BD%91%E7%BB%9C/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://tang7o.cn/tags/HTTPS/"}]},{"title":"浏览器输入url后发生了什么","slug":"浏览器输入url发生的事","date":"2022-04-22T06:29:58.000Z","updated":"2022-04-22T07:59:17.341Z","comments":true,"path":"2022/04/22/浏览器输入url发生的事/","link":"","permalink":"https://tang7o.cn/2022/04/22/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5url%E5%8F%91%E7%94%9F%E7%9A%84%E4%BA%8B/","excerpt":"","text":"大致流程 合成URL DNS域名解析 建立TCP连接 发送HTTP请求，处理请求，返回响应结果 关闭TCP连接 浏览器渲染 合成URL浏览器根据用户输入信息判断是搜索还是网址，如果是搜索内容，就将搜索内容+默认搜索引擎合成新的URL；如果用户输入内容符合URL规则，浏览器就会根据URL协议生成合法的URL。 DNS域名解析DNS的域名解析，在客户端和浏览器、本地DNS之间的查询是递归查询；在本地DNS服务器和根DNS服务器及其子服务器之间是迭代查询。 递归： 在客户端输入URL后，从历览器缓存查找-&gt;本地hosts文件查找-&gt;本地DNS解析器缓存查找-&gt;本地DNS服务器查找，这个步骤中任意一步查到了都会直接返回结果。 如果本地DNS服务器也查不到，则根据本地DNS服务器设置的转发器进行查询。若未用转发模式，则迭代查找过程如下图： 建立TCP连接首先判断是不是HTTPS（HTTP+SSL/TLS）协议，若是，服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密的数据。 三次握手，建立TCP连接 HTTPS加密过程 发送HTTP请求，服务器处理请求，返回响应结果TCP建立连接后，浏览器就可以利用HTTP/HTTPS协议向服务器发送请求。服务器接受到请求，处理请求返回响应。 关闭TCP连接四次挥手，关闭TCP连接 浏览器渲染浏览器根据服务器返回的响应，渲染并显示界面。","categories":[{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"进程切换为什么比线程切换开销大","slug":"进程切换","date":"2022-03-22T02:21:47.000Z","updated":"2022-04-13T13:31:49.208Z","comments":true,"path":"2022/03/22/进程切换/","link":"","permalink":"https://tang7o.cn/2022/03/22/%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2/","excerpt":"","text":"进程切换比线程切换开销大是因为进程切换时要切页表，而且往往伴随着页调度，因为进程的数据段代码段要换出去，以便把将要执行的进程的内容换进来。本来进程的内容就是线程的超集。而且线程只需要保存线程的上下文（相关寄存器状态和栈的信息）就好了，动作很小。 但是如果是不同进程内的线程互换就不好说了。","categories":[{"name":"OS","slug":"OS","permalink":"https://tang7o.cn/categories/OS/"}],"tags":[{"name":"OS","slug":"OS","permalink":"https://tang7o.cn/tags/OS/"}]},{"title":"MySQL Limit优化","slug":"MySQL-LIMIT","date":"2022-03-16T12:44:13.000Z","updated":"2022-04-13T13:31:48.203Z","comments":true,"path":"2022/03/16/MySQL-LIMIT/","link":"","permalink":"https://tang7o.cn/2022/03/16/MySQL-LIMIT/","excerpt":"","text":"耗时本质mysql大数据量使用limit分页，随着页码的增大，查询效率越低下。 当一个表有几百万的数据的时候成了问题！ 如 select * from table limit 0,10 这个没有问题，当 limit 100000,10 的时候就很慢。 原因本质： limit 语句的查询时间和其实记录（offset）的大小成正比。 mysql 的 limit 语句是很方便，但是对于记录很多：百万，千万级别的表并不适合直接使用。 例如： limit 10000,20 的意思扫描满足条件的 10020 行，扔掉 前面的 10000 行，返回最后的 20 行，问题就在这里。limit 2000000，30 扫描了 2000030 行，慢的都堵死了，甚至会导致磁盘 IO 100%消耗，但是 limit 30 这样的语句才扫描 30 行。 优化手段去掉或者利用 limit offset,size 中的 offset。 不是直接使用limit，而是首先获取到 offset 的 id 然后再使用 limit size 来获取数据。 对 limit 分页问题的性能优化方法如果数据是连续不中断的可以使用 between and 来代替 limit 查询。 利用表的覆盖索引来加速分页查询覆盖索引： 就是 select 的数据列只从索引中就能获得，不必读取数据行。也就是说：查询列要被所创建的索引覆盖。 因为利用索引查找有优化算法，且数据就在查询索引上面，不用再去找相关的数据地址了，这样节省了很多时间。另外 mysql 中也有相关的索引缓存，在并发高的时候利用缓存就效果更好了。在我们的例子中，我们知道 id 字段是主键，自然就包含了默认的主键索引。 这次我们之间查询最后一页的数据（利用覆盖索引，只包含id列），如下： 123#覆盖索引只包含id列 的时间显著优于 select * 不言而喻select * from order_table where company_id = 1 and mark =0 order by id desc limit 200000 ,20;select id from order_table where company_id = 1 and mark =0 order by id desc limit 200000 ,20; 如果我们要查询所有列，有两种方法，一种是 id&gt;= 的形式，另一种就是利用 join： 123#两者用的都是一个原理嘛，所以效果也差不多SELECT * FROM xxx WHERE ID &gt; =(select id from xxx limit 1000000, 1) order by id limit 20;SELECT * FROM xxx a JOIN (select id from xxx limit 1000000, 20) b ON a.ID = b.id; 上述子查询的方式虽然比直接使用 Limit 要快很多，但是当数据量过大（千万级别）时，子查询需要很长时间，依旧不够快。 去掉子查询123456#仅仅使用 id&lt;max and limit size;#每次查询前获取上一页最小id作为下一页的最大id使用 假设为：800000001#首页查询select * from order_table where company_id = 1 and mark =0 order by id desc limit 200000;#非首页查询 select * from order_table where company_id = 1 and mark =0 and id &lt; 800000001 order by id desc limit 200000;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/tags/MySQL/"}]},{"title":"HTTP 1.0 VS HTTP 1.1","slug":"HTTP1-0-1-1","date":"2022-03-08T07:43:49.000Z","updated":"2022-04-13T13:31:48.011Z","comments":true,"path":"2022/03/08/HTTP1-0-1-1/","link":"","permalink":"https://tang7o.cn/2022/03/08/HTTP1-0-1-1/","excerpt":"","text":"本文将从以下几个维度来对比 HTTP1.0 和 HTTP1.1: 响应状态码 缓存处理 连接方式 Host 头处理 带宽优化 响应状态码HTTP/1.0 仅定义了 16 种状态码。HTTP/1.1 中新加入了大量的状态码，光是错误响应码就新增了 24 种。比如说： 100（Continue）：在请求大资源前的预热请求。 206（Partial Content）：范围请求的标识码。 409（Conflict）：请求与当前资源的规定冲突。 410（Gone）：资源已被永久转移，而且没有任何已知的转发地址。 缓存处理缓存技术通过避免用户与源服务器的频繁交互，节约了大量的网络带宽，降低了用户接收信息的延迟。 HTTP/1.0HTTP/1.0 提供的缓存机制非常简单。服务器端使用 Expires 标签来标志（时间）一个响应体，在 Expires 标志时间内的请求，都会获得该响应体缓存。服务器端在初次返回给客户端的响应体中，有一个 Last-Modified 标签，该标签标记了被请求资源在服务器的最后一次修改。在请求头中，使用 If-Modifiend-Since 标签，该标签标志一个时间，意为客户端向服务器进行问询：”该时间之前，我要请求的资源是否有被修改过？“通常情况下，请求头中的 If-Modifiend-Sine 的值即为上一次获得该资源时，响应体中的 Last-Modified 的值。 如果服务器即收到了请求头，并判断 If-Modifiend-Sine 时间后，资源确实没有被修改过，则返回给客户端一个 304 not modified 响应头，表示”缓存可用，你从浏览器里拿吧！“。 如果判断 If-Modifiend-Sine 时间后，资源被修改过，则返回给客户端一个 200 OK 的响应体，并附带全新的资源内容，表示”资源被修改过了，我给你一份新的“。 HTTP/1.1HTTP/1.1 的缓存机制在 HTTP/1.0 的基础上，大大增加了灵活性和扩展性。基本工作原理和 HTTP/1.0 保存不变，而是增加了更多细致的特性。其中，请求头中最常见的特性就是 Cache-Control，详见 MDN Web 文档 Cache-Control 连接方式HTTP/1.0 默认使用短链接，也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或者其他的类型的 Web 页中包含有其他 Web 资源（如 JavaScript 文件、图像文件、CSS 文件）等，每遇到这样的一个 Web 资源，浏览器就会重新建立一个 TCP 连接，这样就会导致有大量的“握手报文”和“挥手报文”占用了带宽。 为了解决 HTTP/1.0 存在的资源浪费问题，HTTP/1.1 优化为默认长连接模式。采用长连接模式的请求报文会通知服务端：“我会向你请求连接，并且连接成功建立后，请不要关闭”。因此，该 TCP 连接将持续打开，为后续的客户端服务端的数据交互服务。也就是说在使用长连接的情况下，当一个网页打开完成后，客户端和服务端之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。 如果 TCP 连接一直保持的话也是对资源的浪费，因此，一些服务器软件还会支持超时时间的时间。在超时时间之内没有新的请求达到，TCP 连接才会被关闭。 有必要说明的是，HTTP/1.0 仍提供了长连接选项，在请求头中加入 Connection: Keep-alive。同样的，在HTTP/1.1中，如果不希望使用长连接选项，也可以在请求头中加入 Connection: close，这样会通知服务器端：“我不需要长连接，连接成功后即可关闭”。 HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。 实现长连接需要客户端和服务端都支持长连接。 Host 头处理域名系统（DNS）允许多个主机名绑定到同一个 IP 地址上，但是 HTTP/1.0 并没有考虑这个问题，假设我们有一个资源 URL 是 http://tang7o.cn/index.html, HTTP/1.0 的请求报文中，将会请求的是 GET /index.html HTTP/1.0 也就是不会加入主机名。这样的报文发送到服务器端，服务端理解不了客户端想请求的真正网址。 因此，HTTP/1.1 在请求头中加入了 Host 字段。加入 Host 字段的报文头部将会是： 12GET /index.html HTTP/1.1Host: tang7o.cn 这样，服务器就可以确定客户端想要请求的真正网址了。 带宽优化范围请求HTTP/1.1 引入了范围请求（range request）机制，以避免带宽的浪费。当客户端想请求一个文件的一部分，或者需要继续下载一个已经下载了部分但被终止的文件，HTTP/1.1 可以在请求中加入 Range 头部，以请求（并只能请求字节型数据）数据的一部分。服务器可以忽略 Range 头部，也可以返回若干 Range 响应。 如果一个响应包括部分数据的话，那么将带有 206（Partial Content）状态码。该状态码的意义在于避免了 HTTP/1.0 代理缓存错误的把该响应认为是一个完整的数据响应，从而把他当作一个请求的响应缓存。 在范围响应中，Content-Range 头部标志指示出了该数据块的偏移量和数据块长度。 状态码100HTTP/1.0 中新加入了状态码 100。该状态码的使用场景为，存在某些较大的文件请求，服务器可能不愿意响应这种请求，此时状态码 100 可以作为指示请求是否被正常响应。 然而在 HTTP/1.0 中没有 100（Continue） 状态码，要想触发这一机制，可以发送一个 Expect 头部，其中包含一个 100-continue 的值。 压缩许多格式的数据在传输时都会做压缩处理。数据的压缩可以大幅优化带宽的利用。然而，HTTP/1.0 对数据压缩的选项提供的不多，不支持压缩细节的选择，也无法区分端到端压缩或者是逐跳压缩。 HTTP/1.1 则对内容编码和传输编码做了区分，内容编码总是端到端的，传输编码总是逐跳的。 HTTP/1.0 包含了 Content-Encoding 头部，对消息进行端到端编码。HTTP/1.1 加入了 Transfer-Encoding 头部可以对消息进行逐跳传输编码。HTTP/1.1 还加入了 Accept-Encoding 头部，是客户端来指示它能处理什么样的内容编码。 总结 连接方式：HTTP/1.0 默认短链接，HTTP/1.1 默认长连接。 状态响应码：HTTP/1.1 中新家了大量的状态码，光是错误响应状态码就新增了 24 种。 缓存处理：在 HTTP/1.0 中主要使用 header 里面的 If-Modified-Since, Expires 来作为缓存判断的标准，HTTP/1.1 则引入了更多的缓存控制策略，例如 Entity tag, If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。 带宽优化及网络连接的使用： HTTP/1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP/1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 Host 头处理：HTTP/1.1 在请求头中加入了 Host 字段。","categories":[{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"},{"name":"HTTP","slug":"网络/HTTP","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/HTTP/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/tags/%E7%BD%91%E7%BB%9C/"},{"name":"HTTP","slug":"HTTP","permalink":"https://tang7o.cn/tags/HTTP/"}]},{"title":"Redis的缓存问题","slug":"Redis缓存问题","date":"2022-03-07T03:09:14.000Z","updated":"2022-04-13T13:31:48.339Z","comments":true,"path":"2022/03/07/Redis缓存问题/","link":"","permalink":"https://tang7o.cn/2022/03/07/Redis%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98/","excerpt":"","text":"缓存雪崩缓存雪崩是指在某一个时刻出现大规模的缓存失效的情况，大量的请求直接打在数据库上面，可能会导致数据库宕机，如果这时候重启数据库并不能解决根本问题，会再次造成缓存雪崩。 为什么会造成缓存雪崩？一般来说，造成缓存雪崩主要有两种可能 Redis 宕机了 很多 key 采取了相同的过期时间 如何解决缓存雪崩？ 为避免 Redis 宕机造成缓存雪崩，可以搭建 Redis 集群。 尽量不要设置相同的过期时间，可以在原有的过期时间加上随机数。 服务降级，当流量达到一定的阈值时，就直接返回“系统繁忙”之类的提示，防止过多的请求直接打在数据库上，这样虽然难用，但是至少可以避免服务器宕机。 缓存击穿缓存雪崩是大规模的 key 失效，而缓存击穿是一个热点的 key，有大量并发集中对其访问，突然间这个 key 失效了，导致大量并发请求全部打在数据库上， 导致数据库压力剧增，这种现象就叫做缓存击穿。 比较经典的例子就是商品秒杀时，大量的用户在抢某个商品时，商品的 key 突然过期失效了，所有请求都到数据库上了。 如何解决缓存击穿？ 热点 key 不设置过期时间，避免 key 过期失效。 加锁，如果缓存失效的情况，只有拿到锁才能查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库宕机，不过这样会导致系统的性能变差。 缓存穿透缓存穿透是指用户的请求没有经过缓存而直接请求到数据库上了，比如用户请求的 key 在 Redis 中不存在，或者用户恶意伪造大量不存在的 key 进行请求，都可以绕过缓存，导致数据库压力太大宕机。 如何解决缓存穿透？ 参数校验，例如可以对用户 id 进行校验，直接拦截不合法的请求。 缓存空值，如果某个 key 在 Redis 中不存在，在数据库中也不存在，则把这个 key 值保存到 Redis，设置 value = “null”。 布隆过滤器，布隆过滤器可以判断这个 key 在不在数据库中，特点是：如果判断这个 key 不在数据库，那么这个 key 一定不在数据库中，如果判断这个 key 在数据库中，也不能保证这个 key 一定在数据库中。就是会有少数漏网之鱼，造成这种现象的原因是因为布隆过滤器使用了 hash 算法，对 key 进行 hash 时，不同的 key 的 hash 值一定不同，但是相同的 hash 值不能说明这两个 key 相同。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/tags/Redis/"}]},{"title":"Redis并发竞争 key 问题","slug":"Redis并发","date":"2022-03-07T02:16:51.000Z","updated":"2022-04-13T13:31:48.325Z","comments":true,"path":"2022/03/07/Redis并发/","link":"","permalink":"https://tang7o.cn/2022/03/07/Redis%E5%B9%B6%E5%8F%91/","excerpt":"","text":"Redis 并发竞争 key 就是多个客户端操作一个 key，可能会导致数据出现问题，主要有以下几种解决方法： 乐观锁，watch 命令可以方便的实现乐观锁。watch 命令会监视给的的每一个 key，当 exec 时如果监视的任一个 key 自从调用 watch 后发生过变化，则整个事务会回滚，不执行任何动作。不能在分片集群中使用。 分布式锁，适合分布式场景 时间戳，适合有序场景，比如 A 想把 key 设置为 1，B 想把 key 设置为 2，C 想把 key 设置为 3，对每个操作加上时间戳，写入前先比较自己的时间戳是不是早于现有记录的时间戳，如果早于，就不写入了。 消息队列，串行化处理。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/tags/Redis/"}]},{"title":"Redis分布式锁","slug":"Redis分布式","date":"2022-03-04T01:56:34.000Z","updated":"2022-04-13T13:31:48.296Z","comments":true,"path":"2022/03/04/Redis分布式/","link":"","permalink":"https://tang7o.cn/2022/03/04/Redis%E5%88%86%E5%B8%83%E5%BC%8F/","excerpt":"","text":"什么是分布式锁？分布式锁就是为了保证在分布式场景下，共享资源在同一时刻只能被一个线程访问，或者说是用来控制分布式系统之间同步访问共享资源。 分布式锁有什么特性？ 互斥性：在任意时刻，同一条数据只能被一台机器的一个线程访问。 高可用性：当部分节点宕机后，客户端仍可以正常的获取锁和释放锁。 独占性：加锁和释放锁必须在同一台服务器执行，不能在一个服务器上获取锁，在另一个服务器释放锁。 防锁超时：如果客户端没有主动释放锁，服务器会在一定时间后自动释放锁，防止客户端宕机或者网络异常导致宕机。 分布式锁的实现方法？基本思路就是要在整个系统中提供一个全局、唯一的“锁”，每个系统需要加锁时，都去尝试获取这个“锁”。 Redis 如何实现分布式锁前面写了分布式锁的特性，其实实现分布式锁就是围绕这些特性展开的。 Redis 实现分布式锁的主要命令：SETNX，该命令的作用是当 key 不存在时设置 key 的值，当 key 存在时，什么都不做。 先来看最简单的实现方式，如下图： 从上图可以看到主要两个关系步骤，加锁和解锁。 但是这个简陋的分布式锁存在很多问题，并不难满足上述介绍的分布式锁的特性，比如，当线程1执行到上图中执行业务这步时，业务代码突然出现了异常，无法进行删除锁这一步，那就G了，死锁了，其它线程也无法获取到锁了（SETNX 特性）。 改进方案 1一提到异常，有人就想到了 try-catch-finally 了，把删除锁的操作放到 finally 代码块中，就算出现异常，也是能够正常释放锁的，执行业务出现异常这个问题解决了。但是这并不靠谱，如果 Redis 在执行业务这步宕机了呢，finally 代码块也不会执行。 改进方案 2其实这个问题也好解决，只需要给锁设置一个过期时间就可以，对 key 设置过期时间在 Redis 中是常规操作了。SET key value [EX seconds][PX milliseconds] [NX|XX] EX second: 设置键的过期时间为second秒； PX millisecond：设置键的过期时间为millisecond毫秒； NX：只在键不存在时，才对键进行设置操作； XX：只在键已经存在时，才对键进行设置操作； SET操作完成时，返回OK，否则返回nil。 那现在这个方案就没问题了吗？显然没有 例如，线程 1 获取了锁，并设置了有效时间 10 秒，但是线程 1 在执行业务时超过了 10 秒，锁到期自动释放了，在释放后，线程 2 又获取了锁，在线程 2 执行业务时，线程 1 执行完业务了，随后执行了删除锁这一步，但是线程 1 的锁自动释放了，它删除的是线程 2 的锁。 改进方案 3其实看起来方案 2 的问题很容易解决，只要把锁的过期时间设置的很长，就可以避免两个问题，但是这样并不可行，因为这样相当于回到最简陋的方案（会导致线程 2 一直获取不到锁（线程 1 因异常未能删除锁的情况下））。 如何解决线程 1 释放线程 2 的锁这一问题？ 很简单，可以为锁加一个标识，例如生成一个 UUID，作为锁的标识，每个线程获取锁时都会生成一个不同的 UUID 作为标识，在删除锁时会进行判断，锁的标识和自己生成 UUID 相同时才能进行删除操作。 那么如何确定锁的过期时间呢？ 可以在加锁时，设置一个预估的过期时间，然后开启一个守护线程，定时检测这个锁的失效时间，如果快要过期了，操作还未完成，那么就自动对锁进行“续费”。 那方案 3 就没有问题了吗？并不是，比如方案 3 的分布式锁还不具备可重入性（同一线程可以重复获取锁，解决线程需要多次进入锁内部执行任务的问题） 改进方案 4参考其他重入锁的设计，通过对锁进行重入计数，加锁时加 1，解锁时减 1，计数为 0 时才能释放锁。 那现在的方案还有问题吗？其实还有，比如，线程 1 获取了锁，线程 2 没能获取到锁，那么线程 2 怎么知道线程 1 什么时候释放了锁，进而再去获取锁呢？ 改进方案 5方案 4 中问题，一般有两种解决方案： 可以通过客户端轮询的方式，就是线程 2 过一会就过来看看是不是能获取锁了。这种方案比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。 通过 Redis 的发布订阅功能，当获取锁失败时，订阅锁信息，获取锁成功后释放时，发布释放锁信息。 现在这个方案完美了吗？没有 目前讨论的都是单节点的情况，如果这个节点挂了，那么所有的客户端都获取不到锁了。 改进方案 6为了实现 Redis 的分布式锁，Redis 的作者提出了 RedLock 算法(英文好的可以直接去官网查看)。 首先介绍保证分布式锁的有效性和安全性的要求： 互斥性：在任何给定时刻，只有一个客户端可以持有一个锁。 释放死锁：获取锁的客户端崩溃或者被分区，也可以释放锁。 容错性：只要大多 Redis 节点都在运行，客户端就能获取和释放锁。 为什么基于故障转移实现的 Redis 分布式锁还不够用? 官网中举了一个例子： 客户端A获得主服务器上的锁，然后主服务器向从服务器复制数据的过程中崩了，导致数据没有复制到从数据库中，这时会在从服务器中选出来一个升级为主服务器，但新的主服务器中并没有客户端A设置的锁。所以客户端B也可以获取到锁，违背了上面说的互斥性。 这就解释了为什么使用 RedLock 算法。 RedLock 算法假设有 5 个完全独立的 Redis 服务器，多节点 Redis 实现的 RedLock 算法如下： 获取当前时间戳。 客户端尝试在 5 个实例中按顺序获取锁，在所有实例中使用相同的键名和随机值。当在每个实例中设置锁时，需要将锁的获取时间设置的比锁过期时间短很多。例如，如果锁自动释放时间为 10 秒，则锁的获取时间在 5-50 毫秒。这是为了不要过长时间等待已经关闭的 Redis 实例，如果一个 Redis 实例不可用，我们应该尽快尝试下一个 Redis 实例。 客户端通过从当前时间中减去步骤 1 中获取的时间戳，计算出获取锁所需的时间。当且仅当客户端能够在大多数实例（本例至少 3 个）中获取锁，并且化费在获取锁的总时间小于锁的有效性时间，该锁则被认为已经获得。 如果获得了锁，锁真正的有效时间为锁初始设置的有效时间（过期时间）减去步骤 3 的时间，例如：锁初始的有效时间为 5s，获取锁花了 0.5s，则锁真正的有效时间为 4.5s（忽略了时钟偏移，时钟偏移指两个电脑间时间流速基本相同的情况下，两个电脑（或两个进程）时间的差值） 如果客户端由于某些原因无法获取锁（要么无法锁定 N/2 + 1 个 Redis 实例，要么锁的有效时间为负数），客户端将尝试解锁所有的 Redis 实例（即时是它认为无法锁定的 Redis 实例） RedLock 算法是异步的吗？可以看成同步算法，虽然没有跨进程的同步时钟，但每个进程（多个电脑）的本地时间仍然大致以相同的速度流动，与锁的自动释放时间相比，误差较小，将其忽略的话，则可以看成同步算法。 RedLock 失败重试当客户端无法获取到锁时，应该在随机时间后重试，并且理想的客户端应该并发地将命令同时发给所有 Redis 实例。对于已经获取锁的客户端要在完成任务后及时释放锁，这样其他客户端就不需要等锁自动过期后再获取。如果在获取锁后，在主动释放锁前无法连接到 Redis 实例，那就只能等待锁自动失效了。 释放锁释放锁很简单，只要释放所有 Redis 实例中的锁，不需要考虑是否释放成功（释放时需要判断这个锁的 vlaue 值是否自己设置的，避免释放其他客户端设置的锁） RedLock的 Safety arguments 假设客户端可以获取到大多数 Redis 实例，并且所有 Redis 实例具有相同的 key 和过期时间，但不同的 Redis 实例的 key 是不同的时间设置的（获取锁的时间不可能完全一致），所以过期时间也不同，假设获取第一个 Redis 实例的锁的时间为 T1,最后一个为 T2，则客户端获得锁的最小有效时间为 key 的有效时间 -（T2-T1）-时钟漂移。 为什么需要获取一半以上的 Redis 实例的锁才算获取到锁成功呢？因为如果获取不到一半也算成功的话会导致多个客户端同时获取到锁，违背了互斥性。 一个客户端锁定大多数 Redis 实例所需的时间大于或者接近锁的过期时间时，会认为锁无效，并解锁所有 Redis 实例。 RedLock崩溃的相关解决方法场景：客户端 A 在成功获取锁后，如果所有 Redis 重启，这时客户端 B 就可以再次获取到锁，违背了互斥性。 解决方法：开启 AOF 持久化，可以解决这个问题，但是 AOF 同步到磁盘上的方式默认是每秒一次，如果 1 秒内断电，会导致 1 秒内的数据丢失，如果客户端是在这 1 秒内获得的锁，立即重启可能会导致锁的互斥性失效，解决方法是每次 Redis 无论因为什么原因停掉都要等 key 的过期时间到了再重启（延迟重启），这么做的缺点就是在等待重启这段时间内 Redis 处于关闭的状态。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/tags/Redis/"},{"name":"分布式","slug":"分布式","permalink":"https://tang7o.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"服务器关闭,客户端继续写会发生什么？","slug":"服务器关闭-客户端继续写会发生什么？","date":"2022-03-01T02:44:44.000Z","updated":"2022-04-13T13:31:49.038Z","comments":true,"path":"2022/03/01/服务器关闭-客户端继续写会发生什么？/","link":"","permalink":"https://tang7o.cn/2022/03/01/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%85%B3%E9%97%AD-%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%BB%A7%E7%BB%AD%E5%86%99%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"","text":"当服务器进程被终止时，会关闭其打开的所有文件描述符，此时就会向客户端发送一个 FIN 的报文,客户端则响应一个 ACK 报文,但是这样只完成了“四次挥手”的前两次挥手，也就是说这样只实现了半关闭，客户端仍然可以向服务器写入数据。 但是当客户端向服务器写入数据时，由于服务器端的套接字进程已经终止，此时连接的状态已经异常了，所以服务端进程不会向客户端发送 ACK 报文，而是发送了一个 RST 报文请求将处于异常状态的连接复位；如果客户端还要继续向服务端发送数据，系统会发出一个 SIGPIPE 信号给进程，告诉进程这个连接已经断开了，不要再写了。 根据信号的默认处理规则 SIGPIPE 信号的默认执行动作是 terminate(终止、退出),所以客户端会退出。","categories":[{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"},{"name":"TCP","slug":"网络/TCP","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/TCP/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/tags/%E7%BD%91%E7%BB%9C/"},{"name":"TCP","slug":"TCP","permalink":"https://tang7o.cn/tags/TCP/"}]},{"title":"HashMap为什么使用红黑叔而不是其他数据结构","slug":"HashMap为什么使用红黑树而不是其他数据结构","date":"2022-03-01T01:22:09.000Z","updated":"2022-04-13T13:31:48.024Z","comments":true,"path":"2022/03/01/HashMap为什么使用红黑树而不是其他数据结构/","link":"","permalink":"https://tang7o.cn/2022/03/01/HashMap%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E7%BA%A2%E9%BB%91%E6%A0%91%E8%80%8C%E4%B8%8D%E6%98%AF%E5%85%B6%E4%BB%96%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"为什么要使用红黑树以及什么时候使用红黑树？向 HashMap 中添加数据时不可避免的会产生 Hash 冲突，而 HashMap 使用拉链法来解决 Hash 冲突，这就导致在 Hash 冲突较多的时候，会严重影响 HashMap 的查询效率（链表查询时间复杂度为O(n))，因此引入了红黑树（查询时间复杂度O(log n))这一数据结构来优化。 那么什么时候会使用红黑树呢？ 在链表长度达到 8 并且 HashMap 存储的数据量大于 64 时，会将链表转化为红黑树。 为什么不一开始就直接用红黑树呢？ 红黑树是二叉平衡树的一种，在插入和删除数据时红黑树需要通过旋转来保持“平衡”，这一过程是要付出代价的。而且红黑树节点的大小为链表节点的 2 倍，在节点太少时红黑树查找性能优势并不明显。 为什么不适用其他数据结构？如上所述，引入红黑树的目的是为了优化查询效率，但是能够优化查询效率的数据结构又不止红黑树一种，为什么不适用其他的数据结构呢？ 例如二叉树、平衡二叉树、B树、B+树这些数据结构查询效率也很高，为什么不适用他们呢？ 二叉树二叉树存在数据倾斜问题，极端情况下会退化成链表（只有左节点或只有右节点），不够稳定。 平衡二叉树平衡二叉树和红黑树查询时间复杂度都是O（log n)。但是平衡二叉树有更加严格的”平衡“标准，在插入或者删除数据时，平衡二叉树需要更多的旋转才能达到平衡。 B树、B+树B树和B+树的节点都能存储多个数据，在数据量不是很多的情况下，数据会”挤在“一个节点里面。这个时候遍历效率就退化成了链表。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"}]},{"title":"MySQL 一条 SQL 语句的执行过程","slug":"MySQL-ZXGC","date":"2021-11-23T02:37:56.000Z","updated":"2022-04-13T13:31:48.246Z","comments":true,"path":"2021/11/23/MySQL-ZXGC/","link":"","permalink":"https://tang7o.cn/2021/11/23/MySQL-ZXGC/","excerpt":"","text":"MySQL 驱动我们的系统在和 MySQL 数据库进行通信的时候，总不可能是平白无故的就能接受和发送请求，就算是你没有做什么操作，那总该是有其他的“人”帮我们做了一些事情，基本上使用过 MySQL 数据库的程序员多多少少都会知道 MySQL 驱动这个概念的。就是这个 MySQL 驱动在底层帮助我们做了对数据库的连接，只有建立连接了，才能有后面的交互。看下图表示： 这样的话，在系统和 MySQL 进行交互之前，MySQL 驱动会帮我们建立好连接，然后我们只需要发送 SQL 语句就可以执行 CRUD 了。一次 SQL 请求就会建立一个连接，多个请求就会建立多个连接，那么问题来了，我们系统肯定不是一个人在使用的，换句话说肯定是存在多个请求同时去争抢连接的情况。我们的 web 系统一般都是部署在 tomcat 容器中的，而 tomcat 是可以并发处理多个请求的，这就会导致多个请求会去建立多个连接，然后使用完再都去关闭，这样会有什么问题呢？如下图： java 系统在通过 MySQL 驱动和 MySQL 数据库连接的时候是基于 TCP/IP 协议的，所以如果每个请求都是新建连接和销毁连接，那这样势必会造成不必要的浪费和性能的下降，也就是说上面的多线程请求的时候频繁的创建和销毁连接显然是不合理的。必然会大大的降低我们系统的性能，但是如果给你提供一些固定的用来连接的线程，这样是不是就不需要反复的创建和销毁连接了呢？相信懂行的朋友会会心一笑，没错，就是数据库连接池。 数据库连接池：维护一定的连接数，方便系统获取连接，使用就去池子中获取，用完放回去就可以了，我们不需要关心连接的创建和销毁，也不需要关心线程池是怎么去维护这些连接的。 常见的数据库连接池有 Druid、C3P0、DBCP，连接池实现原理在这里就不深入讨论了，采用连接池大大节省了不断创建与销毁线程的开销，这就是有名的「池化」思想，不管是线程池还是 HTTP 连接池，都能看到它的身影。 数据库连接池到这里，我们已经知道的是我们的系统在访问 MySQL 数据库的时候，建立的连接并不是每次请求都会创建的，而是从数据库连接池中去获取，这样就解决了因为反复的创建和销毁连接带来的性能损耗问题了。不过这里有个小问题，业务系统是并发的，而 MySQL 接受请求的线程呢，只有一个？ 其实 MySQL 的架构体系中也已经提供了这样的一个池子，也是数据库连接池。双方都是通过数据库连接池来管理各个连接的，这样一方面是线程之前不需要争抢连接，更重要的是不需要反复的创建和销毁连接。 至此系统和 MySQL 数据库之间的连接问题已经说说明清楚了。那么 MySQL 数据库中这些连接是怎么来处理的，又是谁来处理的呢？ 网络连接必须由线程来处理对计算机基础稍微有一点了解的同学都是知道的，网络中的连接都是由线程来处理的，所谓网络连接说白了就是一次请求，每次请求都有相应的线程去处理。也就是说对于 SQL 语句的请求在 MySQL 中是由一个个线程去处理的。 那这些线程会怎么去处理这些请求？会做哪些事情？ SQL 接口MySQL 中处理请求的线程在获取到请求以后获取 SQL 语句去交给 SQL 接口处理。 查询解析器假设现在有这样一个 SQL。 12SELECT stuName,age,sex FROM students WHERE id=1 但是这个 SQL 是写给我们人看的，机器哪会知道你在说什么？这个时候解析器就上场了。他会将 SQL 接口传递过来的 SQL 语句进行解析，翻译成 MySQL 自己能认识的语言，至于怎么解析的就不需要再深究了，无非是自己的一套规则。 现在 SQL 已经被解析成 MySQL 认识的样子了，那下一步不就是执行了吗？理论上来说是这样的，但是 MySQL 的强大远不止如此，它还会帮我们选择最优的查询路径。 什么叫最优的查询路径？就是 MySQL 会按照自己认为的效率最高的方式去执行查询。 具体是怎么做到的呢？这就要说到 MySQL 的查询优化器了。 MySQL 查询优化器查询优化器内部具体怎么实现的我们并不关心，我们需要知道的是 MySQL 会帮我们去使用它自己认为最好的方式去优化这条 SQL 语句，并且生成一条条的执行计划，比如你创建了多个索引，MySQL 会依据成本最小原则来选择使用响应的索引，这里的成本主要包括两个方面，IO 成本和 CPU 成本。 IO 成本：即从磁盘把数据加载到内存的成本，默认情况下，读取数据页的 IO 成本是 1，MySQL 是以页的形式读取数据的，即当用到某个数据时，并不会只读取这个数据，而会把这个数据相邻的数据也一起读到内存中，这就是有名的程序局部性原理，所以 MySQL 每次会读取一整页，一页的成本是 1。所以 IO 的成本主要和页的大小有关。 CPU 成本：将数据读入内存后，还需要杰测数据是否满足条件和排序等 CPU 操作的成本，显然它和行数有关，默认情况下，检测记录的成本为 0.2. MySQL 优化器会计算「IO 成本 + CPU 成本」最小的那个索引来执行。 优化器执行选出最优索引等步骤后，会调用存储引擎接口，开始去执行被 MySQL 解析过和优化过的 SQL 语句。 存储引擎查询优化器会调用存储引擎的接口，去执行 SQL，也就是说真正执行 SQL 的动作是在存储引擎中完成的。数据是被存放放在内存或者是磁盘中的（存储引擎是一个非常重要的组件，后面会详细介绍） 执行器执行器是一个非常重要的组件，因为前面那些组件的操作最终必须通过执行器去调用存储引擎的接口才能被执行。执行器最终根据一系列的执行计划去调用存储引擎的接口去完成 SQL 的执行。 初识存储引擎我们以一个更新的 SQL 语句来说明，SQL 如下： 1UPDATE students SET stuName = &#x27;张三&#x27; WHERE id = 1 当我们系统发出这样的语句去交给 MySQL 的时候，MySQL 会按照我们上面介绍的一系列的流程最终通过执行器调用存储引擎去执行，流程图就是上面那个。在执行这个 SQL 的时候 SQL 语句对应的数据要么在内存中，要么是在磁盘中，如果在磁盘中操作，那这样的随机 IO 读写的速度肯定是让人无法接受的，所以每次在执行 SQL 的时候，都会将数据加载到内存中，这块内存就是 InnoDB 中一个非常重要的组件：缓冲池 Buffer Pool。 Buffer PoolBuffer Poll（缓冲池）是 InnoDB 存储引擎中非常重要的内存结构，顾名思义，缓冲池其实就是类似 Redis 一样的作用，因为我们都知道 MySQL 的数据最终是存储在磁盘中的，如果没有这个 Buffer Poll 那么我们每次的数据库请求都会在磁盘中查找，这样必然会存才 IO 操作，这肯定是无法接受的。但是如果有了 Buffer Poll 就是我们在第一次查询的时候会将查询的结果存到 Buffer Poll 中，这样后面再有请求的时候就会先从缓冲池中查询，如果没有再去磁盘中查找，然后放到 Buffer Poll 中，如下图： 按照上面的图，这条 SQL 语句的执行步骤大概是这样的： InnoDB 存储引擎会在缓冲池中查找 id = 1 的这条数据是否存在。 发现不存在，那么就会去磁盘中加载，并将其放在缓冲池中。 该条记录会被加上一个独占锁（总部能你在修改的时候别人也在该吧） undo 日志文件：记录数据被修改前的样子undo 顾名思义，就是没有做，没有发生的意思。undo log 就是没有发生事情（原本事情是什么样子）的一些日志。 我们刚刚已经说了，在准备更新一条语句的时候，该条语句已经被加载到 Buffer Pool 中来，实际上这里还有这样的操作，就是在将该条语句加载到 Buffer Poll 中的时候同时会往 undo 日志文件中插入一条日志，也就是将 id = 1 这条记录原来的值记录下来。 这样做的目的是什么？ InnoDB 存储引擎最大的特点就是支持事务，如果本次更新失败，也就是事务失败，那么该事务中的所有操作都必须回滚到执行前的样子，也就是说当事务失败的时候，也不会对原始数据有影响，如下图： 到这一步，我们执行的 SQL 语句已经被加载到 Buffer Pool 中了，然后开始更新这条语句，更新的操作实际是在 Buffer Pool 中执行的。那么问题来了，按照我们平时开发的一套理论缓冲池中的数据和数据库中的数据不一致的时候，我们就认为缓存中的数据是脏数据，那么此时 Buffer Pool 中的数据岂不是成了脏数据？没错，目前这条数据就是脏数据，Buffer Pool 中的记录是张三，数据库中的记录是李四，这种情况 MySQL 是怎么处理的呢？ redo 日志文件：记录数据被修改后的样子除了从磁盘中加载文件和将操作前的记录保存到 undo 日志中，其他的操作是在内存中完成的，内存中数据的特点就是：断电丢失。如果此时 MySQL 所在的服务器宕机了，那么 Buffer Pool 中的数据会全部丢失的。这个时候 redo 日志文件就需要出来大显神通了。 画外音：redo 日志文件是 InnoDB 特有的，它是存储引擎级别的，不是 MySQL 级别的。 redo 记录的数据修改之后的样子，不管事务是否提交都会记录下来，例如，此时要做的是update students set stuName=&#39;小强&#39; where id=1;那么这条操作就会被记录到 redo log buffer 中，啥？怎么又出来一个 redo log buffer，很简单，MySQL 为了提高效率，所以将这些操作都先放在内存中去完成，然后会在某个会时机将其持久化到磁盘中。 截至目前，我们应该熟悉了 MySQL 的执行器调用存储引擎是怎么将一条 SQL 加载到缓冲池和记录哪些日志的，流程如下： 准备更新一条 SQL 语句 MySQL（InnoDB）会先去缓冲池（Buffer Pool）中去查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载到缓冲池（Buffer Pool）中。 在加载到 Buffer Poll 中的同时，会将这条数据的原始记录保存到 undo 日志文件中。 InnoDB 会在 Buffer Pool 中执行更新操作。 更新后的数据会记录在 redo log buffer 中。 上面说的步骤都是在正常情况下的操作，但是程序的设计和优化并不仅是为了这些正常情况去做的，也是为了那些临界区和极端情况下出现的问题去优化设计的。 这个时候如果服务器宕机了，那么缓存中的数据还是丢失了。真烦，竟然数据总是丢失，那能不能不要放在内存中，直接保存到磁盘呢？很显然不行，因为在上面也已经介绍了，在内存中操作目的是为了提高效率。 此时，如果 MySQL 真的宕机了，那么没有关系的，因为 MySQL 会认为本次事务是失败的，所以数据依旧是更新前的样子，并不会有任何的影响。 好了，语句也更新好了那么需要将更新的值提交啊，也就是需要提交本次的事务了，因为只要事务成功提交了，才会将最后的变更保存到数据库，在提交事务前仍然会具有相关的其他操作。 将 redo log buffer 中的数据持久化到磁盘中，就是将 redo log buffer 中的数据写到 redo log 磁盘文件中，一般情况下，redo log buffer 数据写入磁盘的策略是立即刷入磁盘（具体策略情况在下面小总结处会详细介绍） 如果 redo log buffer 刷入磁盘后，数据库服务器宕机了，那么我们更新的数据怎么办？此时数据是在内存中，数据岂不是丢失了？不，这次数据就不会丢失了，因为 redo log buffer 中的数据已经被写入磁盘了，已经持久化了，就是数据库宕机了，在下次重启的时候 MySQL 也会将 redo 日志文件内容恢复到 Buffer pool 中（这边我理解的是和 Redis 的持久化机制是差不多的，在 Redis 启动的时候会检查 rdb 或者 aof 或者两者都检查，根据持久化的文件来将数据恢复到内存中） 到处为止，从执行器开始调用存储引擎接口做了哪些事情呢？ 准备一条 SQL 语句。 MySQL（InnoDB）会先去缓冲池（Buffer Pool）中去查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载到缓冲池（Buffer Pool）中。 在加载到 Buffer Poll 中的同时，会将这条数据的原始记录保存到 undo 日志文件中。 InnoDB 会在 Buffer Pool 中执行更新操作。 更新后的数据会记录在 redo log buffer 中。 MySQL 提交事务的时候，会将 redo log buffer 中的数据写入到 redo 日志文件中，刷磁盘可以通过 innodb_flush_log_at_trx_commit 参数来设置。 值为 0 表示不刷入磁盘 值为 1 表示立即刷入磁盘 值为 2 表示先刷到 os cache MySQL 重启时会将 redo 日志恢复到缓冲池中。 截至到目前位置，MySQL 的执行器调用存储引擎的接口去执行「执行计划」提供的 SQL 的时候 InnoDB 做了哪些事情也就差基本差不多了，但是这还没完。下面还需要介绍下 MySQL 级别的日志 bin log。 bin log 日志文件：记录整个操作过程上面介绍到的 redo log 是 InnoDB 存储引擎特有的日志文件，而 bin log 是属于 MySQL 级别的日志。redo log 记录的东西是偏向于物理性质的，如：“对上面数据，做了什么修改”。bin log 是偏向于逻辑性质的，类似于：“对 students 表中 id 为 1 的记录做了更新操作”两者的主要特点总结如下。 性质 redo log bin log 文件大小 大小固定（配置中也可以设置，一般默认的就足够了） 可以通过配置参数 max_bin log_size 修改每个 bin log 的大小（但是一般不建议修改）。 实现方式 InnoDB 引擎实现的（也就是说是 InnoDB 存储引擎独有的） MySQL 层实现的，所有引擎都可以使用。 记录方式 循环写的方式记录，当写到结尾时，会回到开头循环写日志。 追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上。 使用场景 适用于崩溃恢复（crash-safe）（这一点其实非常类似 Redis 的持久化特征） 适用于主从复制和数据恢复。 bin log 文件是如何刷入磁盘的？ bin log 的刷盘是有相关的策略的，策略可以通过 sync_bin log 来修改，默认为 0，表示先写入 os cache，也就是在提交事务的时候，数据不会直接刷到磁盘中，这样如果宕机 bin log 数据仍然会丢失。所以建议将 sync_bin log 设置为 1 表示直接将数据写入到磁盘文件中。 刷入 bin log 有以下几种模式： STATMENT 基于 SQL 语句的复制（statement-based replication, SBR)，每一条会修改数据的 SQL 语句会记录到 bin log 中。 【优点】：不需要记录每一行的变化，减少了 bin log 的日志量，节约了 IO，从而提高了性能。 【缺点】：在某些情况下会导致主从数据不一致，比如执行 sysdat()、sleep() 等。 ROW 基于行的复制（row-based replication, RBR），不记录每条SQL语句的上下文信息，仅需记录哪条数据被修改了。 【优点】：不会出现某些特定情况下的存储过程、或 function、或 trigger 的调用和触发无法被正确复制的问题。 【缺点】：会产生大量的日志，尤其是 alter table 的时候会让日志暴涨。 MIXED 基于 STATMENT 和 ROW 两种模式的混合复制（mixed-based replication, MBR），一般的复制使用 STATEMENT 模式保存 bin log，对于 STATEMENT 模式无法复制的操作使用 ROW 模式保存 bin log。 那既然 bin log 也是日志文件，那它是在什么时候记录数据呢？ 其实 MySQL 在提交事务的时候，不仅仅会将 redo log buffer 中的数据写入 redo log 文件中，同时也会将本次修改的数据记录到 bin log 文件中，同时会将本次修改的 bin log 文件名和修改的内容在 bin log 中的位置记录到 redo log 中，最好还会在 redo log 写入 commit 标记，这样就表示本次事务被成功的提交了。 如果在数据被写入到 bin log 文件的时候，数据库宕机了，数据还会丢失吗？ 首先可以确定的是，只要 redo log 最后没有 commit 标记，说明本次事务一定是失败的。但是数据是没有丢失的，因为已经记录到 redo log 的磁盘文件中了。在 MySQL 重启的时候，就会将 redo log 的数据恢复（加载）到 Buffer pool 中。 好了，到目前为止，一个更新操作我们基本介绍的差不多了，但是你有没有感觉少了哪些事情还没有做？是不是你也发现这个时候被更新的记录仅仅是在内存中执行的，哪怕是宕机又恢复了也仅仅是将更新后的记录加载到 Buffer Pool 中，这个时候 MySQL 数据库中的这条记录依旧是旧值，也就是说内存中的数据在我们看来依旧是脏数据，那这个时候怎么办呢？ 其实 MySQL 会有一个后台线程，它会在某个时机将我们 Buffer Pool 中的脏数据刷到 MySQL 数据库中，这样就将内存和数据库中的数据保持统一了。 本文总结到此，关于 Buffer Pool、redo log buffer 和 undo log、redo log、bin log 概念以及关系就基本差不多了。 我们再回顾下 Buffer Pool 是 MySQL 的一个非常重要的组件，因为针对数据库的增删改操作都是在 Buffer Pool 中完成的 undo log 记录的是数据操作前的样子 redo log 记录的是数据被操作后的样子（redo log 是 InnoDB 存储引擎特有） bin log 记录的是整个操作记录（这个对于主从复制具有非常重要的意义） 从准备更新一条数据到事务的提交的流程描述 首先执行器根据 MySQL 的执行计划来查询数据，先是从缓存池中查询数据，如果没有就会去数据库中查询，如果查询到了就将其放到缓存池中 在数据被缓存到缓存池的同时，会写入 undo log 日志文件 更新的动作是在 Buffer Pool 中完成的，同时会将更新后的数据添加到 redo log buffer 中。 完成以后就可以提交事务，在提交的同时会做以下三件事 将 redo log buffer 中的数据刷入到 redo log 文件中。 将本次操作记录写入到 bin log 文件中。 将 bin log 文件名字和更新内容在 bin log 中的位置记录到 redo log 中，同时在 redo log 最后添加 commit 标记。 至此表示整个更新事务已经完成。 文章来源 作者：码海 原文链接：传送门","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/tags/MySQL/"}]},{"title":"MySQL 性能优化","slug":"MySQL-XNYH","date":"2021-11-19T00:17:24.000Z","updated":"2022-04-13T13:31:48.217Z","comments":true,"path":"2021/11/19/MySQL-XNYH/","link":"","permalink":"https://tang7o.cn/2021/11/19/MySQL-XNYH/","excerpt":"","text":"使用 Explain 进行分析Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。 比较重要的字段有: select_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数 优化数据访问1. 减少请求的数据量 只返回必要的列: 最好不要使用 SELECT * 语句。 只返回必要的行: 使用 LIMIT 语句来限制返回的数据。 缓存重复查询的数据: 使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。 2. 减少服务器端扫描的行数最有效的方式是使用索引来覆盖查询。 重构查询方式1. 切分大查询一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。 2. 分解大连接查询将一个大连接查询分解成对每一个表进行一次单表查询，然后将结果在应用程序中进行关联，这样做的好处有: 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 减少锁竞争； 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/tags/MySQL/"}]},{"title":"MySQL 引擎","slug":"MySQL-YQ","date":"2021-11-16T12:46:12.000Z","updated":"2022-04-13T13:31:48.231Z","comments":true,"path":"2021/11/16/MySQL-YQ/","link":"","permalink":"https://tang7o.cn/2021/11/16/MySQL-YQ/","excerpt":"","text":"InnoDB是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。 实现了四个标准的隔离级别，默认级别为可重复读。在可重复读的级别下，通过多版本并发控制（MVCC）+间隙锁（Next-Key Locking）防止幻读。 基于聚簇索引（主索引）建立，在主索引中保存数据。与其他存储引擎有很大的区别，聚簇索引对主键查询有很高的性能，不过它的二级索引（非主键索引）必须包含主键列。所以如果主键列很大的话，索引会很大。 MyISAM在5.1之前，MyISAM 是默认的引擎，MyISAM 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。 提供了大量的特性，包括压缩表、空间数据索引等。 但是 MyISAM 不支持事务和行级锁，而且在崩溃后无法安全恢复。即使后续版本中 MyISAM 支持了事务，但是很多人的概念中依然是不支持事务的引擎。 不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。 比较事务和外键InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。 InnoDB 支持外键。 锁和并发MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。 MyISAM 读写互相阻塞：不仅会在写入的时候阻塞读取，MyISAM 还会在读取的时候阻塞写入，但读本身并不会阻塞另外的读。 InnoDB 读写阻塞与事务隔离级别相关。 索引和存储MyISAM 和 InnoDB 的索引都采用了 B+ 树的结构。 MyISAM 的索引和数据是分开的，是非聚簇索引。叶子节点存放索引键和数据记录的地址，如下图所示： MyISAM 引擎将数据存储成三个文件，以表名命名，扩展名指出文件类型。 .frm 文件存储表定义。 .MYD 文件存储数据。 .MYI 文件存储索引。 而 InnoDB 引擎的数据存储在聚簇索引（主键建立的索引）的叶子节点中，如下图所示： InnoDB 的非聚簇索引的叶子节点存储了该条记录的主键。如下图所示： 因此使用非聚簇索引查询数据时，还需要利用聚簇索引再查询一遍（回表查询）。但是有一种情况例外：你要查询的信息包含在索引内（覆盖索引）。 注意：MyISAM 表是保存成文件的形式，在跨平台的数据转移中使用MyISAM存储会省去不少的麻烦。 其他 MyISAM 引擎保存了表中数据的行数，查询时可以直接读取。InnoDB 引擎需要扫描一遍表来计算行数。但是如果查询语句中包含了 where 条件时，两种引擎的操作是一样的。 DELETE FROM table 时，InnoDB 不会重新建立表，而是一行一行的删除。 如果执行大量的 SELECT，MyISAM 是更好的选择，如果你的数据执行大量的 INSERT 或 UPDATE，出于性能方面的考虑，应该使用 InnoDB 表。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/tags/MySQL/"}]},{"title":"MySQL事务ACID实现原理","slug":"MySQL-ACID","date":"2021-11-13T11:40:15.000Z","updated":"2022-04-13T13:31:48.190Z","comments":true,"path":"2021/11/13/MySQL-ACID/","link":"","permalink":"https://tang7o.cn/2021/11/13/MySQL-ACID/","excerpt":"","text":"原子性实现原理：利用 undo log。 undo log 名为回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的 sql 语句，他需要记录你要回滚的相应日志信息： 当你 delete 一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert 这条旧数据 当你 update 一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行 update 操作 当年insert一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行 delete 操作 undo log 记录了这些回滚需要的信息，当事务执行失败或调用了 rollback ，导致事务需要回滚，便可以利用 undo log 中的信息将数据回滚到修改之前的样子。 持久性实现原理：利用 redo log。 MySQL 先把磁盘上的数据加载到内存，在内存中进行修改，再刷回磁盘。如果此时突然宕机，内存中的数据将会丢失。 如何解决这个问题？ 事务提交前直接把数据写入磁盘？这样做存在以下的问题： 只修改一个页面里的一个字节，就要将整个页面刷入磁盘，太浪费资源了。毕竟一个页面 16kb 大小，你只改其中一点点东西，就要将 16kb 的内容刷入磁盘，听着也不合理。 毕竟一个事务里的 SQL 可能牵涉到多个数据页的修改，而这些数据页可能不是相邻的，也就是属于随机 IO。显然操作随机 IO，速度会比较慢。 于是，采用 redo log 解决上面的问题。当修改数据时，不仅在内存中修改，还会在 redo log 中记录这次操作。当事务提交的时候，会将 redo log 日志进行刷盘（redo log 一部分在内存中，一部分在磁盘上）。当数据库宕机重启的时候，会将 redo log 的内容恢复到数据库中，再根据 undo log 和 bin log 来决定回滚还是提交数据。 采用 redo log 的好处（相对直接将数据写入磁盘）： redo log 体积小，只记录了哪一页修改了什么，刷盘快。 redo log 是一直往末尾追加，属于顺序 IO。效率更高。 隔离性实现原理：锁 + MVCC。 锁很简单，就是事务在修改数据的时候需要获取锁、上锁之类的操作。 MVCC：多版本并发控制（Multi Version Concurrency Control），一个行记录数据有多个版本对快照数据，这些快照数据在 undo log 中。 如果一个事务读取的行正在做 DELELE 或者 UPDATE 操作，读取操作不会等行上的锁释放，而是读取该行的快照版本。 一致性数据库通过原子性、隔离性、持久性来保证一致性。也就是说ACID四大特性之中，C（一致性）是目的，A（原子性）、I（隔离性）、D（持久性）是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现AID三大特性，才有可能实现一致性。 数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等。 应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/tags/MySQL/"}]},{"title":"Redis事务","slug":"Redis事务","date":"2021-11-11T13:32:15.000Z","updated":"2022-04-13T13:31:48.282Z","comments":true,"path":"2021/11/11/Redis事务/","link":"","permalink":"https://tang7o.cn/2021/11/11/Redis%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"Redis 通过 MULTI、EXEC、WATCH 等命令来实现事务功能。事务提供一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制。 以下是一个事务的执行过程，该事务首先以一个 MULTI 命令为开始，接着将多个命令放入事务中，最后由 EXEC 命令将这个事务提交给服务器执行： 1234567891011121314151617181920redis&gt; MULTIOKredis&gt; SET &quot;name&quot; &quot;Practical Common Lisp&quot;QUEUEDredis&gt; GET &quot;name&quot;QUEUEDredis&gt; SET &quot;author&quot; &quot;Peter Seibel&quot;QUEUEDredis&gt; GET &quot;author&quot;QUEUEDredis&gt; EXEC1) OK2) &quot;Practical Common Lisp&quot;3) OK4) &quot;Peter Seibel&quot; 事务的实现一个事务从开始到结束通常会经历以下三个阶段： 事务开始。 命令入队。 事务执行。 事务开始MULTI 命令的执行标志着事务的开始： 12redis&gt; MULTIOK MULTI 命令可以将执行该命令的客户端从非事务状态切换到事务状态，这一切换是通过在客户端状态的 flags 属性中打开 REDIS_MULTI 标识来完成的，具体实现可以用以下伪代码来表示： 12345def MULTI(): #打开事务标识识 client.flags |= REDIS_MULTI #返回OK回复 replyOK() 命令入队当一个客户端还处于非事务状态时，这个客户端发送的命令会立即被服务器执行： 1234567891011redis&gt; SET &quot;name&quot; &quot;Practical Common Lisp&quot;OKredis&gt; GET &quot;name&quot;&quot;Practical Common Lisp&quot;redis&gt; SET &quot;author&quot; &quot;Peter Seibel&quot;OKredis&gt; GET &quot;author&quot;&quot;Peter Seibel&quot; 与此不同的是，当一个客户端切换到事务状态之后，服务器会根据这个客户端发来的不同命令执行不同的操作： 如果命令为 EXEC、DISCARD、WATCH、MULTI四 个命令中的其中一个，那么服务器会立即执行这个命令。 其他的命令不会立即执行，而是将这个命令放入一个事务队列里面，然后向客户端返回 QUEUED 回复。 事务队列每个 Redis 客户端都有自己的事务状态，这个事务状态保存在客户端状态的 mstate 属性中： 12345678typedef struct redisClient &#123; // ... //事务状态 multiState mstate; /* MULTI/EXEC state */ // ...&#125; redisClient; 事务状态包含一个事务对象，以及一个已入队命令的计数器（事务队列的长度）： 1234567typedef struct multiState &#123; //事务队列，FIFO顺序 multiCmd *commands; //已入队命令计数 int count;&#125; multiState; 事务队列是一个 multiCmd 类型的数组，数组中每个 multiCmd 结构都保存来一个已入队的命令的相关信息，包含指向命令实现函数的指针、命令参数，以及参数的数量： 12345678910typedef struct multiCmd &#123; //参数 robj **argv; //参数数量 int argc; //命令指针 struct redisCommand *cmd;&#125; multiCmd; 执行事务当一个处于事务状态的客户端向服务器发送 EXEC 命令时，这个 EXEC 命令会立即被执行。服务器会遍历客户端的事务队列，执行队列中的所有命令，最后将执行的结果全部返回给客户端。 EXEC 的实现原理可以用以下伪代码来描述： 1234567891011121314151617181920212223def EXEC(): # 创建空白的回复队列 reply_queue = [] # 遍历事务队列中的每个项 # 读取命令的参数、参数个数、以及要执行的命令 for argv, argc, cmd in client.mstate.commands: # 执行命令，并取得命令的返回值 reply = execute_command(cmd, argv, argc) # 将返回值加到回复队列末尾 reply_queue.append(reply) # REDIS_MULTI 标识，让客户端回到非事务状态 client.flags &amp; = ~REDIS_MULTI # 清空客户端的事务状态，包括： # 1）清零入队命令计数器 # 2）释放事务队列 client.mstate.count = 0 release_transaction_queue(client.mstate.commands) # 将事务的执行结果返回给客户端 send_reply_to_client(client, reply_queue) WATCH 命令的实现WATCH 命令是一个乐观锁，它可以在 EXEC 命令执行前，监视任意数量的键，并在 EXEC 命令执行时，检查被监视的键是否至少有一个被修改过，如果是，服务器拒绝执行事务，并向客户端返回代表事务执行失败的空回复。 注意：EXEC 命令开始执行后遍历事务队列执行事务，因此事务中的修改不对 WATCH 造成影响。 使用 WATCH 命令监视数据库键每个 Redis 数据库都保存着一个 watched_keys 字典，这个字典的键是某个被 WATCH 命令监视的数据库键，而字典的值则是一个链表，链表中记录了所有监视相应数据库键的客户端： 12345678typedef struct redisDb &#123; // ... //正在被WATCH命令监视的键 dict *watched_keys; // ...&#125; redisDb; 通过 watched_keys 字典，服务器可以清楚的指导那些数据库键正在被监视，以及哪些客户端正在监视这些数据库键。 假设当前客户端为 c10086,数据库 watched_keys 字典状态为下图所示： 当 c10086 执行以下命令后： 12redis&gt; WATCH &quot;name&quot; &quot;age&quot;OK 数据库 watched_keys 字典状态变为下图所示： 监视机制的触发所有对数据库进行修改的命令，在执行之前都会调用 multi.c/touchWatchKey 函数对 watched_keys 字典进行检查，查看是否有客户端正在监视要修改的键，如果有的话，touchWatchKey 函数会将监视被修改键的客户端的 REDIS_DIRTY_CAS 标识打开，标识该客户端的事务安全性已经被破坏。 touchWatchKey 函数的定义可以用以下伪代码来描述： 12345678def touchWatchKey(db, key): # 如果键 key 存在于数据库的 watched_keys 字典中 # 那么说明至少有一个客户端在监视这个 key if key in db.watched_keys: # 遍历所有监视 key 的客户端 for client in db.watched_keys[key]: # 打开 REDIS_DIRTY_CAS 标识 client.flags |= REDIS_DIRTY_CAS 判断事务是否安全当服务器接收到客户端发来的 EXEC 命令时，服务器会根据这个客户端是否打开了 REDIS_DIRTY_CAS 标识来决定是否执行事务： 事务的 ACID 性质在 Redis 中，事务总是具有原子性（Atomicity）、一致性（Consistency）和隔离性（Isolation），某种特定的持久化情况下具有持久性（Durability）。 原子性事务具有原子性是指，数据库将事务中的多个操作当作一个整体来执行，要么都执行，要么就一个也不执行。 对于 Redis 的事务功能来说，事务队列中的命令要么全部执行，要么就一个都不执行，因此，Redis 的事务是具有原子性的。 例子，成功执行的事务，事务的命令都会被执行： 123456789101112redis&gt; MULTIOKredis&gt; SET msg &quot;hello&quot;QUEUEDredis&gt; GET msgQUEUEDredis&gt; EXEC1) OK2) &quot;hello&quot; 例子，执行失败的事务，这个事务因为命令入队出错而被服务器拒绝执行，事务的命令都不会执行： 12345678910redis&gt; MULTIOKredis&gt; SET msg &quot;hello&quot;QUEUEDredis&gt; GET(error) ERR wrong number of arguments for &#x27;get&#x27; commandredis&gt; GET msgQUEUEDredis&gt; EXEC(error) EXECABORT Transaction discarded because of previous errors. Redis 事务和传统的关系数据库事务最大的区别在于：Redis 不支持事务回滚机制，即时事务队列中的某个命令在执行期间出现了错误，整个事务也会继续执行下去，直到事务执行完毕。 例子，即时 RPUSH 命令在执行期间出现了错误，事务的后续命令也会继续执行下去，并且之前执行的命令也不会有任何影响： 12345678910111213141516171819redis&gt; SET msg &quot;hello&quot;OKredis&gt; MULTIOKredis&gt; SADD fruit &quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;QUEUEDredis&gt; RPUSH msg &quot;good bye&quot; &quot;bye bye&quot; # 错误的对字符串键 msg 执行列表键的操作QUEUEDredis&gt; SADD alphabet &quot;a&quot; &quot;b&quot; &quot;c&quot;QUEUEDredis&gt; EXEC1) (integer) 32) (error) WRONGTYPE Operation against a key holding the wrong kind of value3) (integer) 3 Redis 的作者在事务功能的文章中解释说：不支持事务回滚是因为这种复杂的功能和 Redis 追求简单高效的设计主旨不相符，并且他认为，Redis 事务的执行时错误通常都是编译错误产生的，这种错误通常只会出现在开发环境中，而很少在实际的生产环境中出现，所以他认为没有必要为 Redis 开发事务回滚功能。 一致性事务具有一致性指的是，如果数据库在执行事务之前是一致的，那么在执行事务之后，无论事务是否执行成功，数据库也应该仍然是一致的。 “一致”是指数据符合数据库本身的定义和要求，没有包含非法或无效的错误数据。 Redis 通过谨慎的错误检测和简单的设计来保证事务的一致性，以下三部分分别介绍三个 Redis 事务可能出错的地方，并说明 Redis 是如何处理这些错误，从而确保事务的一致性。 1.入队错误如果一个事务在入队命令的过程中，出现了命令不存在，或者命令的格式不正确等情况，那么 Redis 将拒绝执行这个事务。 例子，因为客户端尝试向事务入队一个不存在的命令 Tang7O，所以客户端提交的事务会被服务器拒绝执行。 1234567891011121314redis&gt; MULTIOKredis&gt; SET msg &quot;hello&quot;QUEUEDredis&gt; YAHOOOO(error) ERR unknown command &#x27;Tang7O&#x27;redis&gt; GET msgQUEUEDredis&gt; EXEC(error) EXECABORT Transaction discarded because of previous errors. 因为服务器会拒绝执行入队错误的事务，因此 Redis 事务的一致性不会被带有入队错误的事务影响。 Redis 2.6.5 以前的版本，即时有命令在入队过程中发生了错误，事务一样可以执行，不过被执行的命令只包括哪些正确入队的命令。 2.执行错误除了入队时可能发生错误外，事务还可能在执行过程中发生错误。 执行过程中发生的错误都是一些不能在入队时被服务器发现的错误，这些错误只会在命令实际执行时被触发。 即使在事务的执行过程中发生了错误，服务器也不会中断事务的执行，它会继续执行事务中余下的其他命令，并且已经执行的命令不会被出错的命令影响。 例子，用列表键的 RPUSH 命令操作字符串键。 12345678910111213141516171819redis&gt; SET msg &quot;hello&quot;OKredis&gt; MULTIOKredis&gt; SADD fruit &quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;QUEUEDredis&gt; RPUSH msg &quot;good bye&quot; &quot;bye bye&quot;QUEUEDredis&gt; SADD alphabet &quot;a&quot; &quot;b&quot; &quot;c&quot;QUEUEDredis&gt; EXEC1) (integer) 32) (error) WRONGTYPE Operation against a key holding the wrong kind of value3) (integer) 3 因为在事务执行的过程中，出错的命令会被服务器识别出来，并进行响应的处理，所以不会对事务的一致性产生影响。 3.服务器停机如果 Redis 服务器在事务执行过程中停机，那么根据服务器所使用的持久化模式，可能有以下情况出现： 无持久化：重启之后数据库是空白的，因此数据总是一致的。 RDB 持久化：事务中途停机不会导致不一致性，因为服务器可以根据现有的 RDB 文件来恢复数据，从而将数据库还原到一个一致性状态。如果找不到可供使用的 RDB 文件，那么重启之后数据库将是空白的，而空白数据库总是一致的。 AOF 持久化：服务器可以根据现有的 AOF 文件来恢复数据，从而将数据库还原到一个一致性状态。找不到可供使用的 AOF 文件，那么重启之后数据库将是空白的，而空白数据库总是一致的。 隔离性事务的隔离性是指：即时数据库有多个事务并发地执行，各个事务之间也不会互相影响，并且在并发的状态下执行的事务和串行执行事务的结果完全相同。 因为 Redis 使用单线程来执行事务，并且服务器保证，在执行事务期间不会对事务进行中断，因此，Redis 的事务总是以串行的方式进行的，并且事务也总是具有隔离性的。 持久性事务的持久性是指：当一个事务执行完毕时，执行这个事务所获得的结果已经被保存到永久性存储介质（比如硬盘）里面，即时服务器在事务执行完毕之后停机，执行事务所得的结果也不会丢失。 因为 Redis 的事务不过是简单地用队列包裹起了一组 Redis 命令，Redis 并没有为事务提供任何额外的持久化功能，所以 Redis 事务的持久性由 Redis 所使用的持久化模式来决定： 无持久化：事务不具有持久性，一旦服务器停机，包括事务数据在内的所有数据都将丢失。 RDB 持久化：服务器只在特定的保存条件被满足时才会执行 BGSAVE 命令，对数据库进行保存操作，并且异步执行的 BGSAVE 不能保证事务数据第一时间被保存到硬盘里面，因此 RDB 持久模式下的事务也不具有持久性。 AOF 持久化： appendfsync 选项的值为 always 时，程序总会在执行命令之后调用同步（sync）函数，将命令数据真正的保存到池盘里面，这种配置下的事务是具有持久性的。 appendfsync 选项的值为 everysec 时，程序会每秒同步一次命令数据到磁盘。因此停机可能会恰好发生在等待同步的那一秒内，这可能会造成事务数据丢失，所以这种配置下事务不具有持久性。 appendfsync 选项的值为 no 时，程序会交由操作系统来决定何时将命令数据同步到硬盘。因此事务数据可能在等待同步的过程中丢失，所以这种模式下不具有持久性。 不论 Redis 在什么模式下运作，在一个事务的后面加上 SAVE 命令总是可以保证事务的持久性： 123456789101112redis&gt; MULTIOKredis&gt; SET msg &quot;hello&quot;QUEUEDredis&gt; SAVEQUEUEDredis&gt; EXEC1) OK2) OK 不过因为这种做法的效率太低，所以不具有实用性。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/tags/Redis/"}]},{"title":"深入理解 Redis 复制","slug":"更深入理解Redis复制","date":"2021-11-05T01:16:24.000Z","updated":"2022-04-13T13:31:49.009Z","comments":true,"path":"2021/11/05/更深入理解Redis复制/","link":"","permalink":"https://tang7o.cn/2021/11/05/%E6%9B%B4%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis%E5%A4%8D%E5%88%B6/","excerpt":"","text":"为什么主从复制使用 RDB 而不使用 AOF？1、RDB 文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。而 AOF 文件记录的是每一次写操作的命令，写操作越多文件会变的很大，其中还包括很多对同一个 key 的冗余操作。在主从全数据同步时，传输 RDB 文件可以尽量降低对主库机器网络宽带的消耗，从库在加载 RDB 文件时，一是文件小，读取整个文件的速度会很快，二是因为 RDB 文件存储的都是二进制数据，从库直接按照 RDB 协议解析还原数据即可，速度会非常快，而 AOF 需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度比 RDB 会慢很多，所以使用 RDB 进行主从复制。 2、假设要使用 AOF 做全量复制，意味着必须打开 AOF 功能，打开 AOF 就要选择文件刷盘的策略，选择不当会严重影响 Redis 性能，而 RDB 只有在需要定时备份和主从全量复制数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启 AOF 的。 当主服务器不进行持久化时复制的安全性 在进行主从复制设置时，强烈建议在主服务器上开启持久化，当不能这么做时，比如考虑到延迟的问题，应该将实例配置为避免自动重启。 为什么不持久化的主服务器自动重启非常危险呢？为了更好的理解这个问题，看下面这个失败的例子，其中主服务器和从服务器中数据库都被删除了。 我们设置节点 A 为主服务器，关闭持久化，节点 B 和 C 从节点 A 复制数据。 这是出现了一个崩溃，但 Redis 具有自动重启系统，重启了进程，因为关闭了持久化，节点重启后只有一个空的数据集。 节点 B 和 C 从节点 A 进行复制，现在节点 A 是空的，所以节点 B 和 C 上的复制数据也会被删除。 当在高可用系统中使用 Redis Sentinel，关闭主服务器的持久化，并且运行自动重启后，这种情况是很危险的。比如主服务器可能在很短的时间就完成了重启，以至于 Sentinel 都无法检测到这次失败，那么上面说的这种失败的情况就发生了。 如果数据比较重要，并且在使用主从复制时关闭了主服务器持久化功能的场景中，都应该禁止实例自动重启。 为什么还会有从库的从库的设计？通过分析主从库间的第一次数据同步的过程，你可以看到，一次全量复制中，对于主库来说，需要完成两个耗时的操作：生成 RDB 文件和传输 RDB 文件。 如果从库数量过多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量复制。fork 这个操作会阻塞主进程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络宽带，同样会给主库的资源使用带来压力。那么，有没有好的解决方法可用分担主库压力呢？ 其实是有的，这就是“主-从-从”模式。 在刚才的介绍的主从库模式中，所有的从库都是和主库连接，所有的全量复制也都是和主库进行的。现在，我们可用通过“主-从-从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。 简单来说，我们在部署主从集群的时候，可用手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他非从库。然后，我们可用再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，使它们和刚才所选的从库，建立起主从关系。 1replicaof 所选从库的IP 6379 这样一来，从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行了，这样可用减轻主库上的压力，如下图所示： 级联的“主-从-从”模式好了，到这里，我们了解了主从库间通过全量复制实现数据同步的过程，以及通过“主-从-从”模式分担主库压力的方式。那么，一旦主库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可用避免频繁建立连接的开销。 读写分离及其中的问题在主从复制基础上实现的读写分离，可用实现 Redis 的读负载均衡：由主节点提高写服务，由一个或多个从节点提供读服务（多个从节点既可以提高数据冗余程度，也可以最大化读负载能力）；在读负载较大的应用场景下，可用大大提高 Redis 服务器的并发量。下面介绍在使用 Redis 读写分离时，需要注意的问题。 延迟与不一致问题 前面已经讲到，由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过 offset）判断，如果节点延迟过大，通知应用不再通过该节点读取数据；使用集群同步扩展写负载和读复制等。 数据过期问题 在单机 Redis 中，存在两种删除策略： 惰性删除：服务器不会主动删除数据，只有当客户查询某个数据时，服务器判断该数据是否过期，如果过期则删除。 定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和 CPU 的折中（删除会释放内存，但是频繁的删除操作对 CPU 不友好），该删除的频率和执行时间都受到了限制。 在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过 Redis 从节点读取数据时，很容易读到已经过期的数据。 Redis 3.2 中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已经过期，则不返回给客户端； 故障切换问题 在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的 Redis 节点；当主节点或从节点出现问题而发生变更时；需要及时修改应用程序读写 Redis 数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。 总结 在使用读写分离之前，可用考虑其他方法增加 Redis 的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用 Redis 集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主节点的故障切换尽可能自动化，并减少对应用程序的侵入。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/tags/Redis/"}]},{"title":"Redis复制","slug":"Redis复制","date":"2021-11-04T00:57:39.000Z","updated":"2022-04-13T13:31:48.310Z","comments":true,"path":"2021/11/04/Redis复制/","link":"","permalink":"https://tang7o.cn/2021/11/04/Redis%E5%A4%8D%E5%88%B6/","excerpt":"","text":"在 Redis 中，用户可以通过执行 SLAVEOF 命令或者设置 slaveof 选项，让一个服务器去复制另一个服务器，我们称呼被复制的服务器为主服务器，而复制主服务器的服务器被称为从服务器。 命令如下： SLAVEOF host port 复制功能的实现Redis 2.8前Redis 复制功能分为同步（sync）和命令传播（command propagate）两个操作： 同步：将从服务器的数据库状态更新至主服务器的当前所处的数据库状态。 命令传播：在主服务器的数据库状态被修改，导致主从服务器的数据库状态不一致时，让主从服务器的数据库重新回到一致的状态。 同步从服务器对主服务器的同步操作需要通过向主服务器发送 SYNC 命令来完成，以下是 SYNC命令的执行过程： 从服务器向主服务器发送 SYNC 命令。 收到 SYNC 命令的主服务器执行 BGSAVE 命令，在后台生成一个 RDB 文件，并使用一个缓冲区记录从现在开始执行的所有写命令。 当主服务器的 BGSAVE 命令执行完成后，主服务器会将 BGSAVE 命令产生的 RDB 文件发送给从服务器，从服务器接收并载入这个 RDB 文件，将自己的数据库状态更新至主服务器执行 BGSAVE 时的数据库状态。 主服务器将记录在缓冲区中的命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务器当前的数据库状态。 命令传播主服务器会将自己执行的写命令，也即是造成主从服务器不一致的那条写命令，发送给从服务器执行，当从服务器执行来相同的写命令后，主从服务器将再次回到一致状态。 缺陷在 Redis 2.8 以前，从服务器对主服务器的复制可以分为一下两种情况： 初次复制：从服务器以前没有复制过任何服务器，或者从服务器当前要复制的主服务器和上一次复制的主服务器不同。 断线后重复制：处于命令传播阶段的主从服务器因为网络原因而中断了复制，但从服务器通过自动连接重新连上了主服务器，并继续复制主服务器。 在 Redis 2.8 以前，断线后重复制和初次复制使用相同的方法来实现，这就意味着断线后重复制要再次执行一遍 SYNC 命令。这是十分消耗资源的。（断线时间较短时，断线后重复制仅需要复制断线期间的命令即可，完全没有必要重新复制一遍） SYNC 命令是一个十分消耗资源的操作 主服务器需要执行 BGSAVE 命令来生成 RDB 文件，这个命令会消耗主服务器大量的 CPU、内存和磁盘I/O 资源。 主服务器需要将生成的 RDB 文件发送给从服务器，会消耗大量的网络资源，并对主服务器响应命令请求的时间产生影响。 从服务器需要载入 RDB 文件，在载入期间，从服务器会因为阻塞而无法处理命令请求。 Redis 2.8后为了解决旧版复制功能在处理断线后重复制情况时的抵消问题，Redis 从 2.8 版本开始，使用 PSYNC 代替 SYNC 命令来执行复制时的同步操作。 PSYNC 具有完整重同步和部分重同步两种模式： 完整重同步：用于处理初次复制情况，和 SYNC 命令执行步骤基本相同。 部分重同步：用于处理断线后重复制情况，当从服务器段吸纳后重新连接主服务器时，如果条件允许，主服务器可以将断线期间执行的写命令发给从服务器，从服务器只要接收并执行这些命令，就可以将数据库更新至主服务器当前所处的状态。 部分重同步的实现部分重同步功能由以下三个部分构成： 主服务器的复制偏移量和从服务器复制偏移量。 主服务器的复制积压缓冲区。 服务器的运行 ID。 复制偏移量执行复制的双方分别维护一个复制偏移量： 主服务器每次向从服务器传播 N 个字节的数据时，就将自己的复制偏移量 +N。 从服务器每次收到主服务器传来的 N 个字节的数据时，就将自己的复制偏移量 +N。 通过对比主从服务器的复制偏移量，程序可以很容易的知道主从服务器是否处于一致状态： 复制偏移量相同：处于一致状态。 复制偏移量不同：未处于一致状态。 复制积压缓冲区由主服务器维护的一个固定长度的先进先出的队列，默认大小 1MB。 当主服务器进行命令传播时，不仅会将写命令发给所有从服务器还会将写命令入队到复制积压缓冲区。 因此，主服务器的复制积压缓冲区里面会保存着一部分最近传播的写命令，并且复制积压缓冲区会为队列的每个字节记录相应的复制偏移量。 当从服务器重新连上主服务器时，重服务器会通过 PSYNC 命令将自己的复制偏移量 offset 发送给主服务器，主服务器根据这个复制偏移量来决定对从服务器执行何种同步： 如果 offset 复制偏移量之后的数据仍在复制积压缓冲区中，那么执行部分重同步操作（将 offset 偏移量之后的数据发给从服务器）。 否则，执行完整重同步。 可以根据实际情况来调整复制加压缓冲区的大小。 服务器运行 ID除了复制偏移量和复制积压缓冲区外，实现部分重同步还需要用到服务器运行 ID： 每个 Redis 服务器都有自己的运行 ID。 运行 ID 在服务器启动时自动生成，由 40 个随机的十六进制组成。 从服务器对主服务器进行初次复制时，从服务器会将主服务器的运行 ID 保存下来。当从服务器断线并重连上一个服务器时，从服务器会向当前连接的主服务器发送保存的运行 ID: 从服务器保存的运行 ID 和主服务器的运行 ID 相同，尝试执行部分重同步。 相反，从服务器保存的运行 ID 和主服务器的运行 ID 不同，执行完整重同步。 PSYNC 命令的实现PSYNC 命令的调用方法有两种： 如果从服务器之前没有复制过任何主服务器，或者之前执行过 SLAVEOF no one 命令，那么从服务器在开始一次新的复制时将向主服务器发送 PSYNC ? -1 命令，主动请求主服务器进行完整同步。 相反地，如果从服务器已经复制过某个主服务器，那么从服务器在开始一次新的复制时将向主服务器发送 PSYNC &lt;runid&gt; &lt;offset&gt; 命令，其中 runid 是上一次复制的主服务器的运行 ID，offset 是从服务器当前的复制偏移量，接收到这条命令的主服务器将通过这两个参数来判断实现哪种同步操作。 根据情况，接受到 PSYNC 命令的主服务器会向从服务器发送以下三种回复中的其中一种： +FULLRESYNC &lt;runid&gt; &lt;offset&gt;回复：表示主服务器与从服务器执行完整重同步操作：其中 runid 是主服务器的运行 ID，从服务器会将这个 ID 保存起来，在下次发送 PSYNC 命令的时候使用；offset 是主服务器当前的复制偏移量，从服务器会将这个值作为自己的初始化偏移量。 +CONTINUE 回复：表示主服务器将与从服务器进行部分重同步，从服务器只需要等着主服务器将自己缺少的哪部分数据发送过来就可以了。 -ERR 回复：表示主服务器的版本低于 Redis 2.8，它无法识别 PSYNC 命令，从服务器将向主服务器发送 SYNC 命令，并与主服务器执行完整同步。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/tags/Redis/"}]},{"title":"TCP可靠性","slug":"TCP可靠性","date":"2021-10-26T07:34:39.000Z","updated":"2022-04-13T13:31:48.429Z","comments":true,"path":"2021/10/26/TCP可靠性/","link":"","permalink":"https://tang7o.cn/2021/10/26/TCP%E5%8F%AF%E9%9D%A0%E6%80%A7/","excerpt":"","text":"众所周知，TCP 协议传输的特点主要就是面向字节流、传输可靠、面向连接。这篇文章，我们讨论以下 TCP 如何确保传输的可靠性的。 确保传输可靠性的方式TCP 协议保证数据传输可靠性的方式主要有： 校验和 序列号 确认应答 超时重传 连接管理 流量控制 拥塞控制 校验和TCP 检验和的计算与 UDP 一样，在计算时要加上 12byte 的伪首部，检验范围包括 TCP 首部及数据部分，但是 UDP 的检验和字段为可选的，而 TCP 中是必须有的。 计算方法为：在发送方将整个报文段分为多个 16 位的段，然后将所有段进行反码相加，将结果存放在检验和字段中，接收方用相同的方法进行计算，如最终结果为检验字段所有位是全 1 则正确（UDP 中也是全为 1 则正确），否则存在错误。 示例： 为了方便以 4 位为例： 发送端计算： 数据：1000 0100 、校验和：0000 反码：0111 1011 1111 叠加：0111+1011+1111 = 0010 0001，高于 4 位的，叠加到低 4 位 0001 + 0010 = 0011 即为校验和。 接收端计算： 数据：1000 0100 、校验和 0011 反码：0111 1011 1100 叠加：0111+1011+1100 = 0001 1110，高于 4 位的，叠加到低 4 位 0001 + 1110 = 1111。全为1，则正确。 确认应答与序列号序列号：TCP 传输时将每个字节的数据都进行了编号，这就是序列号。 序列号的作用： 保证可靠性（当接收到的数据总少了某个序号的数据时，能马上知道）。 保证数据的按序到达。 提高效率，可实现多次发送，一次确认。 去除重复数据 确认应答：TCP 传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送 ACK 报文。这个 ACK 报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。 超时重传在进行 TCP 传输时，由于确认应答与序列号机制，发送方发送一部分数据后，都会等待接收方发送的 ACK 报文，并且解析报文，判断数据发送是否成功。但是由于一些原因，发送方可能接收不到 ACK 报文： 情况一： 情况二： 重传时间如何确定？ 在 Linux 中，超时以 $500ms$ 为单位进行控制，每次判定超时重发的超时时间都是 $500ms$ 的整数倍。其规律为：如果重发一次仍得不到应答，就等待 $2500ms$ 后再进行重传，如果仍然得不到应答就等待 $4500ms$ 后重传，依次类推，以指数形式递增，重传次数累计到一定次数后，TCP 认为网络或对端主机出现异常，就会强行关闭连接。 连接管理连接管理机制即TCP建立连接时的三次握手和断开连接时的四次挥手。 TCP文章中有详细结束，在此不在赘述。 流量控制接收端处理数据的速度是有限的，如果发送方发送数据的速度过快，超过接收端的处理能力，就会造成丢包，继而引起丢包重传等一系列反应。 因此 TCP 支持根据接收端的处理能力，来决定发送端的发送速度，这个机制叫做流量控制。 在 TCP 报文段首部中有一个 16 位窗口长度，当接收端接收到发送方的数据后，在应答报文 ACK 中就将自身缓冲区的剩余大小，放入 16 窗口大小中。这个大小随数据传输情况而变，窗口越大，网络吞吐量越高，而一旦接收方发现自身的缓冲区快满了，就将窗口设置为更小的值通知发送方。如果缓冲区满，就将窗口置为 0，发送方收到后就不再发送数据，但是需要定期发送一个窗口探测数据段，使接收端把窗口大小告诉发送端。 注意：窗口大小不完全受 16 位窗口大小限制，在TCP首部 40 字节选项中还包含一个窗口扩大因子 M，实际窗口大小是窗口字段的值左移 M 位。 拥塞控制TCP 传输的过程中，发送端开始发送数据的时候，如果刚开始就发送大量的数据，那么就可能造成一些问题。网络可能在开始的时候就很拥堵，如果给网络中在扔出大量数据，那么这个拥堵就会加剧。拥堵的加剧就会产生大量的丢包，就对大量的超时重传，严重影响传输。 因此 TCP 引入了慢启动的机制，在开始发送数据的时候，先发送少量的数据探路，探清当前网络拥堵的状态后，在决定按照多大的数度发送数据。这时候引入了一个叫做拥塞窗口（cwnd）的概念。每次收到一个 ACK 应答，拥塞窗口加1，在发送数据之前，首先将拥塞窗口与接收端反馈的窗口大小比对，取较小的值作为实际发送的窗口。 TCP 的四种拥塞控制算法： 慢开始 拥塞避免 快重传 快恢复 慢开始假设当前发送方拥塞窗口 cwnd 的值为 1，发送方当前发送一个数据报文段，接收方收到该数据报文段后，给发送方回复一个确认报文段，发送方收到该确认报文后，将拥塞窗口的值变为 2，发送方此时可以连续发送两个数据报文段，接收方收到该数据报文段后，给发送方返回 2 个确认报文段，发送方收到这两个确认报文后，将拥塞窗口的值加 2 变为 4，发送方此时可连续发送 4 个报文段，接收方收到 4 个报文段后，给发送方回复 4 个确认报文，发送方收到确认报文后，将拥塞窗口的值加 4 变为 8，发送方此时可以连续发送 8 个数据报文段… 当前的拥塞窗口 cwnd 的值已经等于慢开始门限值 ssthresh，之后改用拥塞避免算法。 拥塞避免此时每个传输轮次，拥塞窗口 cwnd 只能线性加一，而不是像慢开始算法时，每个传输轮次，拥塞窗口 cwnd 按指数增长。同理：16+1… 直至到达 24，假设 24 个报文段在传输过程中丢失 4 个，接收方只收到 20 个报文段，给发送方依次回复 20 个确认报文段，一段时间后，丢失的 4 个报文段的重传计时器超时了，发送发判断可能出现拥塞，更改 $ssthresh = cwnd / 2、cwnd = 1$ 并重新开始慢开始算法。 快重传 快重传算法规定，发送方只要一连收到三个重复确认（一共是四个，第一个 ACK 2 是正常的）就应当立即重传对方尚未收到的报文段 2，而不必继续等待为 2 设置的重传计时器到期进行超时重传。 因为超时重传需要重新开始慢启动算法，cwnd 重置未 1，太影响效率。 为什么是三个重复确认？ 快恢复与快重传配合使用： 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把慢开始门限 ssthresh 减半。这是为了预防网络发生拥塞。请注意，接下去不执行慢开始算法。 由于发送方现在认为网络很可能没有发生拥塞（如果网络发生了严重的拥塞，就不会一连有好几个报文段连续到达接收方，也就不会导致接收方连续发送重复确认），因此与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口 cwnd 现在不设置为 1），而是$cwnd = cwnd/2、sshthresh = cwnd$，然后开始执行拥塞避免算法，使拥塞窗口缓慢地线性增大。 上图给出了快重传和快恢复的示意图，并标明了“TCP Reno版本”，这是目前使用得很广泛的版本。 图中还画出了已经废弃不用的虚线部分（TCP Tahoe 版本）。请注意它们的区别就是：新的 TCP Reno 版本在快重传之后采用快恢复算法而不是采用慢开始算法。 参考文章： TCP可靠性的保证机制总结 TCP 面试系列之快重传与快恢复 TCP的快速重传机制","categories":[{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"},{"name":"TCP","slug":"网络/TCP","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/TCP/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://tang7o.cn/tags/TCP/"}]},{"title":"CAS","slug":"CAS","date":"2021-10-23T07:03:59.000Z","updated":"2022-04-13T13:31:47.951Z","comments":true,"path":"2021/10/23/CAS/","link":"","permalink":"https://tang7o.cn/2021/10/23/CAS/","excerpt":"","text":"什么是CASCAS 的全称为 Compare-And-Swap，直译就是对比交换。是一条 CPU 的原子指令，其作用是让 CPU 先进行比较两个值是否相等，然后原子地更新某个位置的值，经过调查发现，其实现方式是基于硬件平台的汇编指令，就是说 CAS 是靠硬件实现的，JVM 只是封装了汇编调用，那些 AtomicInteger 类便是使用了这些封装后的接口。 简单解释：CAS 操作需要输入两个数值，一个旧值（期望操作前的值）和一个新值，在操作期间先比较下在旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。 CAS 操作是原子性的，所以多线程并发使用 CAS 更新数据时，可以不使用锁。JDK 中大量使用了CAS 来更新数据而防止加锁（synchronized 重量级锁）来保持原子更新。 相信 sql 大家都熟悉，类似 sql 中的条件更新一样：update set id=3 from table where id=2。因为单条 sql 执行具有原子性，如果有多个线程同时执行此 sql 语句，只有一条能更新成功。 CAS使用示例如果不使用 CAS，在高并发下，多线程同时修改一个变量的值我们需要 synchronized 加锁（可能有人说可以用 Lock 加锁，Lock 底层的 AQS 也是基于 CAS 进行获取锁的）。 123456public class Test &#123; private int i=0; public synchronized int add()&#123; return i++; &#125;&#125; java 中为我们提供了 AtomicInteger 原子类（底层基于 CAS 进行更新数据的），不需要加锁就在多线程并发场景下实现数据的一致性。 123456public class Test &#123; private AtomicInteger i = new AtomicInteger(0); public int add()&#123; return i.addAndGet(1); &#125;&#125; CAS 问题CAS 方式为乐观锁，synchronized 为悲观锁。因此使用 CAS 解决并发问题通常情况下性能更优。 但使用 CAS 方式也会有几个问题： ABA 问题因为 CAS 需要在操作值的时候，检查值有没有发生变化，比如没有发生变化则更新，但是如果一个值原来是 A，变成了 B，又变成了 A，那么使用 CAS 进行检查时则会发现它的值没有发生变化，但是实际上却变化了。 ABA 问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加 1，那么 A-&gt;B-&gt;A 就会变成 1A-&gt;2B-&gt;3A。 从 Java 1.5 开始，JDK 的 Atomic 包里提供了一个类 AtomicStampedReference 来解决 ABA 问题。这个类的 compareAndSet 方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 循环时间长开销大自旋 CAS 如果长时间不成功，会给 CPU 带来非常大的执行开销。如果 JVM 能支持处理器提供的 pause 指令，那么效率会有一定的提升。pause 指令有两个作用：第一，它可以延迟流水线执行命令（de-pipeline），使 CPU 不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零；第二，它可以避免在退出循环的时候因内存顺序冲突（Memory Order Violation）而引起 CPU 流水线被清空（CPU Pipeline Flush），从而提高 CPU 的执行效率。 只能保证一个共享变量的原子操作当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个共享变量操作时，循环 CAS 就无法保证操作的原子性，这个时候就可以用锁。 还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量 i = 2，j = a，合并一下 ij = 2a，然后用 CAS 来操作 ij。 从Java 1.5开始，JDK 提供了 AtomicReference 类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行 CAS 操作。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://tang7o.cn/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://tang7o.cn/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"FutureTask","slug":"FutureTask","date":"2021-10-20T10:41:06.000Z","updated":"2022-04-13T13:31:47.997Z","comments":true,"path":"2021/10/20/FutureTask/","link":"","permalink":"https://tang7o.cn/2021/10/20/FutureTask/","excerpt":"","text":"FutureTask 简介FutureTask 为 Future 提供了基础实现，如获取任务执行结果(get)和取消任务(cancel)等。如果任务尚未完成，获取任务执行结果时将会阻塞。一旦执行结束，任务就不能被重启或取消(除非使用runAndReset执行计算)。FutureTask 常用来封装 Callable 和 Runnable，也可以作为一个任务提交到线程池中执行。除了作为一个独立的类之外，此类也提供了一些功能性函数供我们创建自定义 task 类使用。FutureTask 的线程安全由CAS来保证。 FutureTask 类关系 可以看到,FutureTask 实现了 RunnableFuture 接口，则 RunnableFuture 接口继承了 Runnable 接口和 Future 接口，所以 FutureTask 既能当做一个 Runnable 直接被 Thread 执行，也能作为 Future 用来得到 Callable 的计算结果。 FutureTask 源码解析Callable 接口Callable 是个泛型接口，泛型 V 就是要 call() 方法返回的类型。对比 Runnable 接口，Runnable 不会返回数据也不能抛出异常。 123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; Future 接口Future 接口代表异步计算的结果，通过 Future 接口提供的方法可以查看异步计算是否执行完成，或者等待执行结果并获取执行结果，同时还可以取消执行。Future 接口的定义如下: 12345678public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; cancel():cancel() 方法用来取消异步任务的执行。如果异步任务已经完成或者已经被取消，或者由于某些原因不能取消，则会返回 false。如果任务还没有被执行，则会返回 true 并且异步任务不会被执行。如果任务已经开始执行了但是还没有执行完成，若 mayInterruptIfRunning 为 true，则会立即中断执行任务的线程并返回 true，若 mayInterruptIfRunning 为 false，则会返回 true 且不会中断任务执行线程。 isCanceled():判断任务是否被取消，如果任务在结束（正常执行结束或者执行异常结束）前被取消则返回 true，否则返回 false。 isDone():判断任务是否已经完成，如果完成则返回 true，否则返回 false。需要注意的是：任务执行过程中发生异常、任务被取消也属于任务已完成，也会返回 true。 get():获取任务执行结果，如果任务还没完成则会阻塞等待直到任务执行完成。如果任务被取消则会抛出 CancellationException 异常，如果任务执行过程发生异常则会抛出 ExecutionException 异常，如果阻塞等待过程中被中断则会抛出 InterruptedException 异常。 get(long timeout,Timeunit unit):带超时时间的 get() 版本，如果阻塞等待过程中超时则会抛出 TimeoutException 异常。 核心属性12345678910111213141516171819202122//内部持有的callable任务，运行完毕后置空private Callable&lt;V&gt; callable;//从get()中返回的结果或抛出的异常private Object outcome; // non-volatile, protected by state reads/writes//运行callable的线程private volatile Thread runner;//使用Treiber栈保存等待线程private volatile WaitNode waiters;//任务状态private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; 其中需要注意的是 state 是 volatile 类型的，也就是说只要有任何一个线程修改了这个变量，那么其他所有的线程都会知道最新的值。7 种状态具体表示： NEW：表示是个新的任务或者还没被执行完的任务。这是初始状态。 COMPLETING：任务已经执行完成或者执行任务的时候发生异常，但是任务执行结果或者异常原因还没有保存到 outcome 字段（outcome 字段用来保存任务执行结果，如果发生异常，则用来保存异常原因）的时候，状态会从 NEW 变更到 COMPLETING。但是这个状态会时间会比较短，属于中间状态。 NORMAL：任务已经执行完成并且任务执行结果已经保存到 outcome 字段，状态会从 COMPLETING 转换到 NORMAL。这是一个最终态。 EXCEPTIONAL：任务执行发生异常并且异常原因已经保存到 outcome 字段中后，状态会从 COMPLETING 转换到 EXCEPTIONAL。这是一个最终态。 CANCELLED：任务还没开始执行或者已经开始执行但是还没有执行完成的时候，用户调用了 cancel（false）方法取消任务且不中断任务执行线程，这个时候状态会从NEW转化为 CANCELLED 状态。这是一个最终态。 INTERRUPTING：任务还没开始执行或者已经执行但是还没有执行完成的时候，用户调用了 cancel（true）方法取消任务并且要中断任务执行线程但是还没有中断任务执行线程之前，状态会从 NEW 转化为 INTERRUPTING。这是一个中间状态。 INTERRUPTED：调用 interrupt() 中断任务执行线程之后状态会从 INTERRUPTING 转换到 INTERRUPTED。这是一个最终态。 有一点需要注意的是，所有值大于 COMPLETING 的状态都表示任务已经执行完成（任务正常执行完成，任务执行异常或者任务被取消）。 各个状态之间的可能转换关系如下图所示: 构造函数 FutureTask(Callable callable) 123456public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125; 这个构造函数会把传入的 Callable 变量保存在 this.callable 字段中，该字段定义为 private Callable&lt;V&gt; callable;用来保存底层的调用，在被执行完成以后会指向 null,接着会初始化 state 字段为 NEW。 public FutureTask(Runnable runnable, V result) 1234public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable&#125; 这个构造函数会把传入的 Runnable 封装成一个 Callable 对象保存在 callable 字段中，同时如果任务执行成功的话就会返回传入的 result。这种情况下如果不需要返回值的话可以传入一个 null。 顺带看下 Executors.callable() 这个方法，这个方法的功能是把 Runnable 转换成 Callable，代码如下: 12345public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result);&#125; 可以看到这里采用的是适配器模式，调用RunnableAdapter&lt;T&gt;(task, result)方法来适配，实现如下: 123456789101112static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; &#123; final Runnable task; final T result; RunnableAdapter(Runnable task, T result) &#123; this.task = task; this.result = result; &#125; public T call() &#123; task.run(); return result; &#125;&#125; 这个适配器很简单，就是简单的实现了 Callable 接口，在 call() 实现中调用 Runnable.run() 方法，然后把传入的 result 作为任务的结果返回。 在 new 了一个 FutureTask 对象之后，接下来就是在另一个线程中执行这个 Task,无论是通过直接new 一个 Thread 还是通过线程池，执行的都是 run() 方法，接下来就看看 run() 方法的实现。 核心方法 - run()123456789101112131415161718192021222324252627282930313233public void run() &#123; //新建任务，CAS替换runner为当前线程 if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); &#125; if (ran) set(result);//设置执行结果 &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s);//处理中断逻辑 &#125;&#125; 说明： 运行任务，如果任务状态为 NEW 状态，则利用 CAS 修改为当前线程。执行完毕调用 set(result) 方法设置执行结果。set(result) 源码如下： 1234567protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state finishCompletion();//执行完毕，唤醒等待线程 &#125;&#125; 首先利用 cas 修改 state 状态为 COMPLETING，设置返回结果，然后使用 lazySet(UNSAFE.putOrderedInt) 的方式设置 state 状态为 NORMAL。结果设置完毕后，调用 finishCompletion() 方法唤醒等待线程，源码如下： 123456789101112131415161718192021222324private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123;//移除等待线程 for (;;) &#123;//自旋遍历等待线程 Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t);//唤醒等待线程 &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; //任务完成后调用函数，自定义扩展 done(); callable = null; // to reduce footprint&#125; 回到 run 方法，如果在 run 期间被中断，此时需要调用 handlePossibleCancellationInterrupt 方法来处理中断逻辑，确保任何中断(例如cancel(true))只停留在当前 run 或 runAndReset 的任务中，源码如下： 123456private void handlePossibleCancellationInterrupt(int s) &#123; //在中断者中断线程之前可能会延迟，所以我们只需要让出CPU时间片自旋等待 if (s == INTERRUPTING) while (state == INTERRUPTING) Thread.yield(); // wait out pending interrupt&#125; 核心方法 - get()1234567//获取执行结果public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125; 说明：FutureTask 通过 get() 方法获取任务执行结果。如果任务处于未完成的状态(state &lt;= COMPLETING)，就调用 awaitDone 方法(后面单独讲解)等待任务完成。任务完成后，通过 report 方法获取执行结果或抛出执行期间的异常。report 源码如下： 123456789//返回执行结果或抛出异常private V report(int s) throws ExecutionException &#123; Object x = outcome; if (s == NORMAL) return (V)x; if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x);&#125; 核心方法 - awaitDone(boolean timed, long nanos)12345678910111213141516171819202122232425262728293031323334353637private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123;//自旋 if (Thread.interrupted()) &#123;//获取并清除中断状态 removeWaiter(q);//移除等待WaitNode throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null;//置空等待节点的线程 return s; &#125; else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) //CAS修改waiter queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q);//超时，移除等待节点 return state; &#125; LockSupport.parkNanos(this, nanos);//阻塞当前线程 &#125; else LockSupport.park(this);//阻塞当前线程 &#125;&#125; 说明：awaitDone 用于等待任务完成，或任务因为中断或超时而终止。返回任务的完成状态。函数执行逻辑如下： 如果线程被中断，首先清除中断状态，调用 removeWaiter 移除等待节点，然后抛出 InterruptedException。removeWaiter 源码如下： 12345678910111213141516171819202122private void removeWaiter(WaitNode node) &#123; if (node != null) &#123; node.thread = null;//首先置空线程 retry: for (;;) &#123; // restart on removeWaiter race //依次遍历查找 for (WaitNode pred = null, q = waiters, s; q != null; q = s) &#123; s = q.next; if (q.thread != null) pred = q; else if (pred != null) &#123; pred.next = s; if (pred.thread == null) // check for race continue retry; &#125; else if (!UNSAFE.compareAndSwapObject(this, waitersOffset,q, s)) //cas替换 continue retry; &#125; break; &#125; &#125;&#125; 如果当前状态为结束状态(state &gt; COMPLETING),则根据需要置空等待节点的线程，并返回 Future 状态； 如果当前状态为正在完成(COMPLETING)，说明此时 Future 还不能做出超时动作，为任务让出 CPU 执行时间片； 如果 state 为 NEW，先新建一个 WaitNode，然后 CAS 修改当前 waiters； 如果等待超时，则调用 removeWaiter 移除等待节点，返回任务状态；如果设置了超时时间但是尚未超时，则park阻塞当前线程； 其他情况直接阻塞当前线程。 核心方法 - cancel(boolean mayInterruptIfRunning)123456789101112131415161718192021public boolean cancel(boolean mayInterruptIfRunning) &#123; //如果当前Future状态为NEW，根据参数修改Future状态为INTERRUPTING或CANCELLED if (!(state == NEW &amp;&amp; UNSAFE.compareAndSwapInt(this, stateOffset, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) return false; try &#123; // in case call to interrupt throws exception if (mayInterruptIfRunning) &#123;//可以在运行时中断 try &#123; Thread t = runner; if (t != null) t.interrupt(); &#125; finally &#123; // final state UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); &#125; &#125; &#125; finally &#123; finishCompletion();//移除并唤醒所有等待线程 &#125; return true;&#125; 说明：尝试取消任务。如果任务已经完成或已经被取消，此操作会失败。 如果当前 Future 状态为 NEW，根据参数修改 Future 状态为 INTERRUPTING 或 CANCELLED。 如果当前状态不为 NEW，则根据参数 mayInterruptIfRunning 决定是否在任务运行中也可以中断。中断操作完成后，调用 finishCompletion 移除并唤醒所有等待线程。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://tang7o.cn/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://tang7o.cn/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"线程池 ThreadPoolExecutor 详解","slug":"Executors","date":"2021-10-18T01:47:33.000Z","updated":"2022-04-13T13:31:47.982Z","comments":true,"path":"2021/10/18/Executors/","link":"","permalink":"https://tang7o.cn/2021/10/18/Executors/","excerpt":"","text":"为什么要有线程池线程池能够对线程进行统一分配，调优和监控: 降低资源消耗（线程无限制地创建，然后使用完毕后销毁） 提高响应速度（无须创建线程） 提高线程的可管理性 ThreadPoolExecutor 使用详解其实 java 线程池的实现原理很简单，说白了就是一个线程集合 workerSet 和一个阻塞队列 workQueue。当用户向线程池提交一个任务（也就是线程）时，线程池会先将任务放入 workQueue 中。workerSet 中的线程会不断的从 workQueue 中获取线程然后执行。当 workQueue 中没有任务的时候，worker 就会阻塞，直到队列中有任务了就取出来继续执行。 Execute 原理当一个任务提交至线程池之后: 线程池首先当前运行的线程数量是否少于 corePoolSize。如果是，则创建一个新的工作线程来执行任务。如果都在执行任务，则进入 2。 判断 BlockingQueue 是否已经满了，倘若还没有满，则将线程放入 BlockingQueue。否则进入 3。 如果创建一个新的工作线程将使当前运行的线程数量超过 maximumPoolSize ，则交给 RejectedExecutionHandler 来处理任务，否则创建一个新的线程来执行任务。 当 ThreadPoolExecutor 创建新线程时，通过 CAS 来更新线程池的状态 ctl. 参数123456public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) corePoolSize 线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于 corePoolSize。如果当前线程数为 corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；如果执行了线程池的 prestartAllCoreThreads() 方法，线程池会提前创建并启动所有核心线程。 workQueue 用来保存等待被执行的任务的阻塞队列. 在 JDK 中提供了如下阻塞队列: ArrayBlockingQueue: 基于数组结构的有界阻塞队列，按 FIFO 排序任务； LinkedBlockingQuene: 基于链表结构的阻塞队列，按 FIFO 排序任务，吞吐量通常要高于 ArrayBlockingQuene； SynchronousQuene: 一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于 LinkedBlockingQuene； PriorityBlockingQuene: 具有优先级的无界阻塞队列； LinkedBlockingQueue 比 ArrayBlockingQueue 在插入删除节点性能方面更优，但是二者在 put(), take() 任务的时均需要加锁，SynchronousQueue 使用无锁算法，根据节点的状态判断执行，而不需要用到锁，其核心是 Transfer.transfer(). maximumPoolSize 线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于 maximumPoolSize；当阻塞队列是无界队列，maximumPoolSize 则不起作用, 因为无法提交至核心线程池的线程会一直持续地放入 workQueue. keepAliveTime 线程空闲时的存活时间，即当线程没有任务执行时，该线程继续存活的时间；默认情况下，该参数只在线程数大于 corePoolSize 时才有用，超过这个时间的空闲线程将被终止； unit keepAliveTime 的单位。 threadFactory 创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名。默认为 DefaultThreadFactory。 handler 线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略： AbortPolicy：直接抛出异常，默认策略； CallerRunsPolicy：用调用者所在的线程来执行任务； DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务； DiscardPolicy：直接丢弃任务； 当然也可以根据应用场景实现 RejectedExecutionHandler 接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。 三种类型newFixedThreadPool12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 线程池的线程数量达 corePoolSize 后，即使线程池没有可执行任务时，也不会释放线程。 FixedThreadPool 的工作队列为无界队列 LinkedBlockingQueue （队列容量为 Integer.MAX_VALUE）, 这会导致以下问题: 线程池里的线程数量不超过 corePoolSize,这导致了 maximumPoolSize 和 keepAliveTime 将会是个无用参数。 由于使用了无界队列, 所以 FixedThreadPool 永远不会拒绝, 即饱和策略失效。 newSingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 初始化的线程池中只有一个线程，如果该线程异常结束，会重新创建一个新的线程继续执行任务，唯一的线程可以保证所提交任务的顺序执行。 由于使用了无界队列，所以 SingleThreadPool 永远不会拒绝，即饱和策略失效。 newCachedThreadPool12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 线程池的线程数可达到 Integer.MAX_VALUE，即 2147483647，内部使用 SynchronousQueue 作为阻塞队列；和 newFixedThreadPool 创建的线程池不同， newCachedThreadPool 在没有任务执行时，当线程的空闲时间超过 keepAliveTime，会自动释放线程资源，当提交新任务时，如果没有空闲线程，则创建新线程执行任务，会导致一定的系统开销；执行过程与前两种稍微不同: 主线程调用 SynchronousQueue 的 offer() 方法放入 task，倘若此时线程池中有空闲的线程尝试读取 SynchronousQueue 的 task，即调用了 SynchronousQueue 的 poll()，那么主线程将该 task 交给空闲线程. 否则执行 2。 当线程池为空或者没有空闲的线程，则创建新的线程执行任务。 执行完任务的线程倘若在 60s 内仍空闲，则会被终止。因此长时间空闲的 CachedThreadPool 不会持有任何线程资源。 关闭线程池遍历线程池中的所有线程，然后逐个调用线程的 interrupt 方法来中断线程. 关闭方式 - shutdown将线程池里的线程状态设置成 SHUTDOWN 状态，然后中断所有没有正在执行任务的线程。 关闭方式 - shutdownNow将线程池里的线程状态设置成STOP状态，然后停止所有正在执行或暂停任务的线程。只要调用这两个关闭方法中的任意一个，isShutDown() 返回 true。当所有任务都成功关闭了， isTerminated() 返回true。 ThreadPoolExecutor 源码详解几个关键属性1234567891011121314151617//这个属性是用来存放 当前运行的 worker 数量以及线程池状态的//int是 32 位的，这里把 int 的高 3 位拿来充当线程池状态的标志位,后 29 位拿来充当当前运行 worker 的数量private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));//存放任务的阻塞队列private final BlockingQueue&lt;Runnable&gt; workQueue;//worker的集合,用set来存放private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;();//历史达到的worker数最大值private int largestPoolSize;//当队列满了并且worker的数量达到maxSize的时候,执行具体的拒绝策略private volatile RejectedExecutionHandler handler;//超出coreSize的worker的生存时间private volatile long keepAliveTime;//常驻worker的数量private volatile int corePoolSize;//最大worker的数量,一般当workQueue满了才会用到这个参数private volatile int maximumPoolSize; 内部状态123456789101112131415private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// Packing and unpacking ctlprivate static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 其中 AtomicInteger 变量 ctl 的功能非常强大: 利用低29位表示线程池中线程数，通过高3位表示线程池的运行状态: RUNNING: -1 &lt;&lt; COUNT_BITS，即高3位为111，该状态的线程池会接收新任务，并处理阻塞队列中的任务； SHUTDOWN: 0 &lt;&lt; COUNT_BITS，即高3位为000，该状态的线程池不会接收新任务，但会处理阻塞队列中的任务； STOP : 1 &lt;&lt; COUNT_BITS，即高3位为001，该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务； TIDYING : 2 &lt;&lt; COUNT_BITS，即高3位为010, 所有的任务都已经终止； TERMINATED: 3 &lt;&lt; COUNT_BITS，即高3位为011, terminated() 方法已经执行完成 任务的执行 execute –&gt; addWorker –&gt;runworker (getTask) 线程池的工作线程通过 Woker 类实现，在 ReentrantLock 锁的保证下，把 Woker 实例插入到 HashSet 后，并启动 Woker 中的线程。 从 Woker 类的构造方法实现可以发现: 线程工厂在创建线程 thread 时，将 Woker 实例本身 this 作为参数传入，当执行 start 方法启动线程 thread 时，本质是执行了 Worker 的 runWorker 方法。 firstTask 执行完成之后，通过 getTask 方法从阻塞队列中获取等待的任务，如果队列中没有任务，getTask 方法会被阻塞并挂起，不会占用 cpu 资源； execute 方法ThreadPoolExecutor.execute(task) 实现了 Executor.execute(task)。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&#x27;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; //workerCountOf获取线程池的当前线程数；小于corePoolSize，执行addWorker创建新线程执行command任务 if (addWorker(command, true)) return; c = ctl.get(); &#125; // double check: c, recheck // 线程池处于RUNNING状态，把提交的任务成功放入阻塞队列中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // recheck and if necessary 回滚到入队操作前，即倘若线程池shutdown状态，就remove(command) //如果线程池没有RUNNING，成功从阻塞队列中删除任务，执行reject方法处理任务 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //线程池处于running状态，但是没有线程，则创建线程 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 往线程池中创建新的线程失败，则reject任务 else if (!addWorker(command, false)) reject(command);&#125; 为什么需要 double check 线程池的状态? 在多线程环境下，线程池的状态时刻在变化，而 ctl.get() 是非原子操作，很有可能刚获取了线程池状态后线程池状态就改变了。判断是否将 command 加入 workque 是线程池之前的状态。倘若没有 double check，万一线程池处于非 running 状态(在多线程环境下很有可能发生)，那么 command 永远不会执行。 addWorker 方法从方法 execute 的实现可以看出: addWorker 主要负责创建新的线程并执行任务，线程池创建新线程执行任务时，需要获取全局锁: 1private final ReentrantLock mainLock = new ReentrantLock(); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768private boolean addWorker(Runnable firstTask, boolean core) &#123; // CAS更新线程池数量 retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; // 线程池重入锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); // 线程启动，执行任务(Worker.thread(firstTask).start()); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; Worker 类的 runworker 方法123456789101112private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); // 创建线程 &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; // ...&#125; 继承了 AQS 类，可以方便的实现工作线程的中止操作； 实现了 Runnable 接口，可以将自身作为一个任务在工作线程中执行； 当前提交的任务 firstTask 作为参数传入 Worker 的构造方法； 一些属性还有构造方法: 12345678910111213//运行的线程,前面addWorker方法中就是直接通过启动这个线程来启动这个workerfinal Thread thread;//当一个worker刚创建的时候,就先尝试执行这个任务Runnable firstTask;//记录完成任务的数量volatile long completedTasks;Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; //创建一个Thread,将自己设置给他,后面这个thread启动的时候,也就是执行worker的run方法 this.thread = getThreadFactory().newThread(this);&#125; runWorker 方法是线程池的核心: 线程启动之后，通过 unlock 方法释放锁，设置 AQS 的 state 为 0，表示运行可中断； Worker 执行 firstTask 或从 workQueue 中获取任务: 进行加锁操作，保证 thread 不被其他线程中断(除非线程池被中断) 检查线程池状态，倘若线程池处于中断状态，当前线程将中断。 执行 beforeExecute 执行任务的 run 方法 执行 afterExecute 方法 解锁操作 通过 getTask 方法从阻塞队列中获取等待的任务，如果队列中没有任务，getTask 方法会被阻塞并挂起，不会占用 cpu 资源； 123456789101112131415161718192021222324252627282930313233343536373839404142434445final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 先执行firstTask，再从workerQueue中取task(getTask()) while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; getTask 方法下面来看一下 getTask() 方法，这里面涉及到 keepAliveTime 的使用，从这个方法我们可以看出先吃池是怎么让超过 corePoolSize 的那部分 worker 销毁的。 12345678910111213141516171819202122232425262728293031323334353637private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 注意这里一段代码是 keepAliveTime 起作用的关键: 1234boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); allowCoreThreadTimeOut 为 false，线程即使空闲也不会被销毁；倘若为 ture，在 keepAliveTime 内仍空闲则会被销毁。 如果线程允许空闲等待而不被销毁 timed == false，workQueue.take 任务: 如果阻塞队列为空，当前线程会被挂起等待；当队列中有任务加入时，线程被唤醒，take 方法返回任务，并执行； 如果线程不允许无休止空闲 timed == true, workQueue.poll 任务: 如果在 keepAliveTime 时间内，阻塞队列还是没有任务，则返回 null； 任务的提交 submit 任务，等待线程池 execute。 执行 FutureTask 类的 get 方法时，会把主线程封装成 WaitNode 节点并保存在 waiters 链表中，并阻塞等待运行结果； FutureTask 任务执行完成后，通过 UNSAFE 设置 waiters 相应的 waitNode 为 null，并通过 LockSupport 类unpark 方法唤醒主线程； 1234567891011121314151617181920212223public class Test&#123; public static void main(String[] args) &#123; ExecutorService es = Executors.newCachedThreadPool(); Future&lt;String&gt; future = es.submit(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return &quot;future result&quot;; &#125; &#125;); try &#123; String result = future.get(); System.out.println(result); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 在实际业务场景中，Future 和 Callable 基本是成对出现的，Callable 负责产生结果，Future 负责获取结果。 Callable 接口类似于 Runnable，只是 Runnable 没有返回值。 Callable 任务除了返回正常结果之外，如果发生异常，该异常也会被返回，即 Future 可以拿到异步执行任务各种结果； Future.get 方法会导致主线程阻塞，直到 Callable 任务执行完成； submit方法AbstractExecutorService.submit() 实现了 ExecutorService.submit() 可以获取执行完的返回值, 而 ThreadPoolExecutor 是 AbstractExecutorService.submit() 的子类，所以 submit 方法也是 ThreadPoolExecutor 的方法。 123456// submit()在ExecutorService中的定义&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task); 12345678// submit方法在AbstractExecutorService中的实现public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); // 通过submit方法提交的Callable任务会被封装成了一个FutureTask对象。 RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125; 通过 submit 方法提交的 Callable 任务会被封装成了一个 FutureTask 对象。通过 Executor.execute() 方法提交 FutureTask 到线程池中等待被执行，最终执行的是 FutureTask 的run方法； FutureTask对象public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 可以将 FutureTask 提交至线程池中等待被执行(通过 FutureTask 的 run 方法来执行) 内部状态 12345678910111213141516/* The run state of this task, initially NEW. * ... * Possible state transitions: * NEW -&gt; COMPLETING -&gt; NORMAL * NEW -&gt; COMPLETING -&gt; EXCEPTIONAL * NEW -&gt; CANCELLED * NEW -&gt; INTERRUPTING -&gt; INTERRUPTED */private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; 内部状态的修改通过 sun.misc.Unsafe 修改。 get 方法 123456public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125; 内部通过 awaitDone 方法对主线程进行阻塞，具体实现如下: 1234567891011121314151617181920212223242526272829303132333435private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) queued = UNSAFE.compareAndSwapObject(this, waitersOffset,q.next = waiters, q); else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; LockSupport.parkNanos(this, nanos); &#125; else LockSupport.park(this); &#125;&#125; 如果主线程被中断，则抛出中断异常； 判断 FutureTask 当前的 state，如果大于 COMPLETING，说明任务已经执行完成，则直接返回； 如果当前 state 等于 COMPLETING，说明任务已经执行完，这时主线程只需通过 yield 方法让出 cpu 资源，等待 state 变成 NORMAL； 通过 WaitNode 类封装当前线程，并通过 UNSAFE 添加到 waiters 链表； 最终通过 LockSupport 的 park 或 parkNanos 挂起线程； run 方法 123456789101112131415161718192021222324252627282930public void run() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); &#125; if (ran) set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125; FutureTask.run 方法是在线程池中被执行的，而非主线程 通过执行 Callable 任务的 call 方法； 如果 call 执行成功，则通过 set 方法保存结果； 如果 call 执行有异常，则通过 setException 保存异常； 任务的关闭shutdown 方法会将线程池的状态设置为 SHUTDOWN,线程池进入这个状态后,就拒绝再接受任务,然后会将剩余的任务全部执行完。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //检查是否可以关闭线程 checkShutdownAccess(); //设置线程池状态 advanceRunState(SHUTDOWN); //尝试中断worker interruptIdleWorkers(); //预留方法,留给子类实现 onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate();&#125;private void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //遍历所有的worker for (Worker w : workers) &#123; Thread t = w.thread; //先尝试调用w.tryLock(),如果获取到锁,就说明worker是空闲的,就可以直接中断它 //注意的是,worker自己本身实现了AQS同步框架,然后实现的类似锁的功能 //它实现的锁是不可重入的,所以如果worker在执行任务的时候,会先进行加锁,这里tryLock()就会返回false if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125; shutdownNow 做的比较绝，它先将线程池状态设置为 STOP，然后拒绝所有提交的任务。最后中断左右正在运行中的 worker ,然后清空任务队列。 123456789101112131415161718192021222324252627282930public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); //检测权限 advanceRunState(STOP); //中断所有的worker interruptWorkers(); //清空任务队列 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks;&#125;private void interruptWorkers() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //遍历所有worker，然后调用中断方法 for (Worker w : workers) w.interruptIfStarted(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 更深入理解为什么线程池不允许使用Executors去创建? 推荐方式是什么?线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明：Executors 各个方法的弊端： newFixedThreadPool 和 newSingleThreadExecutor：主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至 OOM 。 newCachedThreadPool 和 newScheduledThreadPool：主要问题是线程数最大数是 Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至 OOM。 推荐方式 1首先引入：commons-lang3 包。 12ScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(&quot;example-schedule-pool-%d&quot;).daemon(true).build()); 推荐方式 2首先引入：com.google.guava 包。 12345678910ThreadFactory namedThreadFactory = new ThreadFactoryBuilder().setNameFormat(&quot;demo-pool-%d&quot;).build();//Common Thread PoolExecutorService pool = new ThreadPoolExecutor(5, 200, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());// excutepool.execute(()-&gt; System.out.println(Thread.currentThread().getName())); //gracefully shutdownpool.shutdown(); 著作权归https://pdai.tech所有。 链接：https://www.pdai.tech/md/java/thread/java-thread-x-juc-executor-ThreadPoolExecutor.html 推荐方式 3spring 配置线程池方式：自定义线程工厂 bean 需要实现 ThreadFactory，可参考该接口的其它默认实现类，使用方式直接注入 bean 调用 execute(Runnable task) 方法即可。 12345678910&lt;bean id=&quot;userThreadPool&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;property name=&quot;corePoolSize&quot; value=&quot;10&quot; /&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;100&quot; /&gt; &lt;property name=&quot;queueCapacity&quot; value=&quot;2000&quot; /&gt;&lt;property name=&quot;threadFactory&quot; value= threadFactory /&gt; &lt;property name=&quot;rejectedExecutionHandler&quot;&gt; &lt;ref local=&quot;rejectedExecutionHandler&quot; /&gt; &lt;/property&gt;&lt;/bean&gt; 1userThreadPool.execute(thread); 配置线程池需要考虑因素从任务的优先级，任务的执行时间长短，任务的性质(CPU 密集/ IO 密集)，任务的依赖关系这四个角度来分析。并且近可能地使用有界的工作队列。 性质不同的任务可用使用不同规模的线程池分开处理: CPU 密集型: 尽可能少的线程，Ncpu + 1 IO 密集型: 尽可能多的线程, Ncpu * 2，比如数据库连接池 混合型: CPU 密集型的任务与 IO 密集型任务的执行时间差别较小，拆分为两个线程池；否则没有必要拆分。 监控线程池的状态可以使用 ThreadPoolExecutor 以下方法: getTaskCount() 返回计划执行的任务的大致总数。 getCompletedTaskCount() 返回已完成执行的任务的大致总数。返回结果少于getTaskCount()。 getLargestPoolSize()返回池中同时存在的最大线程数。返回结果小于等于maximumPoolSize getPoolSize() 返回池中当前的线程数。 getActiveCount() 返回正在积极执行任务的线程的大致数目。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://tang7o.cn/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://tang7o.cn/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"synchronized","slug":"synchronized","date":"2021-10-15T07:45:23.000Z","updated":"2022-04-13T13:31:48.675Z","comments":true,"path":"2021/10/15/synchronized/","link":"","permalink":"https://tang7o.cn/2021/10/15/synchronized/","excerpt":"","text":"Synchronized的使用在应用Sychronized关键字时需要把握如下注意点： 一把锁只能同时被一个线程获取，没有获得锁的线程只能等待； 每个实例都对应有自己的一把锁（this）,不同实例之间互不影响；例外：锁对象是 *.class 以及 synchronized 修饰的是 static 方法的时候，所有对象公用同一把锁 synchronized 修饰的方法，无论方法正常执行完毕还是抛出异常，都会释放锁 对象锁包括方法锁（默认锁对象为 this,当前实例对象）和同步代码块锁（自己指定锁对象）。 代码块形式：手动指定锁定对象，也可是是this,也可以是自定义的锁 示例1 123456789101112131415161718192021222324public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instence = new SynchronizedObjectLock(); @Override public void run() &#123; // 同步代码块形式——锁为this,两个线程使用的锁是一样的,线程1必须要等到线程0释放了该锁后，才能执行 synchronized (this) &#123; System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(instence); Thread t2 = new Thread(instence); t1.start(); t2.start(); &#125;&#125; 输出结果： 1234我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束 示例2 12345678910111213141516171819202122232425262728293031323334353637public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instence = new SynchronizedObjectLock(); // 创建2把锁 Object block1 = new Object(); Object block2 = new Object(); @Override public void run() &#123; // 这个代码块使用的是第一把锁，当他释放后，后面的代码块由于使用的是第二把锁，因此可以马上执行 synchronized (block1) &#123; System.out.println(&quot;block1锁,我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;block1锁,&quot;+Thread.currentThread().getName() + &quot;结束&quot;); &#125; synchronized (block2) &#123; System.out.println(&quot;block2锁,我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;block2锁,&quot;+Thread.currentThread().getName() + &quot;结束&quot;); &#125; &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(instence); Thread t2 = new Thread(instence); t1.start(); t2.start(); &#125;&#125; 输出结果： 12345678block1锁,我是线程Thread-0block1锁,Thread-0结束block2锁,我是线程Thread-0 // 可以看到当第一个线程在执行完第一段同步代码块之后，第二个同步代码块可以马上得到执行，因为他们使用的锁不是同一把block1锁,我是线程Thread-1block2锁,Thread-0结束block1锁,Thread-1结束block2锁,我是线程Thread-1block2锁,Thread-1结束 方法锁形式：synchronized修饰普通方法，锁对象默认为this12345678910111213141516171819202122232425public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instence = new SynchronizedObjectLock(); @Override public void run() &#123; method(); &#125; public synchronized void method() &#123; System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(instence); Thread t2 = new Thread(instence); t1.start(); t2.start(); &#125;&#125; 输出结果： 1234我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束 类锁指synchronize修饰静态的方法或指定锁对象为Class对象 synchronize修饰静态方法 示例1 12345678910111213141516171819202122232425262728public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instence1 = new SynchronizedObjectLock(); static SynchronizedObjectLock instence2 = new SynchronizedObjectLock(); @Override public void run() &#123; method(); &#125; // synchronized用在普通方法上，默认的锁就是this，当前实例 public synchronized void method() &#123; System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; public static void main(String[] args) &#123; // t1和t2对应的this是两个不同的实例，所以代码不会串行 Thread t1 = new Thread(instence1); Thread t2 = new Thread(instence2); t1.start(); t2.start(); &#125;&#125; 输出结果： 1234我是线程Thread-0我是线程Thread-1Thread-1结束Thread-0结束 示例2 123456789101112131415161718192021222324252627public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instence1 = new SynchronizedObjectLock(); static SynchronizedObjectLock instence2 = new SynchronizedObjectLock(); @Override public void run() &#123; method(); &#125; // synchronized用在静态方法上，默认的锁就是当前所在的Class类，所以无论是哪个线程访问它，需要的锁都只有一把 public static synchronized void method() &#123; System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(instence1); Thread t2 = new Thread(instence2); t1.start(); t2.start(); &#125;&#125; 输出结果： 1234我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束 synchronized指定锁对象为Class对象12345678910111213141516171819202122232425public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instence1 = new SynchronizedObjectLock(); static SynchronizedObjectLock instence2 = new SynchronizedObjectLock(); @Override public void run() &#123; // 所有线程需要的锁都是同一把 synchronized(SynchronizedObjectLock.class)&#123; System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(instence1); Thread t2 = new Thread(instence2); t1.start(); t2.start(); &#125;&#125; 输出结果： 1234我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束 Synchronized原理分析加锁和释放锁的原理深入JVM看字节码，创建如下的代码： 1234567891011121314public class SynchronizedDemo2 &#123; Object object = new Object(); public void method1() &#123; synchronized (object) &#123; &#125; method2(); &#125; private static void method2() &#123; &#125;&#125; 使用javac命令进行编译生成.class文件 1&gt;javac SynchronizedDemo2.java 使用javap命令反编译查看.class文件的信息 1&gt;javap -v SynchronizedDemo2.class 得到如下的信息： 关注红色方框里的 monitorenter 和 monitorexit 即可。 Monitorenter 和 Monitorexit 指令，会让对象在执行，使其锁计数器加 1 或者减 1。每一个对象在同一时间只与一个 monitor (锁)相关联，而一个 monitor 在同一时间只能被一个线程获得，一个对象在尝试获得与这个对象相关联的Monitor 锁的所有权的时候，monitorenter 指令会发生如下3中情况之一： monitor 计数器为 0，意味着目前还没有被获得，那这个线程就会立刻获得然后把锁计数器 + 1，一旦 + 1，别的线程再想获取，就需要等待。 如果这个 monitor 已经拿到了这个锁的所有权，又重入了这把锁，那锁计数器就会累加，变成 2，并且随着重入的次数，会一直累加。 这把锁已经被别的线程获取了，等待锁释放。 monitorexit 指令：释放对于 monitor 的所有权，释放过程很简单，就是将 monitor 的计数器减 1，如果减完以后，计数器不是 0，则代表刚才是重入进来的，当前线程还继续持有这把锁的所有权，如果计数器变成 0，则代表当前线程不再拥有该 monitor 的所有权，即释放锁。 下图表现了对象，对象监视器，同步队列以及执行线程状态之间的关系： 该图可以看出，任意线程对 Object 的访问，首先要获得 Object 的监视器，如果获取失败，该线程就进入同步状态，线程状态变为 BLOCKED，当 Object 的监视器占有者释放后，在同步队列中得线程就会有机会重新获取该监视器。 可重入原理：加锁次数计数器上面的 demo 中在执行完同步代码块之后紧接着再会去执行一个静态同步方法，而这个方法锁的对象依然就这个类对象，那么这个正在执行的线程还需要获取该锁吗? 答案是不必的，从上图中就可以看出来，执行静态同步方法的时候就只有一条 monitorexit 指令，并没有 monitorenter 获取锁的指令。这就是锁的重入性，即在同一锁程中，线程不需要再次获取同一把锁。 Synchronized 先天具有重入性。每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一。 保证可见性的原理：内存模型和happens-before规则Synchronized 的 happens-before 规则，即监视器锁规则：对同一个监视器的解锁，happens-before 于对该监视器的加锁。继续来看代码： 1234567891011public class MonitorDemo &#123; private int a = 0; public synchronized void writer() &#123; // 1 a++; // 2 &#125; // 3 public synchronized void reader() &#123; // 4 int i = a; // 5 &#125; // 6&#125; 该代码的happens-before关系如图所示： 在图中每一个箭头连接的两个节点就代表之间的 happens-before 关系，黑色的是通过程序顺序规则推导出来，红色的为监视器锁规则推导而出：线程 A 释放锁 happens-before 线程 B 加锁，蓝色的则是通过程序顺序规则和监视器锁规则以及传递性规则推测出来 happens-befor 关系。现在我们来重点关注 2 happens-before 5，通过这个关系我们可以得出什么? 根据 happens-before 的定义中的一条:如果 A happens-before B，则 A 的执行结果对 B 可见，并且 A 的执行顺序先于 B。线程 A 先对共享变量 A 进行加一，由 2 happens-before 5 关系可知线程 A 的执行结果对线程 B 可见即线程 B 所读取到的 a 的值为 1。 JVM中锁的优化简单来说在 JVM 中 monitorenter 和 monitorexit 字节码依赖于底层的操作系统的 Mutex Lock 来实现的，但是由于使用 Mutex Lock 需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；然而在现实中的大部分情况下，同步方法是运行在单线程环境（无锁竞争环境）如果每次都调用 Mutex Lock 那么将严重的影响程序的性能。不过在 jdk1.6 中对锁的实现引入了大量的优化，如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级锁（Lightweight Locking）、偏向锁（Biased Locking）、适应性自旋（Adaptive Spinning）等技术来减少锁操作的开销。 锁粗化（Lock Coarsening）：也就是减少不必要的紧连在一起的 unlock，lock 操作，将多个连续的锁扩展成一个范围更大的锁。 锁消（Lock Elimination）：通过运行时 JIT 编译器的逃逸分析来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本地 Stack 上进行对象空间的分配（同时还可以减少 Heap 上的垃圾收集开销）。 轻量级锁（Lightweight Locking）：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态（即单线程执行环境），在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在 monitorenter 和 monitorexit 中只需要依靠一条 CAS 原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒（具体处理步骤下面详细讨论）。 偏向锁（Biased Locking）：是为了在无锁竞争的情况下避免在锁获取过程中执行不必要的 CAS 原子指令，因为 CAS 原子指令虽然相对于重量级锁来说开销比较小但还是存在非常可观的本地延迟。 适应性自旋（Adaptive Spinning）：当线程在获取轻量级锁的过程中执行 CAS 操作失败时，在进入与 monitor 相关联的操作系统重量级锁（mutex semaphore）前会进入忙等待（Spinning）然后再次尝试，当尝试一定的次数后如果仍然没有成功则调用与该 monitor 关联的 semaphore （即互斥锁）进入到阻塞状态。 锁的类型在 Java SE 1.6 里 Synchronied 同步锁，一共有四种状态：无锁、偏向锁、轻量级所、重量级锁，它会随着竞争情况逐渐升级。锁可以升级但是不可以降级，目的是为了提供获取锁和释放锁的效率。 锁膨胀方向： 无锁 → 偏向锁 → 轻量级锁 → 重量级锁（此过程是不可逆的） 自旋锁与自适应自旋锁自旋锁 引入背景：大家都知道，在没有加入锁优化时，Synchronized 是一个非常“胖大”的家伙。在多线程竞争锁时，当一个线程获取锁时，它会阻塞所有正在竞争的线程，这样对性能带来了极大的影响。在挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作对系统的并发性能带来了很大的压力。同时 HotSpot 团队注意到在很多情况下，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和回复阻塞线程并不值得。在如今多处理器环境下，完全可以让另一个没有获取到锁的线程在门外等待一会（自旋），但不放弃 CPU 的执行时间。等待持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需要让线程执行一个忙循环（自旋），这便是自旋锁由来的原因。 自旋锁早在 JDK1.4 中就引入了，只是当时默认时关闭的。在 JDK 1.6 后默认为开启状态。自旋锁本质上与阻塞并不相同，先不考虑其对多处理器的要求，如果锁占用的时间非常的短，那么自旋锁的新能会非常的好，相反，其会带来更多的性能开销（因为在线程自旋时，始终会占用 CPU 的时间片，如果锁占用的时间太长，那么自旋的线程会白白消耗掉 CPU 资源）。因此自旋等待的时间必须要有一定的限度，如果自选超过了限定的次数仍然没有成功获取到锁，就应该使用传统的方式去挂起线程了，在 JDK 定义中，自旋锁默认的自旋次数为 10 次，用户可以使用参数 -XX:PreBlockSpin 来更改。 可是现在又出现了一个问题：如果线程锁在线程自旋刚结束就释放掉了锁，那么是不是有点得不偿失。所以这时候我们需要更加聪明的锁来实现更加灵活的自旋。来提高并发的性能。（这里则需要自适应自旋锁！） 自适应自旋锁在 JDK 1.6 中引入了自适应自旋锁。这就意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。如果在同一个锁对象上，自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，那么 JVM 会认为该锁自旋获取到锁的可能性很大，会自动增加等待时间。比如增加到 100 次循环。相反，如果对于某个锁，自旋很少成功获取锁。那再以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，JVM对程序的锁的状态预测会越来越准备，JVM也会越来越聪明。 锁消除锁消除时指虚拟机即时编译器再运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持。意思就是：JVM 会判断再一段程序中的同步明显不会逃逸出去从而被其他线程访问到，那 JVM 就把它们当作栈上数据对待，认为这些数据时线程独有的，不需要加同步。此时就会进行锁消除。 当然在实际开发中，我们很清楚的知道那些地方时线程独有的，不需要加同步锁，但是在 Java API 中有很多方法都是加了同步的，那么此时 JVM 会判断这段代码是否需要加锁。如果数据并不会逃逸，则会进行锁消除。比如如下操作：在操作 String 类型数据时，由于 String 是一个不可变类，对字符串的连接操作总是通过生成的新的 String 对象来进行的。因此 Javac 编译器会对 String 连接做自动优化。在 JDK 1.5 之前会使用 StringBuffer 对象的连续 append() 操作，在 JDK 1.5 及以后的版本中，会转化为 StringBuidler 对象的连续 append() 操作。 众所周知，StringBuilder 不是安全同步的，但是在上述代码中， JVM 判断该段代码并不会逃逸，则将该代码带默认为线程独有的资源，并不需要同步，所以执行了锁消除操作。(还有 Vector 中的各种操作也可实现锁消除。在没有逃逸出数据安全防卫内) 锁粗化原则上，我们都知道在加同步锁时，尽可能的将同步块的作用范围限制到尽量小的范围(只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小。在存在锁同步竞争中，也可以使得等待锁的线程尽早的拿到锁)。 大部分上述情况是完美正确的，但是如果存在连串的一系列操作都对同一个对象反复加锁和解锁，甚至加锁操作时出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要地性能操作。 1234567public static String test04(String s1, String s2, String s3) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString();&#125; 在上述地连续 append() 操作中就属于这类情况。JVM 会检测到这样一连串地操作都是对同一个对象加锁，那么 JVM 会将加锁同步地范围扩展（粗化）到整个一系列操作的 外部，使整个一连串地 append() 操作只需要加锁一次就可以了。 轻量级锁在 JDK 1.6 之后引入的轻量级锁，需要注意的是轻量级锁并不是替代重量级锁的，而是对在大多数情况下同步块并不会有竞争出现提出的一种优化。它可以减少重量级锁对线程的阻塞带来地线程开销。从而提高并发性能。 如果要理解轻量级锁，那么必须先要了解 HotSpot 虚拟机中对象头地内存布局。上面介绍 Java 对象头也详细介绍过。在对象头中（Object Header）存在两部分。第一部分用于存储对象自身的运行时数据，HashCode、GC Age、锁标记位、是否为偏向锁等。一般为32位或者64位（视操作系统位数定）。官方称之为 Mark Word，它是实现轻量级锁和偏向锁的关键。 另外一部分存储的是指向方法区对象类型数据的指针（Klass Point），如果对象是数组的话，还会有一个额外的部分用于存储数据的长度。 轻量级锁加锁在线程执行同步块之前，JVM 会先在当前线程的栈帧中创建一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的 Mark Word 的拷贝（JVM 会将对象头中的 Mark Word 拷贝到锁记录中，官方称为 Displaced Mark Ward ）这个时候线程堆栈与对象头的状态如图： 如上图所示：如果当前对象没有被锁定，那么锁标志位位 01 状态，JVM 在执行当前线程时，首先会在当前线程栈帧中创建锁记录 Lock Record 的空间用于存储锁对象目前的 Mark Word 的拷贝。 然后，虚拟机使用 CAS 操作将标记字段 Mark Word 拷贝到锁记录中，并且将 Mark Word 更新为指向 Lock Record 的指针。如果更新成功了，那么这个线程就有用了该对象的锁，并且对象 Mark Word 的锁标志位更新为（Mark Word 中最后的 2 bit）00，即表示此对象处于轻量级锁定状态，如图： 如果这个更新操作失败，JVM 会检查当前的 Mark Word 中是否存在指向当前线程的栈帧的指针，如果有，说明该锁已经被获取，可以直接调用。如果没有，则说明该锁被其他线程抢占了，如果有两条以上的线程竞争同一个锁，那轻量级锁就不再有效，直接膨胀位重量级锁，没有获得锁的线程会被阻塞。此时，锁的标志位为 10.Mark Word 中存储的时指向重量级锁的指针。 轻量级解锁时，会使用原子的 CAS 操作将 Displaced Mark Word 替换回到对象头中，如果成功，则表示没有发生竞争关系。如果失败，表示当前锁存在竞争关系。锁就会膨胀成重量级锁。两个线程同时争夺锁，导致锁膨胀的流程图如下： 偏向锁 引入背景：在大多实际环境下，锁不仅不存在多线程竞争，而且总是由同一个线程多次获取，那么在同一个线程反复获取所释放锁中，其中并还没有锁的竞争，那么这样看上去，多次的获取锁和释放锁带来了很多不必要的性能开销和上下文切换。 为了解决这一问题，HotSpot 的作者在 Java SE 1.6 中对 Synchronized 进行了优化，引入了偏向锁。当一个线程访问同步快并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程 ID，以后该线程在进入和推出同步块时不需要进行 CAS 操作来加锁和解锁。只需要简单地测试一下对象头的 Mark Word 里是否存储着指向当前线程的偏向锁。如果成功，表示线程已经获取到了锁。 偏向锁的撤销偏向锁使用了一种等待竞争出现才会释放锁的机制。所以当其他线程尝试获取偏向锁时，持有偏向锁的线程才会释放锁。但是偏向锁的撤销需要等到全局安全点（就是当前线程没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着。如果线程不处于活动状态，直接将对象头设置为无锁状态。如果线程活着，JVM 会遍历栈帧中的锁记录，栈帧中的锁记录和对象头要么偏向于其他线程，要么恢复到无锁状态或者标记对象不适合作为偏向锁。 著作权归https://pdai.tech所有。 链接：https://www.pdai.tech/md/java/thread/java-thread-x-key-synchronized.html 锁的优缺点对比 锁 优点 缺点 使用场景 偏向锁 加锁和解锁不需要 CAS 操作，没有额外的性能消耗，和执行非同步方法相比仅存在纳秒级的差距 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 适用于只有一个线程访问同步快的场景 轻量级锁 竞争的线程不会阻塞，提高了响应速度 如线程成始终得不到锁竞争的线程，使用自旋会消耗CPU性能 追求响应时间，同步快执行速度非常快 重量级锁 线程竞争不使用自旋，不会消耗CPU 线程阻塞，响应时间缓慢，在多线程下，频繁的获取释放锁，会带来巨大的性能消耗 追求吞吐量，同步快执行速度较长 Synchronized与Locksynchronized的缺陷 效率低：锁的释放情况少，只有代码执行完毕或者异常结束才会释放锁；试图获取锁的时候不能设定超时，不能中断一个正在使用锁的线程，相对而言，Lock 可以中断和设置超时。 不够灵活：加锁和释放的时机单一，每个锁仅有一个单一的条件（某个对象），相对而言，读写锁更加灵活。 无法知道是否成功获得锁，相对而言，Lock可以拿到状态，如果成功获取锁，….，如果获取失败，…..。 Lock解决相应问题Lock 类这里不做过多解释，主要看里面的4个方法: lock(): 加锁 unlock(): 解锁 tryLock(): 尝试获取锁，返回一个boolean值 tryLock(long,TimeUtil): 尝试获取锁，可以设置超时 Synchronized 只有锁只与一个条件（是否获取锁）相关联，不灵活，后来 Condition 与 Lock 的结合 解决了这个问题。 多线程竞争一个锁时，其余未得到锁的线程只能不停的尝试获得锁，而不能中断。高并发的情况下会导致性能下降。ReentrantLock 的lockInterruptibly() 方法可以优先考虑响应中断。 一个线程等待时间过长，它可以中断自己，然后 ReentrantLock 响应这个中断，不再让这个线程继续等待。有了这个机制，使用 ReentrantLock 时就不会像 synchronized 那样产生死锁了。 ReentrantLock 为常用类，它是一个可重入的互斥锁 Lock，它具有与使用 synchronized 方法和语句所访问的隐式监视器锁相同的一些基本行为和语义，但功能更强大。 再深入理解synchronized 是通过软件（JVM）实现的，简单易用，即使在 JDK5 之后有了 Lock，仍然被广泛地使用。 使用 Synchronized 有哪些要注意的？ 锁对象不能为空，因为锁的信息都保存在对象头里。 作用域不宜过大，影响程序执行的速度，控制范围过大，编写代码也容易出错。 避免死锁。 在能选择的情况下，既不要用 Lock 也不要用 synchronized 关键字，用 java.util.concurrent 包中的各种各样的类，如果不用该包下的类，在满足业务的情况下，可以使用 synchronized 关键，因为代码量少，避免出错。 synchronized 是公平锁吗？ synchronized 实际上是非公平的，新来的线程有可能立即获得监视器，而在等待区中等候已久的线程可能再次等待。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://tang7o.cn/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://tang7o.cn/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"volatile","slug":"volatile","date":"2021-10-13T01:38:44.000Z","updated":"2022-04-13T13:31:48.722Z","comments":true,"path":"2021/10/13/volatile/","link":"","permalink":"https://tang7o.cn/2021/10/13/volatile/","excerpt":"","text":"volatile的作用详解防重排序大家应该都很熟悉单例模式的实现，而在并发环境下的单例实现方式，我们通常可以采用双重检查加锁(DCL)的方式来实现。其源码如下： 1234567891011121314151617public class Singleton &#123; public static volatile Singleton singleton; /** * 构造函数私有，禁止外部实例化 */ private Singleton() &#123;&#125;; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 现在我们分析一下为什么要在变量 singleton 之间加上 volatile 关键字。要理解这个问题，先要了解对象的构造过程，实例化一个对象其实可以分为三个步骤： 分配内存空间。 初始化对象。 将内存空间的地址赋值给对应的引用。 但是由于操作系统可以对指令进行重排序，所以上面的过程也可能会变成如下过程： 分配内存空间。 将内存空间的地址赋值给对应的引用。 初始化对象 如果是这个流程，多线程环境下就可能将一个未初始化的对象引用暴露出来，从而导致不可预料的结果。因此，为了防止这个过程的重排序，我们需要将变量设置为 volatile 类型的变量。 实现可见性可见性问题主要指一个线程修改了共享变量值，而另一个线程却看不到。引起可见性问题的主要原因是每个线程拥有自己的一个高速缓存区——线程工作内存。volatile 关键字能有效的解决这个问题，我们看下下面的例子，就可以知道其作用： 1234567891011121314151617181920212223242526272829303132333435363738394041public class VolatileTest &#123; int a = 1; int b = 2; public void change()&#123; a = 3; b = a; &#125; public void print()&#123; System.out.println(&quot;b=&quot;+b+&quot;;a=&quot;+a); &#125; public static void main(String[] args) &#123; while (true)&#123; final VolatileTest test = new VolatileTest(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; test.change(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; test.print(); &#125; &#125;).start(); &#125; &#125;&#125; 直观上说，这段代码的结果只可能有两种：$b=3;a=3$ 或 $b=2;a=1$。不过运行上面的代码(可能时间上要长一点)，你会发现除了上两种结果之外，还出现了第三种结果： 1234567891011...... b=2;a=1b=2;a=1b=3;a=3b=3;a=3b=3;a=1 // 这里b=3;a=3b=2;a=1b=3;a=3b=3;a=3...... 为什么会出现 $b=3;a=1$ 这种结果呢? 正常情况下，如果先执行 change 方法，再执行 print 方法，输出结果应该为 $b=3;a=3$。相反，如果先执行的 print 方法，再执行 change 方法，结果应该是 $b=2;a=1$。那 $b=3;a=1$ 的结果是怎么出来的? 原因就是第一个线程将值 $a=3$ 修改后，但是对第二个线程是不可见的，所以才出现这一结果。如果将 a 和 b 都改成 volatile 类型的变量再执行，则再也不会出现 $b=3;a=1$ 的结果了。 保证原子性:单次读/写volatile 不能保证完全的原子性，只能保证单次的读/写操作具有原子性。先从如下两个问题来理解： 问题1： i++为什么不能保证原子性?对于原子性，需要强调一点，也是大家容易误解的一点：对 volatile 变量的单次读/写操作可以保证原子性的，如 long 和 double 类型变量，但是并不能保证 i++ 这种操作的原子性，因为本质上 i++ 是读、写两次操作。 现在我们就通过下列程序来演示一下这个问题： 1234567891011121314151617181920212223242526public class VolatileTest01 &#123; volatile int i; public void addI()&#123; i++; &#125; public static void main(String[] args) throws InterruptedException &#123; final VolatileTest01 test01 = new VolatileTest01(); for (int n = 0; n &lt; 1000; n++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; test01.addI(); &#125; &#125;).start(); &#125; Thread.sleep(10000);//等待10秒，保证上面程序执行完成 System.out.println(test01.i); &#125;&#125; 大家可能会误认为对变量i加上关键字 volatile 后，这段程序就是线程安全的。大家可以尝试运行上面的程序。下面是我本地运行的结果：981 可能每个人运行的结果不相同。不过应该能看出，volatile 是无法保证原子性的(否则结果应该是 1000)。原因也很简单，i++ 其实是一个复合操作，包括三步骤： 读取 i 的值。 对 i 加 1。 将 i 的值写回内存。 volatile 是无法保证这三个操作是具有原子性的，我们可以通过 AtomicInteger 或者 Synchronized 来保证 +1 操作的原子性。 注：上面几段代码中多处执行了 Thread.sleep() 方法，目的是为了增加并发问题的产生几率，无其他作用。 问题2： 共享的long和double变量的为什么要用volatile?因为 long 和 double 两种数据类型的操作可分为高 32 位和低 32 位两部分，因此普通的 long 或 double 类型读/写可能不是原子的。因此，鼓励大家将共享的 long 和 double 变量设置为 volatile 类型，这样能保证任何情况下对 long 和 double 的单次读/写操作都具有原子性。 目前各种平台下的商用虚拟机都选择把 64 位数据的读写操作作为原子操作来对待，因此我们在编写代码时一般不把 long 和 double 变量专门声明为 volatile 多数情况下也是不会错的。 volatile 的实现原理volatile 可见性实现 volatile 变量的内存可见性是基于内存屏障(Memory Barrier)实现: 内存屏障，又称内存栅栏，是一个 CPU 指令。 在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，JMM 为了保证在不同的编译器和 CPU 上有相同的结果，通过插入特定类型的内存屏障来禁止特定类型的编译器重排序和处理器重排序，插入一条内存屏障会告诉编译器和 CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序。 12345678910public class Test &#123; private volatile int a; public void update() &#123; a = 1; &#125; public static void main(String[] args) &#123; Test test = new Test(); test.update(); &#125;&#125; 通过 hsdis 和 jitwatch 工具可以得到编译后的汇编代码: 123456789101112131415161718...... 0x0000000002951563: and $0xffffffffffffff87,%rdi 0x0000000002951567: je 0x00000000029515f8 0x000000000295156d: test $0x7,%rdi 0x0000000002951574: jne 0x00000000029515bd 0x0000000002951576: test $0x300,%rdi 0x000000000295157d: jne 0x000000000295159c 0x000000000295157f: and $0x37f,%rax 0x0000000002951586: mov %rax,%rdi 0x0000000002951589: or %r15,%rdi 0x000000000295158c: lock cmpxchg %rdi,(%rdx) //在 volatile 修饰的共享变量进行写操作的时候会多出 lock 前缀的指令 0x0000000002951591: jne 0x0000000002951a15 0x0000000002951597: jmpq 0x00000000029515f8 0x000000000295159c: mov 0x8(%rdx),%edi 0x000000000295159f: shl $0x3,%rdi 0x00000000029515a3: mov 0xa8(%rdi),%rdi 0x00000000029515aa: or %r15,%rdi...... lock 前缀的指令在多核处理器下会引发两件事情: 将当前处理器缓存行的数据写回到系统内存。 写回内存的操作会使在其他 CPU 里缓存了该内存地址的额数据无效。 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存(L1，L2 或其他)后再进行操作，但操作完不知道何时会写到内存。 如果对声明了 volatile 的变量进行写操作，JVM 就会向处理器发送一条 lock 前缀的指令，将这个变量所在缓存行的数据写回到系统内存。 为了保证各个处理器的缓存是一致的，实现了缓存一致性协议(MESI)，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 所有多核处理器下还会完成：当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值。 volatile 变量通过这样的机制就使得每个线程都能获得该变量的最新值。 volatile 有序性实现volatile 的 happens-before 关系happens-before 规则中有一条是 volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。 1234567891011121314151617//假设线程A执行writer方法，线程B执行reader方法class VolatileExample &#123; int a = 0; volatile boolean flag = false; public void writer() &#123; a = 1; // 1 线程A修改共享变量 flag = true; // 2 线程A写volatile变量 &#125; public void reader() &#123; if (flag) &#123; // 3 线程B读同一个volatile变量 int i = a; // 4 线程B读共享变量 …… &#125; &#125;&#125; 根据 happens-before 规则，上面过程会建立 3 类 happens-before 关系。 根据程序次序规则：1 happens-before 2 且 3 happens-before 4。 根据 volatile 规则：2 happens-before 3。 根据 happens-before 的传递性规则：1 happens-before 4。 因为以上规则，当线程 A 将 volatile 变量 flag 更改为 true 后，线程 B 能够迅速感知。 volatile 禁止重排序为了性能优化，JMM 在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序。JMM 提供了内存屏障阻止这种重排序。 Java 编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。 JMM 会针对编译器制定 volatile 重排序规则表。 为了实现 volatile 内存语义时，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎是不可能的，为此，JMM 采取了保守的策略。 在每个 volatile 写操作的前面插入一个 StoreStore 屏障。 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障。 在每个 volatile 读操作的前面插入一个 LoadLoad 屏障。 在每个 volatile 读操作的后面插入一个 LoadStore 屏障。 volatile 写是在前面和后面分别插入内存屏障，而 volatile 读操作是在后面插入两个内存屏障。 内存屏障 说明 StoreStore 屏障 禁止上面的普通写和下面的 volatile 写重排序。 StoreLoad 屏障 防止上面的 volatile 写与下面可能有的 volatile 读/写重排序。 LoadLoad 屏障 禁止下面所有的普通读操作和上面的 volatile 读重排序。 LoadStore 屏障 禁止下面所有的普通写操作和上面的 volatile 读重排序。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://tang7o.cn/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"}]},{"title":"Happens-Before规则","slug":"happens-before","date":"2021-10-10T03:32:35.000Z","updated":"2022-04-13T13:31:48.534Z","comments":true,"path":"2021/10/10/happens-before/","link":"","permalink":"https://tang7o.cn/2021/10/10/happens-before/","excerpt":"","text":"先来个示例： 【示例一】 1234567891011121314class VolatileExample &#123; int x = 0; volatile boolean v = false; public void writer() &#123; x = 42; v = true; &#125; public void reader() &#123; if (v == true) &#123; //x的值是多少呢？ &#125; &#125;&#125; 这里，假设线程 A 执行 writer() 方法，按照 volatile 会将 v = true 写入内存；线程 B 执行 reader() 方法，按照 volatile，线程 B 会从内存中读取变量 v，如果线程 B 读取到的变量 v 为 true，那么，此时的变量 x 的值是多少呢？？ 这个示例程序给人的直觉就是x的值为 42，其实，x 的值具体是多少和 JDK 的版本有关，如果使用的 JDK 版本低于 1.5，则 x 的值可能为 42，也可能为 0。如果使用 1.5 及 1.5 以上版本的 JDK，则 x 的值就是 42。 看到这个，就会有人提出问题了？这是为什么呢？其实，答案就是在 JDK1.5 版本中的 Java 内存模型中引入了 Happens-Before 规则。 接下来，我们就结合案例程序来说明 Java 内存模型中的 Happens-Before 规则。 1.程序次序规则在一个线程中，按照代码的顺序，前面的操作 Happens-Before 于后面的任意操作。 例如【示例一】中的程序 x = 42 会在 v = true 之前执行。这个规则比较符合单线程的思维：在同一个线程中，程序在前面对某个变量的修改一定是对后续操作可见的。 2.volatile变量规则对一个 volatile 变量的写操作，Happens-Before 于后续对这个变量的读操作。 也就是说，对一个使用了volatile变量的写操作，先行发生于后面对这个变量的读操作。 3.传递规则如果 A Happens-Before B，并且 B Happens-Before C，则 A Happens-Before C。 【示例一】中根据 Happens-Before 规则我们可以得到: x = 42 Happens-Before v = true，程序次序规则。 v = true Happens-Before v == true，volatile变量规则。 x = 42 Happens-Before v == true，传递规则。 也就是说，如果线程 B 读取到了 v = true，那么，线程 A 设置的 x = 42 对线程 B 就是可见的。换句话说，就是此时的线程 B 能够访问到 x = 42。 4.锁定规则对一个锁的解锁操作 Happens-Before 于后续对这个锁的加锁操作。 例如，下面的代码，在进入 synchronized 代码块之前，会自动加锁，在代码块执行完毕后，会自动释放锁。 【示例二】 12345678910public class Test&#123; private int x = 0; public void initX&#123; synchronized(this)&#123; //自动加锁 if(this.x &lt; 1)&#123; this.x = 1; &#125; &#125; //自动释放锁 &#125;&#125; 我们可以这样理解这段程序：假设变量 x 的值为 0，线程A执行完 synchronized 代码块之后将 x 变量的值修改为 1，并释放 synchronized 锁。当线程 B 进入 synchronized 代码块时，能够获取到线程 A 对 x 变量的写操作，也就是说，线程 B 访问到的 x 变量的值为 1。 5.线程启动规则如果线程 A 调用线程 B 的 start() 方法来启动线程 B，则 start() 操作 Happens-Before 于线程 B 中的任意操作。 我们也可以这样理解线程启动规则：线程 A 启动线程 B 之后，线程 B 能够看到线程 A 在启动线程 B 之前的操作。 【示例三】 123456//在线程A中初始化线程BThread threadB = new Thread(()-&gt;&#123; //此处的变量x的值是多少呢？答案是100&#125;);x = 100; //线程A在启动线程B之前将共享变量x的值修改为100threadB.start(); //启动线程B 上述代码是在线程 A 中执行的一个代码片段，根据线程启动规则，线程 A 启动线程 B 之后，线程 B 能够看到线程 A 在启动线程 B 之前的操作，在线程 B 中访问到的 x 变量的值为 100。 6.线程终结规则线程 A 等待线程 B 完成（在线程 A 中调用线程 B 的 join() 方法实现），当线程 B 完成后（线程 A 调用线程 B 的 join() 方法返回），则线程 A 能够访问到线程 B 对共享变量的操作。 【示例四】 1234567Thread threadB = new Thread(()-&#123; //在线程B中，将共享变量x的值修改为100 x = 100;&#125;);threadB.start(); //在线程A中启动线程BthreadB.join(); //在线程A中等待线程B执行完成//此处访问共享变量x的值为100 7.线程中断规则对线程 interrupt() 方法的调用 Happens-Before 于被中断线程的代码检测到中断事件的发生。 例如，下面的程序代码。在线程 A 中断线程 B 之前，将共享变量 x 的值修改为 100，则当线程 B 检测到中断事件时，访问到的 x 变量的值为 100。 【示例五】 12345678910111213141516171819 //在线程A中将x变量的值初始化为0private int x = 0;public void execute()&#123; //在线程A中初始化线程B Thread threadB = new Thread(()-&gt;&#123; //线程B检测自己是否被中断 if (Thread.currentThread().isInterrupted())&#123; //如果线程B被中断，则此时X的值为100 System.out.println(x); &#125; &#125;); //在线程A中启动线程B threadB.start(); //在线程A中将共享变量X的值修改为100 x = 100; //在线程A中中断线程B threadB.interrupt();&#125; 8.对象终结规则一个对象的初始化完成 Happens-Before 于它的 finalize() 方法的开始。 【示例六】 12345678910111213141516public class Test &#123; public Test()&#123; System.out.println(&quot;构造方法&quot;); &#125; @Override protected void finalize() throws Throwable &#123; System.out.println(&quot;对象销毁&quot;); &#125; public static void main(String[] args)&#123; new Test(); System.gc(); &#125;&#125; 运行结果如下所示。 12构造方法对象销毁","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://tang7o.cn/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://tang7o.cn/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"final","slug":"final","date":"2021-10-08T11:33:57.000Z","updated":"2022-04-13T13:31:48.506Z","comments":true,"path":"2021/10/08/final/","link":"","permalink":"https://tang7o.cn/2021/10/08/final/","excerpt":"","text":"基本使用修饰类当某个类被定义为 final 时，表明这个类不能被继承。 注意：final 类中所有的方法都隐式为 final，因为无法覆盖他们，所以 final 类中给任何方法添加 final 关键字都是没有意义的。 可以使用组合的方式扩展 final 类。比如我们想写个 MyString 复用 String 类的方法，并新增一个 toMyString() 方法。 1234567891011121314class MyString&#123; private String innerString; // ..... // 复用 String 的方法 public int length() &#123; return innerString.length(); &#125; // 添加新方法 public String toMyString() &#123; //... &#125;&#125; 修饰方法表示方法不可被覆盖，但是可以被重载。 private 方法是隐式的 final。 private final类中所有 private 方法都隐式的指定为 final，由于无法取用 private 方法，所以也就不能覆盖它。 修饰参数Java 允许在参数列表中以声明的方式将参数指明为 final，这意味这你无法在方法中更改参数引用所指向的对象。这个特性主要用来向匿名内部类传递数据。 修饰变量对于一个 final 变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。 编译期常量、非编译器常量12345678910111213public class Test &#123; //编译期常量 final int i = 1; final static int J = 1; final int[] a = &#123;1,2,3,4&#125;; //非编译期常量 Random r = new Random(); final int k = r.nextInt(); public static void main(String[] args) &#123; &#125;&#125; k的值由随机数对象决定，所以不是所有的final修饰的字段都是编译期常量，只是k的值在被初始化后无法被更改。 static final一个既是 static 又是 final 的字段只占据一段不能改变的存储空间，它必须在定义的时候进行赋值，否则编译器将不予通过。 123456789101112import java.util.Random;public class Test &#123; static Random r = new Random(); final int k = r.nextInt(10); static final int k2 = r.nextInt(10); public static void main(String[] args) &#123; Test t1 = new Test(); System.out.println(&quot;k=&quot;+t1.k+&quot; k2=&quot;+t1.k2); Test t2 = new Test(); System.out.println(&quot;k=&quot;+t2.k+&quot; k2=&quot;+t2.k2); &#125;&#125; 12k=2 k2=7k=8 k2=7 我们可以发现对于不同的对象 k 的值是不同的，但是 k2 的值却是相同的，这是为什么呢? 因为 static 关键字所修饰的字段并不属于一个对象，而是属于这个类的。也可简单的理解为 static final 所修饰的字段仅占据内存的一个一份空间，一旦被初始化之后便不会被更改。 blank finalJava 允许生成空白 final，也就是说被声明为 final 但又没有给出定值的字段,但是必须在该字段被使用之前被赋值，这给予我们两种选择： 在定义处进行赋值(这不叫空白final) 在构造器中进行赋值，保证了该值在被使用前赋值。 这增强了 final 的灵活性。 12345678910public class Test &#123; final int i1 = 1; final int i2;//空白final public Test() &#123; i2 = 1; &#125; public Test(int x) &#123; this.i2 = x; &#125;&#125; 可以看到 i2 的赋值更为灵活。但是请注意，如果字段由 static 和 final 修饰，仅能在定义处赋值，因为该字段不属于对象，属于这个类。 final 域重排序基本类型1234567891011121314151617181920public class FinalDemo &#123; private int a; //普通域 private final int b; //final域 private static FinalDemo finalDemo; public FinalDemo() &#123; a = 1; // 1. 写普通域 b = 2; // 2. 写final域 &#125; public static void writer() &#123; finalDemo = new FinalDemo(); &#125; public static void reader() &#123; FinalDemo demo = finalDemo; // 3.读对象引用 int a = demo.a; //4.读普通域 int b = demo.b; //5.读final域 &#125;&#125; 假设线程 A 在执行 writer() 方法，线程 B 执行 reader() 方法。 写 final 域重排序规则写 final 域的重排序规则禁止对 final 域的写重排序到构造函数之外，这个规则的实现主要包含了两个方面： JMM 禁止编译器把 final 域的写重排序到构造函数之外； 编译器会在 final 域写之后，构造函数 return 之前，插入一个 storestore 屏障。这个屏障可以禁止处理器把 final 域的写重排序到构造函数之外。 我们再来分析 writer 方法，虽然只有一行代码，但实际上做了两件事情： 构建了一个 FinalDemo 对象； 把这个对象赋值给成员变量 finalDemo。 我们来画下存在的一种可能执行时序图，如下： 由于 a，b 之间没有数据依赖性，普通域(普通变量) a 可能会被重排序到构造函数之外，线程 B 就有可能读到的是普通变量 a 初始化之前的值(零值)，这样就可能出现错误。而 final 域变量 b，根据重排序规则，会禁止 final 修饰的变量 b 重排序到构造函数之外，从而 b 能够正确赋值，线程 B 就能够读到 final 变量初始化后的值。 因此，写 final 域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的 final 域已经被正确初始化过了，而普通域就不具有这个保障。比如在上例，线程 B 有可能就是一个未正确初始化的对象 finalDemo。 读 final 域重排序规则读 final 域重排序规则为：在一个线程中，初次读对象引用和初次读该对象包含的 final 域，JMM 会禁止这两个操作的重排序。(注意，这个规则仅仅是针对处理器)，处理器会在读 final 域操作的前面插入一个 LoadLoad 屏障。实际上，读对象的引用和读该对象的 final 域存在间接依赖性，一般处理器不会重排序这两个操作。但是有一些处理器会重排序，因此，这条禁止重排序规则就是针对这些处理器而设定的。 read() 方法主要包含了三个操作： 初次读引用变量 finalDemo; 初次读引用变量 finalDemo 的普通域 a; 初次读引用变量 finalDemo 的 final 域 b; 假设线程 A 写过程没有重排序，那么线程 A 和线程 B 有一种的可能执行时序为下图： 读对象的普通域被重排序到了读对象引用的前面就会出现线程 B 还未读到对象引用就在读取该对象的普通域变量，这显然是错误的操作。而 final 域的读操作就“限定”了在读 final 域变量前已经读到了该对象的引用，从而就可以避免这种情况。 读 final 域的重排序规则可以确保：在读一个对象的 final 域之前，一定会先读这个包含这个 final 域的对象的引用。 引用类型对 final 修饰的对象的成员域写操作针对引用数据类型，final 域写针对编译器和处理器重排序增加了这样的约束：在构造函数内对一个 final 修饰的对象的成员域的写入，与随后在构造函数之外把这个被构造的对象的引用赋给一个引用变量，这两个操作是不能被重排序的。注意这里的是“增加”也就说前面对 final 基本数据类型的重排序规则在这里还是使用。这句话是比较拗口的，下面结合实例来看。 1234567891011121314151617181920212223public class FinalReferenceDemo &#123; final int[] arrays; private FinalReferenceDemo finalReferenceDemo; public FinalReferenceDemo() &#123; arrays = new int[1]; //1 arrays[0] = 1; //2 &#125; public void writerOne() &#123; finalReferenceDemo = new FinalReferenceDemo(); //3 &#125; public void writerTwo() &#123; arrays[0] = 2; //4 &#125; public void reader() &#123; if (finalReferenceDemo != null) &#123; //5 int temp = finalReferenceDemo.arrays[0]; //6 &#125; &#125;&#125; 针对上面的实例程序，线程线程 A 执行 wirterOne() 方法，执行完后线程 B 执行 writerTwo() 方法，然后线程 C 执行 reader() 方法。下图就以这种执行时序出现的一种情况来讨论。 由于对 final 域的写禁止重排序到构造方法外，因此 1 和 3 不能被重排序。由于一个 final 域的引用对象的成员域写入不能与随后将这个被构造出来的对象赋给引用变量重排序，因此 2 和 3 不能重排序。 对final修饰的对象的成员域读操作JMM 可以确保线程 C 至少能看到写线程 A 对 final 引用的对象的成员域的写入，即能看下 arrays[0] = 1，而写线程 B 对数组元素的写入可能看到可能看不到。JMM 不保证线程 B 的写入对线程 C 可见，线程 B 和线程 C 之间存在数据竞争，此时的结果是不可预知的。如果可见的，可使用锁或者 volatile。 关于 final 重排序的总结按照 final 修饰的数据类型分类： 基本数据类型: final域写：禁止 final 域写与构造方法重排序，即禁止 final 域写重排序到构造方法之外，从而保证该对象对所有线程可见时，该对象的 final 域全部已经初始化过。 final域读：禁止初次读对象的引用与读该对象包含的 final 域的重排序。 引用数据类型： 额外增加约束：禁止在构造函数对一个 final 修饰的对象的成员域的写入与随后将这个被构造的对象的引用赋值给引用变量重排序。 一个有趣的现象123byte b1=1;byte b2=3;byte b3=b1+b2; //当程序执行到这一行的时候会出错，因为b1、b2可以自动转换成int类型的变量，运算时java虚拟机对它进行了转换，结果导致把一个int赋值给byte-----出错 如果对 b1、b2 加上 final 就不会出错。 123final byte b1=1;final byte b2=3;byte b3=b1+b2;//不会出错","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"final","slug":"final","permalink":"https://tang7o.cn/tags/final/"}]},{"title":"Java线程","slug":"Java线程","date":"2021-10-07T06:16:11.000Z","updated":"2022-04-13T13:31:48.105Z","comments":true,"path":"2021/10/07/Java线程/","link":"","permalink":"https://tang7o.cn/2021/10/07/Java%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"线程状态转换 新建（New）创建后尚未启动。 可运行（Runnable）可能正在运行，也可能正在等待 CPU 时间片。 包含了操作系统线程状态中的 Running 和 Ready。 阻塞（Blocking）等待获取一个排它锁，如果其线程释放了锁就会结束此状态。 无限期等待（Waiting）等待其它线程显式地唤醒，否则不会被分配 CPU 时间片。 进入方法 退出方法 没有设置 Timeout 参数的 Object.wait() 方法 Object.notify() / Object.notifyAll() 没有设置 Timeout 参数的 Thread.join() 方法 被调用的线程执行完毕 LockSupport.park() 方法 - 限期等待（Timed Waiting）无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。 调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。 调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。 睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。 阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用 Thread.sleep() 和 Object.wait() 等方法进入。 进入方法 退出方法 Thread.sleep() 方法 时间结束 设置了 Timeout 参数的 Object.wait() 方法 时间结束 / Object.notify() / Object.notifyAll() 设置了 Timeout 参数的 Thread.join() 方法 时间结束 / 被调用的线程执行完毕 LockSupport.parkNanos() 方法 - LockSupport.parkUntil() 方法 - 死亡（Terminated）可以是线程结束任务后自己结束，或者产生了异常而结束。 线程使用方式 实现 Runnable 接口； 实现 callable 接口； 继承 Thread 类； 实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以说任务是通过线程驱动从而执行的。 实现 Runnable 接口需要实现 run() 方法。 通过 Thread 调用 start() 方法来启动线程。 12345public class MyRunnable implements Runnable &#123; public void run() &#123; // ... &#125;&#125; 12345public static void main(String[] args) &#123; MyRunnable mr = new MyRunnable(); Thread thread = new Thread(mr); thread.start();&#125; 实现 callable 接口与 Runnable 相比，Callable 可以有返回值，返回值通过 FutureTask 进行封装。 12345public class MyCallable implements Callable&lt;Integer&gt; &#123; public Integer call() &#123; return 123; &#125;&#125; 1234567public static void main(String[] args) throws ExecutionException, InterruptedException &#123; MyCallable mc = new MyCallable(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc); Thread thread = new Thread(ft); thread.start(); System.out.println(ft.get());&#125; 继承 Thread 类同样也需要实现 run() 方法，因为 Thread 类也实现了 Runnable 接口。 当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程调度时会执行该线程的 run() 方法。 12345public class MyThread extends Thread &#123; public void run() &#123; // ... &#125;&#125; 1234public static void main(String[] args) &#123; MyThread mt = new MyThread(); mt.start();&#125; 实现接口 VS 继承 Thread实现接口要比继承 Thread 好一些，因为： Java 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口； 类可能只要求可执行就行，继承整个 Thread 类开销过大。 基础线程机制ExecutorExecutor 管理多个异步任务的执行，而无需程序员显示的管理线程周期。这里异步是指多个任务的执行互不干扰，不需要进行同步操作。 主要有三种 Executor： CachedThreadPool: 一个任务创建一个线程； FixedThreadPool: 所有任务只能使用固定大小的线程； SingleThreadExecutor: 相当于大小为 1 的 FixedThreadPool。 1234567public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) &#123; executorService.execute(new MyRunnable()); &#125; executorService.shutdown();&#125; Daemon守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。 main() 属于非守护线程。 使用 setDaemon() 方法将一个线程设置成守护线程。 1234public static void main(String[] args) &#123; Thread thread = new Thread(new MyRunnable()); thread.setDaemon(true);&#125; sleep()Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。 sleep() 可能会抛出 InterruptedException，因为异常不能跨线程传回 main() 中，因此必须在本地进行处理。线程中抛出其他异常也需要在本地进行处理。 1234567public void run() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; yield()对静态方法 Thread.yield() 的调用声明了当前线程已经完成类生命周期中最重要的部分，可以切换给其他线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其他线程可以运行。 线程中断一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。 InterruptedException通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。 对于以下代码，在 main() 中启动一个线程之后再中断它，由于线程中调用了 Thread.sleep() 方法，因此会抛出一个 InterruptedException，从而提前结束线程，不执行之后的语句。 1234567891011121314public class InterruptExample &#123; private static class MyThread1 extends Thread &#123; @Override public void run() &#123; try &#123; Thread.sleep(2000); System.out.println(&quot;Thread run&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 123456public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new MyThread1(); thread1.start(); thread1.interrupt(); System.out.println(&quot;Main run&quot;);&#125; 123456Main runjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at InterruptExample.lambda$main$0(InterruptExample.java:5) at InterruptExample$$Lambda$1/713338599.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) interrupted()如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。 但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。 123456789101112public class InterruptExample &#123; private static class MyThread2 extends Thread &#123; @Override public void run() &#123; while (!interrupted()) &#123; // .. &#125; System.out.println(&quot;Thread end&quot;); &#125; &#125;&#125; 12345public static void main(String[] args) throws InterruptedException &#123; Thread thread2 = new MyThread2(); thread2.start(); thread2.interrupt();&#125; 1Thread end Executor 的中断操作调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。 如果只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。 1234Future&lt;?&gt; future = executorService.submit(() -&gt; &#123; // ..&#125;);future.cancel(true); 线程互斥同步Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。 synchronized1.同步一个代码块 12345public void func() &#123; synchronized (this) &#123; // ... &#125;&#125; 它只作用于同一个对象，如果调用两个对象上的同步代码块，就不会进行同步。 对于以下代码，使用 ExecutorService 执行了两个线程，由于调用的是同一个对象的同步代码块，因此这两个线程会进行同步，当一个线程进入同步代码块时，另一个线程就必须等待。 12345678910public class SynchronizedExample &#123; public void func1() &#123; synchronized (this) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; &#125; &#125;&#125; 123456public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e1.func1());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 对于以下代码，两个线程调用了不同对象的同步代码块，因此这两个线程就不需要同步。从输出结果可以看出，两个线程交叉执行。 1234567public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e2.func1());&#125; 10 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 2.同步一个方法 123public synchronized void func () &#123; // ...&#125; 它和同步一个代码块一样，作用于同一个对象。 3.同步一个类 12345public void func() &#123; synchronized (SynchronizedExample.class) &#123; // ... &#125;&#125; 作用于整个类，也就是说两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。 12345678910public class SynchronizedExample &#123; public void func2() &#123; synchronized (SynchronizedExample.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; &#125; &#125;&#125; 1234567public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func2()); executorService.execute(() -&gt; e2.func2());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 4.同步一个静态方法 123public synchronized static void fun() &#123; // ...&#125; 作用于整个类。 ReentrantLockReentrantLock 是 java.util.concurrent(J.U.C)包中的锁。 123456789101112131415public class LockExample &#123; private Lock lock = new ReentrantLock(); public void func() &#123; lock.lock(); try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; &#125; finally &#123; lock.unlock(); // 确保释放锁，从而避免发生死锁。 &#125; &#125;&#125; 123456public static void main(String[] args) &#123; LockExample lockExample = new LockExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; lockExample.func()); executorService.execute(() -&gt; lockExample.func());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 比较1.锁的实现 synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。 2.性能 新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。 3.等待可中断 当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。 ReentrantLock 可中断，而 synchronized 不行。 4.公平锁 公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。 synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。 5.锁绑定多个条件 一个 ReentrantLock 可以同时绑定多个 Condition 对象。 使用选择除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。 线程间协作当多个线程可以一起工作去解决某个问题时，如果某些部分必须在其它部分之前完成，那么就需要对线程进行协调。 join()在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。 1234567891011121314151617181920212223242526272829303132333435public class JoinExample &#123; private class A extends Thread &#123; @Override public void run() &#123; System.out.println(&quot;A&quot;); &#125; &#125; private class B extends Thread &#123; private A a; B(A a) &#123; this.a = a; &#125; @Override public void run() &#123; try &#123; a.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;B&quot;); &#125; &#125; public void test() &#123; A a = new A(); B b = new B(a); b.start(); a.start(); &#125;&#125; 1234public static void main(String[] args) &#123; JoinExample example = new JoinExample(); example.test();&#125; 12AB wait() notify() notifyAll()当调用 wait() 使得线程等待某个条件满足， 线程在等待时会挂起，当其他线程的运行使这个条件满足时，其他线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。 它们都属于 Object 的一部分，而不属于 Thread。 只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateExeception。 使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。 123456789101112131415public class WaitNotifyExample &#123; public synchronized void before() &#123; System.out.println(&quot;before&quot;); notifyAll(); &#125; public synchronized void after() &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;after&quot;); &#125;&#125; 123456public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); WaitNotifyExample example = new WaitNotifyExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());&#125; 12beforeafter wait() 和 sleep() 的区别 wait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法； wait() 会释放锁，sleep() 不会。 await() signal() signalAll()java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。 使用 Lock 来获取一个 Condition 对象。 1234567891011121314151617181920212223242526public class AwaitSignalExample &#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void before() &#123; lock.lock(); try &#123; System.out.println(&quot;before&quot;); condition.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void after() &#123; lock.lock(); try &#123; condition.await(); System.out.println(&quot;after&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 123456public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); AwaitSignalExample example = new AwaitSignalExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());&#125; 12beforeafter","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://tang7o.cn/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://tang7o.cn/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"JWT","slug":"JWT","date":"2021-10-06T12:57:20.000Z","updated":"2022-04-13T13:31:48.070Z","comments":true,"path":"2021/10/06/JWT/","link":"","permalink":"https://tang7o.cn/2021/10/06/JWT/","excerpt":"","text":"什么是JWT？JWT官网 JSON Web Token (JWT)是一个开放标准(RFC 7519)，它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息。该信息可以被验证和信任，因为它是数字签名的。 什么时候用JWT？ 授权：这是使用JWT最常见的场景。用户登录后，每个后续请求都将包含JWT，允许用户访问该令牌允许的路由、服务和资源。单点登录是当今广泛使用JWT的一项功能，因为它的开销很小，并且能够轻松跨不同域使用。 信息交换：对于安全的在各方之间传输信息而言，JSON Web Tokens无疑是一种很好的方式。因为JWT可以被签名，例如，用公钥/私钥对，你可以确定发送人就是它们所说的那个人。另外，由于签名是使用头和有效负载计算的，您还可以验证内容没有被篡改。 JWT结构JSON Web Token由三部分组成，它们之间用圆点(.)连接。这三部分分别是： Header Payload Signature 因此，一个典型的JWT看起来是这个样子的：xxxxx.yyyyy.zzzzz 接下来，具体看一下每个部分： HeaderHeader典型的由两部分组成：token的类型（JWT）和加密算法的名称（比如：SHA256或者RSA等等）。 例如 1234&#123; &#x27;alg&#x27;: &quot;HS256&quot;, &#x27;typ&#x27;: &quot;JWT&quot;&#125; 然后使用Base64对这个JSON编码就得到JWT的第一部分。 PayloadPayload包含声明（要求）。声明是关于实体(通常是用户)和其他数据的声明。声明有三种类型: registered, public 和 private。 Registered claims : 这里有一组预定义的声明，它们不是强制的，但是推荐。比如：iss (issuer), exp (expiration time), sub (subject), aud (audience)等。 Public claims : 可以随意定义。 Private claims : 用于在同意使用它们的各方之间共享信息，并且不是注册的或公开的声明。 下面是一个例子： 12345&#123; &quot;sub&quot;: &quot;1234567890&quot;, &quot;name&quot;: &quot;tang&quot;, &quot;admin&quot;: true&#125; 然后将其进行base64加密，得到Jwt的第二部分。 请注意，对于已签名的令牌，此信息虽然受到防篡改保护，但任何人都可以读取。除非加密，否则不要将机密信息放在 JWT 的负载或标头元素中。 SignatureJWT的第三部分是一个签证信息，这个签证信息由三部分组成： header (base64后的) payload (base64后的) secret 这个部分需要base64加密后的header和base64加密后的payload使用.连接组成的字符串，然后通过header中声明的加密方式进行加盐secret组合加密，然后就构成了jwt的第三部分。 1HMACSHA256(base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload), secret) 将这三部分用.连接成一个完整的字符串,构成了最终的jwt 注意：secret是保存在服务器端的，jwt的签发生成也是在服务器端的，secret就是用来进行jwt的签发和jwt的验证，所以，它就是你服务端的私钥，在任何场景都不应该流露出去。一旦客户端得知这个secret, 那就意味着客户端是可以自我签发jwt了。 基于Token的身份认证 与 基于服务器的身份认证基于服务器的身份认证在讨论基于Token的身份认证是如何工作的以及它的好处之前，我们先来看一下以前我们是怎么做的： HTTP协议是无状态的，也就是说，如果我们已经认证了一个用户，那么他下一次请求的时候，服务器不知道我是谁，我们必须再次认证 传统的做法是将已经认证过的用户信息存储在服务器上，比如Session。用户下次请求的时候带着Session ID，然后服务器以此检查用户是否认证过。 这种基于服务器的身份认证方式存在一些问题： Sessions : 每次用户认证通过以后，服务器需要创建一条记录保存用户信息，通常是在内存中，随着认证通过的用户越来越多，服务器的在这里的开销就会越来越大。 Scalability : 由于Session是在内存中的，这就带来一些扩展性的问题。 CORS : 当我们想要扩展我们的应用，让我们的数据被多个移动设备使用时，我们必须考虑跨资源共享问题。当使用AJAX调用从另一个域名下获取资源时，我们可能会遇到禁止请求的问题。 CSRF : 用户很容易受到CSRF攻击。 JWT与Session的差异相同点是，它们都是存储用户信息；然而，Session是在服务器端的，而JWT是在客户端的。 Session方式存储用户信息的最大问题在于要占用大量服务器内存，增加服务器的开销。 而JWT方式将用户状态分散到了客户端中，可以明显减轻服务端的内存压力。 Session的状态是存储在服务器端，客户端只有session id；而Token的状态是存储在客户端。 基于Token的身份认证基于Token的身份认证是无状态的，服务器或者Session中不会存储任何用户信息。 没有会话信息意味着应用程序可以根据需要扩展和添加更多的机器，而不必担心用户登录的位置。 虽然这一实现可能会有所不同，但其主要流程如下： 用户使用用户名密码来请求服务器 服务器进行验证用户的信息 服务器通过验证发送给用户一个token 客户端存储token，并在每次请求时附送上这个token值 服务端验证token值，并返回数据 注意： 每一次请求都需要token Token应该放在请求header中 我们还需要将服务器设置为接受来自所有域的请求，用Access-Control-Allow-Origin: * 用Token的好处 无状态和可扩展性：Tokens存储在客户端。完全无状态，可扩展。我们的负载均衡器可以将用户传递到任意服务器，因为在任何地方都没有状态或会话信息。 安全：Token不是Cookie。（The token, not a cookie.）每次请求的时候Token都会被发送。而且，由于没有Cookie被发送，还有助于防止CSRF攻击。即使在你的实现中将token存储到客户端的Cookie中，这个Cookie也只是一种存储机制，而非身份认证机制。没有基于会话的信息可以操作，因为我们没有会话! 还有一点，token在一段时间以后会过期，这个时候用户需要重新登录。这有助于我们保持安全。还有一个概念叫token撤销，它允许我们根据相同的授权许可使特定的token甚至一组token无效。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"JWT","slug":"JWT","permalink":"https://tang7o.cn/tags/JWT/"}]},{"title":"线程安全的实现方法","slug":"线程安全的实现方法","date":"2021-10-06T07:38:13.000Z","updated":"2022-04-13T13:31:49.181Z","comments":true,"path":"2021/10/06/线程安全的实现方法/","link":"","permalink":"https://tang7o.cn/2021/10/06/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95/","excerpt":"","text":"1.互斥同步synchronized 和 ReentrantLock。 2.非阻塞同步互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。 互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁(这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁)、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。 (一)CAS随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施(不断地重试，直到成功为止)。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。 乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是: 比较并交换(Compare-and-Swap，CAS)。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。 (二)AtomicIntegerJ.U.C 包里面的整数原子类 AtomicInteger，其中的 compareAndSet() 和 getAndIncrement() 等方法都使用了 Unsafe 类的 CAS 操作。 以下代码使用了 AtomicInteger 执行了自增的操作。 12345private AtomicInteger cnt = new AtomicInteger();public void add() &#123; cnt.incrementAndGet();&#125; 以下代码是 incrementAndGet() 的源码，它调用了 unsafe 的 getAndAddInt()。 123public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 以下代码是 getAndAddInt() 源码，var1 指示对象内存地址，var2 指示该字段相对对象内存地址的偏移，var4 指示操作需要加的数值，这里为 1。通过 getIntVolatile(var1, var2) 得到旧的预期值，通过调用 compareAndSwapInt() 来进行 CAS 比较，如果该字段内存地址中的值等于 var5，那么就更新内存地址为 var1+var2 的变量为 var5+var4。 可以看到 getAndAddInt() 在一个循环中进行，发生冲突的做法是不断的进行重试。 12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; (三)ABA如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。 J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。 3.无同步方案要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。 (一)栈封闭多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。 123456789101112import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class StackClosedExample &#123; public void add100() &#123; int cnt = 0; for (int i = 0; i &lt; 100; i++) &#123; cnt++; &#125; System.out.println(cnt); &#125;&#125; 1234567public static void main(String[] args) &#123; StackClosedExample example = new StackClosedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; example.add100()); executorService.execute(() -&gt; example.add100()); executorService.shutdown();&#125; 12100100 (二)线程本地存储(Thread Local Storage)如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。 符合这种特点的应用并不少见，大部分使用消费队列的架构模式(如“生产者-消费者”模式)都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”(Thread-per-Request)的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。 可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。 对于以下代码，thread1 中设置 threadLocal 为 1，而 thread2 设置 threadLocal 为 2。过了一段时间之后，thread1 读取 threadLocal 依然是 1，不受 thread2 的影响。 123456789101112131415161718192021public class ThreadLocalExample &#123; public static void main(String[] args) &#123; ThreadLocal threadLocal = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; &#123; threadLocal.set(1); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(threadLocal.get()); threadLocal.remove(); &#125;); Thread thread2 = new Thread(() -&gt; &#123; threadLocal.set(2); threadLocal.remove(); &#125;); thread1.start(); thread2.start(); &#125;&#125; 输出结果 11 为了理解 ThreadLocal，先看以下代码: 12345678910111213141516public class ThreadLocalExample1 &#123; public static void main(String[] args) &#123; ThreadLocal threadLocal1 = new ThreadLocal(); ThreadLocal threadLocal2 = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; &#123; threadLocal1.set(1); threadLocal2.set(1); &#125;); Thread thread2 = new Thread(() -&gt; &#123; threadLocal1.set(2); threadLocal2.set(2); &#125;); thread1.start(); thread2.start(); &#125;&#125; 它所对应的底层结构图为: 每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象，Thread 类中就定义了 ThreadLocal.ThreadLocalMap 成员。 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-&gt;value 键值对插入到该 Map 中。 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; get() 方法类似。 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; ThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。 在一些场景 (尤其是使用线程池) 下，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal 有内存泄漏的情况，应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。 (三)可重入代码(Reentrant Code)这种代码也叫做纯代码(Pure Code)，可以在代码执行的任何时刻中断它，转而去执行另外一段代码(包括递归调用它本身)，而在控制权返回后，原来的程序不会出现任何错误。 可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://tang7o.cn/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://tang7o.cn/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"Roaring Bitmap","slug":"Roaring-Bitmap","date":"2021-10-05T08:59:57.000Z","updated":"2022-04-13T13:31:48.353Z","comments":true,"path":"2021/10/05/Roaring-Bitmap/","link":"","permalink":"https://tang7o.cn/2021/10/05/Roaring-Bitmap/","excerpt":"","text":"说到Roaring bitmaps，就必须先从bitmap说起。Bitmap是一种数据结构，假设有某个list：[1,3,4,7,10] 对应的bitmap就是：[1,0,1,1,0,0,1,0,0,1] 非常直观，用0/1表示某个值是否存在，比如10这个值就对应第10位，对应的bit值是1，这样用一个字节就可以代表8个文档id，旧版本(5.0之前)的Lucene就是用这样的方式来压缩的，但这样的压缩方式仍然不够高效，如果有1亿个文档，那么需要12.5MB的存储空间，这仅仅是对应一个索引字段(我们往往会有很多个索引字段)。于是有人想出了Roaring bitmaps这样更高效的数据结构。 主要思想我们以存放 Integer 值的 Bitmap 来举例，RBM 把一个 32 位的 Integer 划分为高 16 位和低 16 位，通过高 16 位找到该数据存储在哪个桶中（高 16 位可以划分 2^16 个桶），把剩余的低 16 位放入该桶对应的 Container 中。 每个桶都有对应的 Container，不同的 Container 存储方式不同。依据不同的场景，主要有 2 种不同的 Container，分别是 Array Container 和 Bitmap Container。Array Container 存放稀疏的数据，Bitmap Container 存放稠密的数据。若一个 Container 里面的元素数量小于 4096，使用 Array Container 来存储。当 Array Container 超过最大容量 4096 时，会转换为 Bitmap Container。 Array ContainerArray Container 是 Roaring Bitmap 初始化默认的 Container。Array Container 适合存放稀疏的数据，其内部数据结构是一个有序的 Short 数组。数组初始容量为 4，数组最大容量为 4096，所以 Array Container 是动态变化的，当容量不够时，需要扩容，并且当超过最大容量 4096 时，就会转换为 Bitmap Container。由于数组是有序的，存储和查询时都可以通过二分查找快速定位其在数组中的位置。 下面我们具体看一下数据如何被存储的，例如，0x00020032（十进制131122）放入一个 RBM 的过程如下图所示： 0x00020032 的前 16 位是 0002，找到对应的桶 0x0002。在桶对应的 Container 中存储低 16 位，因为 Container 元素个数不足 4096，因此是一个 Array Container。低 16 位为 0032（十进制为50）, 在 Array Container 中二分查找找到相应的位置插入即可（如上图50的位置）。 相较于原始的 Bitmap 需要占用 16K (131122/8/1024) 内存来存储这个数，而这种存储实际只占用了4B（桶中占 2 B，Container中占 2 B，不考虑数组的初始容量）。 Bitmap Container第二种 Container 是 Bitmap Container。它的数据结构是一个 Long 数组，数组容量恒定为 1024，和上文的 Array Container 不同，Array Container 是一个动态扩容的数组。Bitmap Container 不用像 Array Container 那样需要二分查找定位位置，而是可以直接通过下标直接寻址。 由于每个 Bitmap Container 需要处理低 16 位数据，也就是需要使用 Bitmap 来存储需要 8192 B（2^16/8）, 而一个 Long 值占 8 个 B，所以数组大小为 1024。因此一个 Bitmap Container 固定占用内存 8 KB。 下面我们具体看一下数据如何被存储的，例如，0xFFFF3ACB（十进制4294916811）放入一个 RBM 的过程如下图所示： 0xFFFF3ACB 的前 16 位是 FFFF，找到对应的桶 0xFFFF。在桶对应的 Container 中存储低 16 位，因为 Container 中元素个数已经超过 4096，因此是一个 Bitmap Container。低 16 位为 3ACB（十进制为15051）, 因此在 Bitmap Container 中通过下标直接寻址找到相应的位置，将其置为 1 即可（如上图15051的位置）。 为什么超过最大容量 4096 时变更 Container 类型。 可以看到元素个数达到 4096 之前，Array Container 占用的空间比 Bitmap Container 的少，当 Array Container 中元素到 4096 个时，正好等于 Bitmap Container 所占用的 8 KB。当元素个数超过了 4096 时，Array Container 所占用的空间还是继续线性增长，而 Bitmap Container 的内存空间并不会增长，始终还是占用 8 KB，与数据量无关。所以当 Array Container 超过最大容量 4096 会转换为 Bitmap Container。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Roaring Bitmap","slug":"Roaring-Bitmap","permalink":"https://tang7o.cn/tags/Roaring-Bitmap/"}]},{"title":"Elasticsearch","slug":"Elasticsearch","date":"2021-10-04T05:26:17.000Z","updated":"2022-04-13T13:31:47.967Z","comments":true,"path":"2021/10/04/Elasticsearch/","link":"","permalink":"https://tang7o.cn/2021/10/04/Elasticsearch/","excerpt":"","text":"介绍Elasticsearch 是一个分布式可扩展的实时搜索和分析引擎,一个建立在全文搜索引擎 Apache Lucene(TM) 基础上的搜索引擎.当然 Elasticsearch 并不仅仅是 Lucene 那么简单，它不仅包括了全文搜索功能，还可以进行以下工作: 分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。 实时分析的分布式搜索引擎。 可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。 基本概念先说Elasticsearch的文件存储，Elasticsearch是面向文档型数据库，一条数据在这里就是一个文档，用JSON作为文档序列化的格式，比如下面这条用户数据： 12345678&#123; &quot;name&quot; : &quot;John&quot;, &quot;sex&quot; : &quot;Male&quot;, &quot;age&quot; : 25, &quot;birthDate&quot;: &quot;1990/05/01&quot;, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125; 用Mysql这样的数据库存储就会容易想到建立一张User表，有balabala的字段等，在Elasticsearch里这就是一个文档，当然这个文档会属于一个User的类型，各种各样的类型存在于一个索引当中。这里有一份简易的将Elasticsearch和关系型数据术语对照表: 关系数据库 Elasticsearch 数据库 索引(Index) 表 类型(type) 行 文档(Docments) 列(Columns) 字段(Fields) 一个 Elasticsearch 集群可以包含多个索引(数据库)，也就是说其中包含了很多类型(表)。这些类型中包含了很多的文档(行)，然后每个文档中又包含了很多的字段(列)。Elasticsearch的交互，可以使用Java API，也可以直接使用HTTP的Restful API方式，比如我们打算插入一条记录，可以简单发送一个HTTP的请求： 12345678PUT /megacorp/employee/1 &#123; &quot;name&quot; : &quot;John&quot;, &quot;sex&quot; : &quot;Male&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125; 索引Elasticsearch索引的精髓： 一切设计都是为了提高搜索的性能 另一层意思：为了提高搜索的性能，难免会牺牲某些其他方面，比如插入/更新，否则其他数据库不用混了。前面看到往Elasticsearch里插入一条记录，其实就是直接PUT一个json的对象，这个对象有多个fields，比如上面例子中的name, sex, age, about, interests，那么在插入这些数据到Elasticsearch的同时，Elasticsearch还默默的为这些字段建立索引—倒排索引，因为Elasticsearch最核心功能是搜索。 什么是倒排索引?继续上面的例子，假设有这么几条数据(为了简单，去掉about, interests这两个field): ID Name Age Sex 1 Kate 24 Female 2 John 24 Male 3 Bill 29 Male D是Elasticsearch自建的文档id，那么Elasticsearch建立的索引如下: Name: Term Posting List Kate 1 John 2 Bill 3 Age: Term Posting List 24 [1,2] 29 3 Sex: Term Posting List Female 1 Male [2,3] Posting ListElasticsearch分别为每个field都建立了一个倒排索引，Kate, John, 24, Female这些叫term，而[1,2]就是Posting List。Posting list就是一个int的数组，存储了所有符合某个term的文档id。 通过posting list这种索引方式似乎可以很快进行查找，比如要找age=24的同学，爱回答问题的小明马上就举手回答：我知道，id是1，2的同学。但是，如果这里有上千万的记录呢？如果是想通过name来查找呢？ Term DictionaryElasticsearch为了能快速找到某个term，将所有的term排个序，二分法查找term，logN的查找效率，就像通过字典查找一样，这就是Term Dictionary。现在再看起来，似乎和传统数据库通过B-Tree的方式类似啊，为什么说比B-Tree的查询快呢？ Term IndexB-Tree通过减少磁盘寻道次数来提高查询性能，Elasticsearch也是采用同样的思路，直接通过内存查找term，不读磁盘，但是如果term太多，term dictionary也会很大，放内存不现实，于是有了Term Index，就像字典里的索引页一样，A开头的有哪些term，分别在哪页，可以理解term index是一颗树： 这棵树不会包含所有的term，它包含的是term的一些前缀。通过term index可以快速地定位到term dictionary的某个offset，然后从这个位置再往后顺序查找。 所以term index不需要存下所有的term，而仅仅是他们的一些前缀与Term Dictionary的block之间的映射关系，再结合FST(Finite State Transducers)的压缩技术，可以使term index缓存到内存中。从term index查到对应的term dictionary的block位置之后，再去磁盘上找term，大大减少了磁盘随机读的次数。 FST是什么？ FSTs are finite-state machines that map a term (byte sequence) to an arbitrary output. 假设我们现在要将mop, moth, pop, star, stop and top(term index里的term前缀)映射到序号：0，1，2，3，4，5(term dictionary的block位置)。最简单的做法就是定义个Map，大家找到自己的位置对应入座就好了，但从内存占用少的角度想想，有没有更优的办法呢？答案就是：FST 圈表示一种状态 —&gt;表示状态的变化过程，上面的字母/数字表示状态变化和权重 将单词分成单个字母通过圈和—&gt;表示出来，0权重不显示。如果圈后面出现分支，就标记权重，最后整条路径上的权重加起来就是这个单词对应的序号。 FST以字节的方式存储所有的term，这种压缩方式可以有效的缩减存储空间，使得term index足以放进内存，但这种方式也会导致查找时需要更多的CPU资源。 压缩技巧Frame Of ReferenceElasticsearch里除了上面说到用FST压缩term index外，对posting list也有压缩技巧。 增量编码压缩，将大数变小数，按字节存储 首先，Elasticsearch要求posting list是有序的(为了提高搜索的性能，再任性的要求也得满足)，这样做的一个好处是方便压缩，看下面这个图例： 原理就是通过增量，将原来的大数变成小数仅存储增量值，再精打细算按bit排好队，最后通过字节存储，而不是大大咧咧的尽管是2也是用int(4个字节)来存储。 Roaring bitmaps参考这篇文章 联合索引上面说了半天都是单field索引，如果多个field索引的联合查询，倒排索引如何满足快速查询的要求呢？ 利用跳表(Skip list)的数据结构快速做“与”运算，或者 利用上面提到的bitset按位“与” 先看看跳表的数据结构： 将一个有序链表level0，挑出其中几个元素到level1及level2，每个level越往上，选出来的指针元素越少，查找时依次从高level往低查找，比如55，先找到level2的31，再找到level1的47，最后找到55，一共3次查找，查找效率和2叉树的效率相当，但也是用了一定的空间冗余来换取的。 假设有下面三个posting list需要联合索引： 如果使用跳表，对最短的posting list中的每个id，逐个在另外两个posting list中查找看是否存在，最后得到交集的结果。 如果使用bitset，就很直观了，直接按位与，得到的结果就是最后的交集。 总结和思考Elasticsearch的索引思路: 将磁盘里的东西尽量搬进内存，减少磁盘随机读取次数(同时也利用磁盘顺序读特性)，结合各种奇技淫巧的压缩算法，用及其苛刻的态度使用内存。 所以，对于使用Elasticsearch进行索引时需要注意: 不需要索引的字段，一定要明确定义出来，因为默认是自动建索引的 同样的道理，对于String类型的字段，不需要分词的也需要明确定义出来，因为默认也是会分词的 选择有规律的ID很重要，随机性太大的ID(比如java的UUID)不利于查询 关于最后一点，个人认为有多个因素: 其中一个(也许不是最重要的)因素: 上面看到的压缩算法，都是对Posting list里的大量ID进行压缩的，那如果ID是顺序的，或者是有公共前缀等具有一定规律性的ID，压缩比会比较高； 另外一个因素: 可能是最影响查询性能的，应该是最后通过Posting list里的ID到磁盘中查找Document信息的那步，因为Elasticsearch是分Segment存储的，根据ID这个大范围的Term定位到Segment的效率直接影响了最后查询的性能，如果ID是有规律的，可以快速跳过不包含该ID的Segment，从而减少不必要的磁盘读次数。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://tang7o.cn/tags/Elasticsearch/"}]},{"title":"Kafka","slug":"Kafka","date":"2021-10-02T12:57:02.000Z","updated":"2022-04-13T13:31:48.162Z","comments":true,"path":"2021/10/02/Kafka/","link":"","permalink":"https://tang7o.cn/2021/10/02/Kafka/","excerpt":"","text":"KafkaKafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据，具有高性能、持久化、多副本备份、横向扩展能力……… 一些基本的介绍这里就不展开了，网上有太多关于这些的介绍了，读者可以自行百度一下！ 基础架构及术语 Producer：消息的生产者，是消息的入口。 kafka cluster： Broker：broker是kafka的实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个不重复的编号。 Topic：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。 Partition：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！ Replication：每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器上，同一机器对同一个分区也只可能存放一个副本（包括自己）。 Message：每一条发送的消息主体。 Consumer：消费者，即消息的消费方，是消息的出口。 Consumer Group：我们可以将多个消费者组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！ Zookeeper：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。 工作流程发生数据Producer在写入数据的时候永远找leader，不会直接将数据写入follower！写入的流程如下图所示： 消息写入learder后，follower是主动的去leader进行同步的！producer采用push模式将数据发不到broker，每条数据追加到分区中，顺序写入磁盘，所以保证同一分区内的数据是有序的！写入示意图如下图所示： 上面说到数据会写入不同的分区，那么kafka为什么要分区呢？ 方便扩展：因为一个topic可以有多个partition，所以我们可以通过扩展机器去轻松的应对日益增长的数据量。 提高并发：以partiton为读写单位，可以多个消费者同时消费数据，提高了消息的处理效率。 熟悉负载均衡的朋友应该知道，当我们向某个服务器发送请求的时候，服务端可能会对请求做一个负载，将流量分发到不同的服务器，那在kafka中，如果某个topic有多个partition，producer又怎么知道该将数据发往哪个partition呢？kafka中有几个原则： 如果写入时指定了partition，那么直接使用指定的。 如果没有指定partition，但是设置了数据的key，那么根据key的值hash出一个partiton。 如果既没有指定partition又没有设置key，则会轮询出一个partiton。 保证消息不丢失是一个消息队列中间件的基本保证，kafka是如何保证消息不丢失的呢？其实上面的写入流程图中已经描述出来了，那就是通过ACK应答机制！在producer写入数据时可以通过设置参数来确定是否确认kafka接受到数据，这个参数的可设置的值为0、1、all。 0：代表producer往集群中发送数据不需要等到集群的确认，不确保消息发送成功。安全性最低但是效率最高。 1：代表producer往集群中发送数据只要等到leader的确认就可以发送下一条，只确保leader发送成功。 all：代表producer往集群中发送数据需要所有的follower都完成从leader的同步才会发送下一条，确保leader发送成功和所有的副本完成备份。安全性最高但效率最低。 如果向不存在的topic中写数据，kafka会自动创建topic，分区和副本的数量根据默认配置是1。 保存数据Producer将数据写入kafka后，集群就需要对数据进行保存了！kafka将数据保存在磁盘，可能在我们的一般的认知里，写入磁盘是比较耗时的操作，不适合这种高并发的组件。Kafka初始会单独开辟一块磁盘空间，顺序写入数据（效率比随机写入高的多）。 Partition结构Partition在服务器上的表现形式就是一个一个的文件夹，每个partition的文件夹下面会有多组segment文件，每组segment文件又包含.index文件、.log文件、.timeindex文件（早期版本中没有）三个文件， log文件就实际是存储message的地方，而index和timeindex文件为索引文件，用于检索消息。 如上图，这个partition有三组segment文件，每个log文件的大小是一样的，但是存储的message数量是不一定相等的（每条的message大小不一致）。文件的命名是以该segment最小offset来命名的，如0000.index存储offset为0~368795的消息，kafka就是利用分段+索引的方式来解决查找效率的问题。 .index文件：偏移量索引文件，每个索引项共占用8个字节，并分为两部分。相对偏移量（offset）和物理地址（position）。 相对偏移量：表示消息相对与基准偏移量的偏移量，占4个字节。 物理地址：消息在日志分段文件中对应的物理位置，也占4个字节。 .log：日志文件，存储具体的消息。 .timeindex：时间戳索引文件，每个索引项共占用12个字节，并分为两部分。相对偏移量（4字节）和时间戳（八个字节）。 kafka采用稀疏存储的方式，因此.index和.timeindex文件并不会为没一条消息建立索引，而是每隔一定的字节数建立一条索引。 Message结构上面说到log文件就实际是存储message的地方，我们在producer往kafka写入的也是一条一条的message，那存储在log中的message是什么样子的呢？消息主要包含消息体、消息大小、offset、压缩类型……等等！我们重点需要知道的是下面三个： 1. offset：offset是一个占8byte的有序id号，它可以唯一确定每条消息在parition内的位置！ 2. 消息大小：消息大小占用4byte，用于描述消息的大小。 3. 消息体：消息体存放的是实际的消息数据（被压缩过），占用的空间根据具体的消息而不一样。 存储策略无论消息是否被消费，kafka都会保存所有的消息。那么对于旧消息有什么删除策略呢？ 基于时间，默认配置为7天。 基于大小，默认配置为1073741824。 需要注意的是，kafka读取特定消息的时间复杂度是O(1),所以删除过期的消息并不会提高kafka的性能！ 消费数据消息存储在log文件后，消费者就可以进行消费了。与生产消息相同的是，消费者在拉取消息时也是找leader去拉取的。 多个消费者可以组成一个消费者组（consumer group），每个消费者组都有一个组id！同一个消费者组的消费者可以消费同一个topic下的不同分区的数据，但不会组内多个消费者消费同一个分区的数据。 上图是消费者组内的消费者小于partition数量的情况，所以会出现某个消费者消费多个partition的情况，消费的速度不如只消费一个partition的速度。如果是消费者组的消费者多于partition的数量，那会不会出现多个消费者消费同一个partition的数据呢？上面已经提到过不会出现这种情况！多出来的消费者不消费任何partition的数据。所以在实际的应用中，建议消费者组的consumer的数量与partition的数量一致！ 在保存数据的小节里面，我们聊到了partition划分为多组segment，每个segment又包含.log、.index、.timeindex文件，存放的每条message包含offset、消息大小、消息体……我们多次提到segment和offset，查找消息的时候是怎么利用segment+offset配合查找的呢？假如现在需要查找一个offset为368801的message是什么样的过程呢？我们先看看下面的图：（.index中的’,’是用来区分偏移量和物理地址的标记） 先找到offset为368801的message所在的segment文件（利用二分法查找），这里找到的就是在第二个segment文件。 打开找到的segment中的.index文件（也就是368796.index文件，该文件起始偏移量为368796+1，我们要查找的offset为368801的message在该index内的偏移量为368796+5=368801，所以这里要查找的相对offset为5）。由于该文件采用的是稀疏索引的方式存储着相对offset及对应message物理偏移量的关系，所以直接找相对offset为5的索引找不到，这里同样利用二分法查找相对offset小于或者等于指定的相对offset的索引条目中最大的那个相对offset，所以找到的是相对offset为4的这个索引。 根据找到的相对offset为4的索引确定message存储的物理偏移位置为256。打开数据文件，从位置为256的那个地方开始顺序扫描直到找到offset为368801的那条Message。 这套机制是建立在offset为有序的基础上，利用segment+有序offset+稀疏索引+二分查找+顺序查找等多种手段来高效的查找数据！至此，消费者就能拿到需要处理的数据进行处理了。那每个消费者又是怎么记录自己消费的位置呢？在早期的版本中，消费者将消费到的offset维护zookeeper中，consumer每间隔一段时间上报一次，这里容易导致重复消费，且性能不好！在新的版本中消费者消费到的offset已经直接维护在kafk集群的__consumer_offsets这个topic中！ Kafka中的ISR、AR代表什么？ISR的伸缩指什么？ ISR：In-Sync Replicas 副本同步队列 AR:Assigned Replicas 所有副本 ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度，当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR，存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。 AR=ISR+OSR。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://tang7o.cn/tags/Kafka/"}]},{"title":"HTTPS加密过程","slug":"https加密过程","date":"2021-09-28T01:54:07.000Z","updated":"2022-04-13T13:31:48.564Z","comments":true,"path":"2021/09/28/https加密过程/","link":"","permalink":"https://tang7o.cn/2021/09/28/https%E5%8A%A0%E5%AF%86%E8%BF%87%E7%A8%8B/","excerpt":"","text":"HTTPS的加密过程/原理 1、服务器将携带的公钥向数字证书机构申请证书。 2、数字证书机构用自己的私钥对公钥签名颁发证书，并返回给服务器。 3、服务器将申请携带公钥的证书分发给客服端。 4、客户端验证证书，证书机构通过验证，或者用户接受不受信任的证书(非权威机构颁发的证书)。获取到公钥。到这一步，在证书保证下服务器拥有私钥，客户端拥有公钥，可进行非对称性加密。 5、使用公钥加密报文发送给服务器，其中携带随机串。其中的随机串用户传输数据时进行对称加密 6、服务器使用私钥解密。获取报文信息及随机串。 7、解密后服务器发送握手消息给客户端。 8、客户端接受握手消息，握手结束，双方确定加密算法(使用随机串确定的对称性加密)，开始传输。 注意： 确认加密算法的过程使用的是非对称性加密。 数据传输过程使用对称性加密","categories":[{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"},{"name":"HTTPS","slug":"网络/HTTPS","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/HTTPS/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://tang7o.cn/tags/HTTPS/"}]},{"title":"为什么ArrayList每次扩容1.5倍","slug":"为什么ArrayList每次扩容1-5倍","date":"2021-09-23T01:41:12.000Z","updated":"2022-04-13T13:31:48.765Z","comments":true,"path":"2021/09/23/为什么ArrayList每次扩容1-5倍/","link":"","permalink":"https://tang7o.cn/2021/09/23/%E4%B8%BA%E4%BB%80%E4%B9%88ArrayList%E6%AF%8F%E6%AC%A1%E6%89%A9%E5%AE%B91-5%E5%80%8D/","excerpt":"","text":"ArrayList底层是数组elementData，用来存放插入的数据。初始大小0，有数据插入时，默认大小DEFAULT_CAPACITY = 10。 什么时候扩容当插入数据，导致size+1&gt;elementData.length时，开始扩容。（就是存不下了） 123456789101112131415161718192021222324public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! // add一个元素时，size + 1 elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); &#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; // 计算新容量 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 代表elementData数组还是一个空数组，没有任何数据 return Math.max(DEFAULT_CAPACITY, minCapacity); // elementData为空时，会扩容到DEFAULT_CAPACITY = 10和minCapacity的最大值，而minCapacity在插入数据时第一次值为1（size + 1 = 1），会扩容为10 &#125; return minCapacity;&#125; 如何扩容？新数组容量为旧数组的1.5倍：newCapacity = 1.5 * oldCapacity ，并且将旧数组内容通过Array.copyOf全部复制到新数组。此时，size还未真正+1，新旧数组长度（size一致），不过容量不同。把这里的系数1.5，称作扩容因子k = newCapacity / oldCapacity。 12345678910111213141516171819202122232425/*** Increases the capacity to ensure that it can hold at least the* number of elements specified by the minimum capacity argument.** @param minCapacity the desired minimum capacity*/private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 扩容因子为何是1.5？扩容因子最合适的范围为（1，2）。 当扩容因子 k = 2 时，每次扩容后的容量刚好大于之前分配的总和： c\\sum_{i=0}^n2^i=c(2^{n+1}-1)\\;","categories":[],"tags":[]},{"title":"SQL语句优化","slug":"SQL语句优化","date":"2021-09-13T01:08:32.000Z","updated":"2022-04-13T13:31:48.367Z","comments":true,"path":"2021/09/13/SQL语句优化/","link":"","permalink":"https://tang7o.cn/2021/09/13/SQL%E8%AF%AD%E5%8F%A5%E4%BC%98%E5%8C%96/","excerpt":"","text":"1.避免SELECT *SELECT中每少提取一个字段，数据的提取速度就会有相应的提升。提升的速度还要看舍弃的字段大小来判断。 2.建立索引根据自己的需求适当建立索引，单个索引或者联合索引。mysql建立联合索引时注意最左匹配原则。 3.避免在列上运算，这样会导致索引失效1SELECT name, score FROM t WHERE score/10 = 9; 改为 1SELECT name, score FROM t WHERE score = 10 * 9; 4.使用JOIN时应该用小结果集驱动大结果集，同时把复杂的JOIN查询拆分为多个查询，因为JOIN多个表可能导致更多的锁和堵塞。可以用JOIN代替复杂的字查询。 5.使用LIKE时避免使用全模糊查询’%%’,因最左匹配这样不会走索引，会全表扫描。 1SELECT name, score FROM t WHERE name LIKE &#x27;%王%&#x27;; 改为 1SELECT name, score FROM t WHERE name LIKE &#x27;王%&#x27;; 6. 避免使用null值的判断null不走索引。 可以给字段一个默认值，比如0。 1SELECT name, score FROM t WHERE score IS NULL; 改为 1SELECT name, score FROM t WHERE score = 0; 7. 避免使用oror会走全表扫描 1SELECT name, score FROM t WHERE score = 30 OR score = 40; 改为 123SELECT name, score FROM t WHERE score = 30UNIONSELECT name, score FROM t WHERE score = 40; 8.避免使用in和not in12SELECT name, score FROM t WHERE score IN (2,3);SELECT name, score FROM t WHERE score IN (SELECT score FROM t1); 优化方式：如果是连续的值，可以用between代替。如下： 1SELECT name, score FROM t WHERE score BETWEEN 2 AND 3; 如果是子查询,可以用exists代替。如下： 1SELECT name, score FROM t WHERE EXISTS (SELECT * FROM t1 WHERE t.name = t1.name); 9.LIMITlimit基数比较大时，使用between，between限定比limit快，但是between也有缺陷，如果id中间有断行或者是中间有部分id不读取的情况，数据会少 1SELECT name, score FROM t WHERE socre = 100 limit 100000, 10; 改为 1SELECT name, score FROM t WHERE socre = 100 BETWEEN 100000 and 100010; 10.慢sql调优找到慢sql的原因，是什么引起慢的。可能是查询条件没有索引，或者查询出来的数据量太大。 查询条件没有索引根据查询条件选择最好的索引字段建立索引。即这个字段的值比较分散相对不集中，且这个字段不能有null值，因为字段值集中枚举较少可能数据库引擎不会走索引；索引字段null值，就不会走索引，会全表扫描。 数据量太大如果是查询出来的数据量太大。导致某一个条件的值查询出来的数据量很多，占了整张表数据量的很大一部分。这就需要对数据进行分析，看看能不能通过查询的必选条件建立索引去除很大一部分数据，或者通过某几个条件可以去除大量数据，然后对这几个条件建立联合索引。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/tags/MySQL/"}]},{"title":"内存溢出和内存泄漏","slug":"内存溢出和内存泄漏","date":"2021-09-12T08:10:43.000Z","updated":"2022-04-13T13:31:48.838Z","comments":true,"path":"2021/09/12/内存溢出和内存泄漏/","link":"","permalink":"https://tang7o.cn/2021/09/12/%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%92%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/","excerpt":"","text":"定义内存泄漏是申请了内存用完了不释放，内存溢出是申请内存时，没有足够的内存可以使用。内存泄漏最终会导致内存溢出，也可以说内存泄漏是内存溢出的一种。 引起内存溢出的原因有那些？ 内存中加载的数据量过于庞大，如一次从数据库中取出过多数据。 集合类中有对对象的引用，使用完未清空，使得JVM不能回收。 代码中存在死循环或循环产生过多重复的对象实体。 使用第三方软件中的BUG 启动参数内存设置的过小 如何解决？ 修改JVM启动参数，直接增加内存。 检查错误日志，查看溢出前是否有其他异常或者错误。 对代码进行检查和分析，找出可能发生内存溢出的位置。 检查代码中是否有死循环或递归调用。 检查是否有循环重复产生新对象实体。 检查对数据库查询中，是否有一次获得全部数据的查询。 检查List、Map等集合对象是否是用完未清除。 使用内存查看工具动态查看内存使用情况。 使用jmap命令。 jmap pid查看共享对象信息。 jmap -head pid查看堆使用情况 jmap -histo pid查看堆中对象数量和大小 jmap -dump:fromat=b,file=heapdump pid将内存使用的详细情况输出到文件。然后可以使用jhat -port 4000 filename查看该文件。 使用jvisualvm、jconsole等JVM可视化工具。 注意事项内存溢出绝大部分时候都是源码层面的问题，在开发过程中需要注意： 尽早释放无用对象的引用 程序里不可避免大量使用字符串时，避免使用String，应使用StringBuffer。 尽量减少静态变量的使用，静态变量是全局的，GC不会回收。 避免集中创建对象尤其是大对象，JVM会突然需要大量内存，这时容易触发GC。 尽量运用对象池技术以提高系统性能。 不要在经常调用的方法中创建对象，尤其是忌讳在循环中创建对象。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://tang7o.cn/categories/Java/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://tang7o.cn/tags/JVM/"}]},{"title":"JVM调优","slug":"JVM调优","date":"2021-09-08T02:56:03.000Z","updated":"2022-04-13T13:31:48.051Z","comments":true,"path":"2021/09/08/JVM调优/","link":"","permalink":"https://tang7o.cn/2021/09/08/JVM%E8%B0%83%E4%BC%98/","excerpt":"","text":"在调优之前，我们需要记住下面的原则： 多数的 Java 应用不需要在服务器上进行 GC 优化； 多数导致 GC问题的 Java 应用，都不是因为我们参数设置错误，而是代码问题； 在应用上线之前，先考虑将机器的 JVM 参数设置到最优（最适合）； 减少创建对象的数量； 减少使用全局变量和大对象； GC 优化是到最后不得已才采用的手段； 在实际使用中，分析 GC 情况优化代码比优化 GC 参数要多得多； GC 调优主要的目的是减少 GC 的频率和 Full GC 的次数。 JVM 调优的一般步骤1. 监控 GC 状态使用各种 JVM 工具，查看当前日志，分析当前 JVM 参数设置，并且分析当前堆内存快照和 gc 日志，根据实际的各区域内存划分和 GC 执行时间，觉得是否进行优化。 jps 查找正在运行的 java 进程。 jstat -gc PID 查看对应进程的 GC 状态。 jmap -histo PID 查看当前堆中所有类的实例数量和内存占用。 也可以使用 jvisualvm 查看以上内容； 2. 分析结果，判断是否需要优化如果各项参数设置合理，系统没有超时日志出现，GC频率不高，GC耗时不高，那么没有必要进行GC优化，如果GC时间超过1-3秒，或者频繁GC，则必须优化。 注：如果满足下面的指标，则一般不需要进行GC： Minor GC执行时间不到50ms； Minor GC执行不频繁，约10秒一次； Full GC执行时间不到1s； Full GC执行频率不算频繁，不低于10分钟1次； 3. 调整 GC 类型和内存分配如果内存分配过大或过小，或者采用的 GC 收集器比较慢，则应该优先调整这些参数，并且先找 1 台或几台机器进行 beta，然后比较优化过的机器和没有优化的机器的性能对比，并有针对性的做出最后选择。 4. 不断的分析和调整通过不断的试验和试错，分析并找到最合适的参数，如果找到了最合适的参数，则将这些参数应用到所有服务器。 JVM 调优参数参考 针对 JVM 堆的设置，一般可以通过 -Xms、-Xmx 限定其最小、最大值，为了防止垃圾收集器在最小、最大之间收缩堆而产生额外的时间，通常把最大、最小设置为相同的值; 年轻代和年老代将根据默认的比例（1：2）分配堆内存， 可以通过调整二者之间的比率NewRadio来调整二者之间的大小，也可以针对回收代。 比如年轻代，通过 -XX:newSize -XX:MaxNewSize来设置其绝对大小。同样，为了防止年轻代的堆收缩，我们通常会把-XX:newSize -XX:MaxNewSize设置为同样大小。 年轻代和年老代设置多大才算合理 更大的年轻代必然导致更小的年老代，大的年轻代会延长普通 GC 的周期，但会增加每次 GC 的时间；小的年老代会导致更频繁的 Full GC 更小的年轻代必然导致更大年老代，小的年轻代会导致普通 GC 很频繁，但每次的 GC 时间会更短；大的年老代会减少 Full GC 的频率 如何选择应该依赖应用程序对象生命周期的分布情况： 如果应用存在大量的临时对象，应该选择更大的年轻代；如果存在相对较多的持久对象，年老代应该适当增大。但很多应用都没有这样明显的特性。 在抉择时应该根 据以下两点： 本着Full GC尽量少的原则，让年老代尽量缓存常用对象，JVM 的默认比例1：2 也是这个道理 。 通过观察应用一段时间，看其他在峰值时年老代会占多少内存，在不影响 Full GC 的前提下，根据实际情况加大年轻代，比如可以把比例控制在 1：1。但应该给年老代至少预留1/3的增长空间。 在配置较好的机器上（比如多核、大内存），可以为年老代选择并行收集算法： -XX:+UseParallelOldGC 。 线程堆栈的设置：每个线程默认会开启 1M 的堆栈，用于存放栈帧、调用参数、局部变量等，对大多数应用而言这个默认值太了，一般 256K 就足用。 理论上，在内存不变的情况下，减少每个线程的堆栈，可以产生更多的线程，但这实际上还受限于操作系统。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://tang7o.cn/categories/Java/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://tang7o.cn/tags/JVM/"}]},{"title":"查找占用内存最多的三个进程","slug":"查找占用内存最多的三个进程","date":"2021-09-07T14:02:15.000Z","updated":"2022-04-13T13:31:49.052Z","comments":true,"path":"2021/09/07/查找占用内存最多的三个进程/","link":"","permalink":"https://tang7o.cn/2021/09/07/%E6%9F%A5%E6%89%BE%E5%8D%A0%E7%94%A8%E5%86%85%E5%AD%98%E6%9C%80%E5%A4%9A%E7%9A%84%E4%B8%89%E4%B8%AA%E8%BF%9B%E7%A8%8B/","excerpt":"","text":"查询使用内存最多的三个进程： ps aux | sort -k3nr | head -n 3 查询使用内存最多的三个进程： ps aux | sort -k4nr | head -n 3 sort： ​ -k [n] 按照第 n 列查询 ​ -n 按照数值排序（10 &gt; 2） ​ -r 降序（默认升序） head -n [k] ：显示前 k 行","categories":[{"name":"Linux","slug":"Linux","permalink":"https://tang7o.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://tang7o.cn/tags/Linux/"}]},{"title":"通过端口查看进程","slug":"通过端口查看进程","date":"2021-08-30T13:46:20.000Z","updated":"2022-04-13T13:31:49.235Z","comments":true,"path":"2021/08/30/通过端口查看进程/","link":"","permalink":"https://tang7o.cn/2021/08/30/%E9%80%9A%E8%BF%87%E7%AB%AF%E5%8F%A3%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B/","excerpt":"","text":"通过 lsof 或者 netstat 命令查找占用端口号的进程ID； 以 80 端口号为例： lsof -i:80 或者 netstat -nlp | grep :80 通过 ps 命令查看进程的详细信息 ps -ef | grep PID","categories":[{"name":"Linux","slug":"Linux","permalink":"https://tang7o.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://tang7o.cn/tags/Linux/"}]},{"title":"MySQL分页查询","slug":"MySQL分页查询","date":"2021-08-20T02:00:54.000Z","updated":"2022-04-13T13:31:48.267Z","comments":true,"path":"2021/08/20/MySQL分页查询/","link":"","permalink":"https://tang7o.cn/2021/08/20/MySQL%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"limit基本格式查询第1条到第10条的数据的sql是： 1select * from table limit 0,10; 对应我们的需求就是查询第一页的数据： 1select * from table limit (1-1)*10,10; 从上面的分析我们可以得出分页sql的格式是： 1select * from table limit (start-1)*limit,limit; 其中start是页码，limit是每页显示的条数。 建立主键或者唯一索引在数据量较小时使用 limit 进行数据分页在性能上不会有明显的缓慢，当数据量达到万级到百万级时，SQL 的语句的性能会影响数据的返回。这时需要利用主键或者唯一索引进行数据分页。 假设主键或者唯一索引为 id。 select * from table where id &gt; (pageNo-1)*pageSize limit pageSize; 基于数据再排序当需要返回的信息为顺序或者倒序时，对上面的语句基于数据再排序。 order by asc/desc，默认为 asc （顺序） 例：返回的数据按照 id 顺序进行排列 select * from table where demo_id &gt; (pageNo-1)*pageSize order by demo_id limit pageSize;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/tags/MySQL/"}]},{"title":"TimSort源码","slug":"TimSort源码","date":"2021-07-13T13:29:45.000Z","updated":"2022-04-13T13:31:48.444Z","comments":true,"path":"2021/07/13/TimSort源码/","link":"","permalink":"https://tang7o.cn/2021/07/13/TimSort%E6%BA%90%E7%A0%81/","excerpt":"","text":"1. 简介TimSort 是一种稳定的, 自适应的变种归并排序. 当被应用在部分有序的数组排序问题时, TimSort 有远好于$O(NlogN)$的时间性能. 而在最差情况下, TimSort 也能保持与传统归并排序相近的表现.从 JDK 1.7 开始被引入并成为 Java 中 Arrays 的默认排序算法. 2. 核心思想TimSort 算法结合了归并排序和插入排序. TimSort 算法为了减少对升序部分的回溯和对降序部分的性能倒退, 将输入按其升序和降序的特点进行了分区. 排序的输入单位不是一个个单独的数字, 而是一个个的分区. 每一个分区叫一个 run, 针对这些 run 进行排序. 每次拿出来两个 run 按照规则进行合并, 合并成一个 run 压入栈中. 直到栈中只剩一个 run. 这个 run 就是排序好的结果. 算法过程: 如果输入数组长度小于 32, 直接使用二分插入排序. 找到每个 run, 压入栈. 按照规则合并. 3. 源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753class TimSort&lt;T&gt; &#123; /** * 使用 TimSort 算法的阈值, 小于此值使用 二分插入排序. */ private static final int MIN_MERGE = 32; /** * 待排序的数组 */ private final T[] a; /** * 比较器(排序规则) */ private final Comparator&lt;? super T&gt; c; /** * 进入 gallop 模式的阈值 */ private static final int MIN_GALLOP = 7; /** * 控制何时进入 gallop 模式. */ private int minGallop = MIN_GALLOP; /** * tem 数组的最大初始大小. * 用于合并相关操作. */ private static final int INITIAL_TMP_STORAGE_LENGTH = 256; /** * 合并时使用的数组. */ private T[] tmp; private int tmpBase; private int tmpLen; /** * 压入栈中的 run 的个数 */ private int stackSize = 0; private final int[] runBase; // 每个 run 的起始索引 private final int[] runLen; // 每个 run 的长度. /** * 创建 TimSort 实例以维护正在进行的排序状态. */ private TimSort(T[] a, Comparator&lt;? super T&gt; c, T[] work, int workBase, int workLen) &#123; this.a = a; this.c = c; // 分配临时存储 tem // 如有必要,可以在以后增加 int len = a.length; int tlen = (len &lt; 2 * INITIAL_TMP_STORAGE_LENGTH) ? len &gt;&gt;&gt; 1 : INITIAL_TMP_STORAGE_LENGTH; if (work == null || workLen &lt; tlen || workBase + tlen &gt; work.length) &#123; @SuppressWarnings(&#123;&quot;unchecked&quot;, &quot;UnnecessaryLocalVariable&quot;&#125;) T[] newArray = (T[])java.lang.reflect.Array.newInstance (a.getClass().getComponentType(), tlen); tmp = newArray; tmpBase = 0; tmpLen = tlen; &#125; else &#123; tmp = work; tmpBase = workBase; tmpLen = workLen; &#125; /* * 根据原数组长度，为序列栈分配初始空间 */ int stackLen = (len &lt; 120 ? 5 : len &lt; 1542 ? 10 : len &lt; 119151 ? 24 : 49); runBase = new int[stackLen]; runLen = new int[stackLen]; &#125; /* * 排序 */ static &lt;T&gt; void sort(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c, T[] work, int workBase, int workLen) &#123; // 断言, 保证后面的条件成立, 多用于调试阶段 // 除非手动打开, 否则无用 assert c != null &amp;&amp; a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length; int nRemaining = hi - lo; if (nRemaining &lt; 2) return; // 长度为 0 或 1 数组总是有序的. // 数组长度小于 32, 直接使用二分插入排序. if (nRemaining &lt; MIN_MERGE) &#123; // 寻找第一个 run // 执行完成之后. [lo, lo+initRunLen) 是有序的. int initRunLen = countRunAndMakeAscending(a, lo, hi, c); // 二分插入排序 binarySort(a, lo, hi, lo + initRunLen, c); return; &#125; /** * 新建一个 TimSort 实例, 存储运行时的状态, 比如临时的 run */ TimSort&lt;T&gt; ts = new TimSort&lt;&gt;(a, c, work, workBase, workLen); // 当 run 块长度小于 minRun 时, 使用二分插入排序. (MIN_MERGE / 2 &lt;= minRun &lt;= MIN_MERGE) int minRun = minRunLength(nRemaining); do &#123; // 寻找下一个 run int runLen = countRunAndMakeAscending(a, lo, hi, c); // run 太短了, 扩展到 min(minRun, nRemaining) 使用二分插入排序. if (runLen &lt; minRun) &#123; // 排到最后剩余元素可能不足 minRun 个. int force = nRemaining &lt;= minRun ? nRemaining : minRun; // 二分插入排序 binarySort(a, lo, lo + force, lo + runLen, c); // 更新 run 长度. runLen = force; &#125; // 将 run 压入栈中 ts.pushRun(lo, runLen); // 根据栈中的 run 块长度选择合并. ts.mergeCollapse(); // 更新, 继续寻找 lo += runLen; nRemaining -= runLen; &#125; while (nRemaining != 0); assert lo == hi; // 合并剩余的 run ts.mergeForceCollapse(); assert ts.stackSize == 1; &#125; /** * 二分插入排序 * * @param a 总数组, 只对 a 的 [lo, hi) 部分进行排序 * @param lo 要排序的范围第一个元素的索引. * @param hi 要排序的范围最后一个元素之后的索引 * @param start [lo,start) 是有序的, 从 start 开始乱序. */ @SuppressWarnings(&quot;fallthrough&quot;) private static &lt;T&gt; void binarySort(T[] a, int lo, int hi, int start, Comparator&lt;? super T&gt; c) &#123; assert lo &lt;= start &amp;&amp; start &lt;= hi; if (start == lo) start++; for ( ; start &lt; hi; start++) &#123; // 待插入的数据 T pivot = a[start]; // 在 [left, right] 中找到插入 privot 的位置. int left = lo; int right = start; assert left &lt;= right; /* * 寻找插入的位置 */ while (left &lt; right) &#123; int mid = (left + right) &gt;&gt;&gt; 1; if (c.compare(pivot, a[mid]) &lt; 0) right = mid; else left = mid + 1; &#125; assert left == right; int n = start - left; // 需要移动的元素的数量 // 如果待移动的元素 &lt;= 2 个, 直接移动 // 减少 System.arraycopy 的调用 switch (n) &#123; case 2: a[left + 2] = a[left + 1]; case 1: a[left + 1] = a[left]; break; default: System.arraycopy(a, left, a, left + 1, n); &#125; // 插入元素 a[left] = pivot; &#125; &#125; /** * 寻找 run 的函数. */ private static &lt;T&gt; int countRunAndMakeAscending(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c) &#123; assert lo &lt; hi; int runHi = lo + 1; if (runHi == hi) return 1; // 寻找 run if (c.compare(a[runHi++], a[lo]) &lt; 0) &#123; // 降序 while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &lt; 0) runHi++; // 原地反转数组, 使其变为升序 reverseRange(a, lo, runHi); &#125; else &#123; // 升序 while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &gt;= 0) runHi++; &#125; return runHi - lo; &#125; /** * 原地反转数组 */ private static void reverseRange(Object[] a, int lo, int hi) &#123; hi--; while (lo &lt; hi) &#123; Object t = a[lo]; a[lo++] = a[hi]; a[hi--] = t; &#125; &#125; /** * 求 minRun * minRun: 小于 minRun 的 run, 扩展为 min(minRun, 剩余元素), 使用二分插入排序. */ private static int minRunLength(int n) &#123; assert n &gt;= 0; int r = 0; // n &lt; MIN_MERGE 直接使用二分插入排序了, 不会调用此方法 // 若 n 为 2 的幂, 那么 r 最终会为 0, 返回结果是 MIN_MERGE / 2 // 在剩余情况下, 返回值 k 落在 [MIN_MERGE/2, MIN_MERGE] 间 // 同时保证 n / k 接近且严格小于一个 2 的幂 while (n &gt;= MIN_MERGE) &#123; r |= (n &amp; 1); n &gt;&gt;= 1; &#125; return n + r; &#125; /** * 将 run 压入栈. * * @param runBase run 第一个元素的索引 * @param runLen run 的长度 */ private void pushRun(int runBase, int runLen) &#123; this.runBase[stackSize] = runBase; this.runLen[stackSize] = runLen; stackSize++; &#125; /** * 根据栈顶的三个 run 的长度进行选择合并 * 将较短的二个合并(i-1 和 i-2 或者 i-2 和 i-3) * (和 2048 游戏差不多) */ private void mergeCollapse() &#123; while (stackSize &gt; 1) &#123; int n = stackSize - 2; if (n &gt; 0 &amp;&amp; runLen[n-1] &lt;= runLen[n] + runLen[n+1]) &#123; if (runLen[n - 1] &lt; runLen[n + 1]) n--; mergeAt(n); &#125; else if (runLen[n] &lt;= runLen[n + 1]) &#123; mergeAt(n); &#125; else &#123; break; &#125; &#125; &#125; /** * 合并栈中的所有 run, 直到只剩下一个 run */ private void mergeForceCollapse() &#123; while (stackSize &gt; 1) &#123; int n = stackSize - 2; // 判断 合并 i-1 i-2 还是合并 i-3 i-2 // 和上个方法一个道理 // 尽量合并短的 if (n &gt; 0 &amp;&amp; runLen[n - 1] &lt; runLen[n + 1]) n--; mergeAt(n); &#125; &#125; /** * 合并栈中的第 i 个和第 i + 1 个 run * i 必须时倒数第二个或者倒数第三个 */ private void mergeAt(int i) &#123; assert stackSize &gt;= 2; assert i &gt;= 0; assert i == stackSize - 2 || i == stackSize - 3; int base1 = runBase[i]; int len1 = runLen[i]; int base2 = runBase[i + 1]; int len2 = runLen[i + 1]; assert len1 &gt; 0 &amp;&amp; len2 &gt; 0; assert base1 + len1 == base2; /* * 更新 run 的长度 */ runLen[i] = len1 + len2; // 如果准备进行归并的是倒数第二和倒数第三的序列, 那么还需要维护倒数第一序列的状态 if (i == stackSize - 3) &#123; runBase[i + 1] = runBase[i + 2]; runLen[i + 1] = runLen[i + 2]; &#125; stackSize--; /* * 目前我们有 run1: [base1, base1 + len1) 和 run2 : [base2, base2 + len2) * 其中 base1 + len1 == base2 * 首先尝试在 run1 中寻找一个索引 base1 + k * 使得 [base1 + k, base1 + len1) 中的每一个元素都比 run2 中的元素小 * 从而减少实际需进行归并操作的 run 的长度 */ int k = gallopRight(a[base2], a, base1, len1, 0, c); assert k &gt;= 0; base1 += k; len1 -= k; // 说明 run1 和 run2 已经是有序的了 if (len1 == 0) return; /* * 与上一段类似, 在 run2 中寻找索引 base2 + k * 使得 [base2 + k, base2 + len2) 中每一个元素都比 run1 中的元素大 */ len2 = gallopLeft(a[base1 + len1 - 1], a, base2, len2, len2 - 1, c); assert len2 &gt;= 0; // 说明 run1 和 run2 已经是有序的了 if (len2 == 0) return; // 合并剩余的元素, 长度短的 run 为基底. if (len1 &lt;= len2) mergeLo(base1, len1, base2, len2); else mergeHi(base1, len1, base2, len2); &#125; /** * 查找最接近 key 的索引 * 使用的二分查找, 加了一些优化 * * @param key 查找的值 * @param a 要在其中搜索的数组 * @param base 查找范围中的第一个元素的索引 * @param len 查找范围的长度 * @param hint 开始搜索的索引 * @param c 比较器(排序规则) * @return k 使得 [base, base + k - 1] &lt; key &lt;= [base + k, base + len] */ private static &lt;T&gt; int gallopLeft(T key, T[] a, int base, int len, int hint, Comparator&lt;? super T&gt; c) &#123; assert len &gt; 0 &amp;&amp; hint &gt;= 0 &amp;&amp; hint &lt; len; // 在经典二分查找开始前, 先尝试缩小查找范围 int lastOfs = 0; int ofs = 1; if (c.compare(key, a[base + hint]) &gt; 0) &#123; // 查看 key 属于哪个区间 // [base + hint, base + hint + 1), [base + hint + 1, base + hint + 3), [base + hint + 3, base + hint + 7),[base + hint + 7, base + hint + 15)... // 使 a[base+hint+lastOfs] &lt; key &lt;= a[base+hint+ofs] int maxOfs = len - hint; while (ofs &lt; maxOfs &amp;&amp; c.compare(key, a[base + hint + ofs]) &gt; 0) &#123; lastOfs = ofs; ofs = (ofs &lt;&lt; 1) + 1; if (ofs &lt;= 0) // 溢出 ofs = maxOfs; &#125; if (ofs &gt; maxOfs) ofs = maxOfs; // 更新下标, 相对 hint 进行偏移 // 之前的ofs和lastOfs都是相对于hint位置的, 现在把它重置为相对于base的位置 lastOfs += hint; ofs += hint; &#125; else &#123; // key &lt;= a[base + hint] // 和上面同样的思路 // 使 a[base+hint-ofs] &lt; key &lt;= a[base+hint-lastOfs] final int maxOfs = hint + 1; while (ofs &lt; maxOfs &amp;&amp; c.compare(key, a[base + hint - ofs]) &lt;= 0) &#123; lastOfs = ofs; ofs = (ofs &lt;&lt; 1) + 1; if (ofs &lt;= 0) // 溢出 ofs = maxOfs; &#125; if (ofs &gt; maxOfs) ofs = maxOfs; // 更新下标, 相对 hint 进行偏移 int tmp = lastOfs; lastOfs = hint - ofs; ofs = hint - tmp; &#125; assert -1 &lt;= lastOfs &amp;&amp; lastOfs &lt; ofs &amp;&amp; ofs &lt;= len; /* * 在区间 [base + lastOfs, base + ofs) 上进行二分查找 */ lastOfs++; while (lastOfs &lt; ofs) &#123; int m = lastOfs + ((ofs - lastOfs) &gt;&gt;&gt; 1); if (c.compare(key, a[base + m]) &gt; 0) lastOfs = m + 1; // a[base + m] &lt; key else ofs = m; // key &lt;= a[base + m] &#125; assert lastOfs == ofs; // so a[base + ofs - 1] &lt; key &lt;= a[base + ofs] return ofs; &#125; /** * 与上个方法对称 */ private static &lt;T&gt; int gallopRight(T key, T[] a, int base, int len, int hint, Comparator&lt;? super T&gt; c) &#123; assert len &gt; 0 &amp;&amp; hint &gt;= 0 &amp;&amp; hint &lt; len; int ofs = 1; int lastOfs = 0; if (c.compare(key, a[base + hint]) &lt; 0) &#123; // Gallop left until a[b+hint - ofs] &lt;= key &lt; a[b+hint - lastOfs] int maxOfs = hint + 1; while (ofs &lt; maxOfs &amp;&amp; c.compare(key, a[base + hint - ofs]) &lt; 0) &#123; lastOfs = ofs; ofs = (ofs &lt;&lt; 1) + 1; if (ofs &lt;= 0) // int overflow ofs = maxOfs; &#125; if (ofs &gt; maxOfs) ofs = maxOfs; // Make offsets relative to b int tmp = lastOfs; lastOfs = hint - ofs; ofs = hint - tmp; &#125; else &#123; // a[b + hint] &lt;= key // Gallop right until a[b+hint + lastOfs] &lt;= key &lt; a[b+hint + ofs] int maxOfs = len - hint; while (ofs &lt; maxOfs &amp;&amp; c.compare(key, a[base + hint + ofs]) &gt;= 0) &#123; lastOfs = ofs; ofs = (ofs &lt;&lt; 1) + 1; if (ofs &lt;= 0) // int overflow ofs = maxOfs; &#125; if (ofs &gt; maxOfs) ofs = maxOfs; // Make offsets relative to b lastOfs += hint; ofs += hint; &#125; assert -1 &lt;= lastOfs &amp;&amp; lastOfs &lt; ofs &amp;&amp; ofs &lt;= len; /* * Now a[b + lastOfs] &lt;= key &lt; a[b + ofs], so key belongs somewhere to * the right of lastOfs but no farther right than ofs. Do a binary * search, with invariant a[b + lastOfs - 1] &lt;= key &lt; a[b + ofs]. */ lastOfs++; while (lastOfs &lt; ofs) &#123; int m = lastOfs + ((ofs - lastOfs) &gt;&gt;&gt; 1); if (c.compare(key, a[base + m]) &lt; 0) ofs = m; // key &lt; a[b + m] else lastOfs = m + 1; // a[b + m] &lt;= key &#125; assert lastOfs == ofs; // so a[b + ofs - 1] &lt;= key &lt; a[b + ofs] return ofs; &#125; /** * 以稳定的方式合并两个相邻的 run. * a[base1] &gt; a[base2]&amp;&amp; 第一个 run 的最后一个元素比第二个 run 的所有元素都大. * 为了性能, 只有 len1 ≤ len2 时才调用此方法, 否则调用它的孪生兄弟 mergeHi. * 如果 len1 == len2 可以调用任意一个方法. */ private void mergeLo(int base1, int len1, int base2, int len2) &#123; assert len1 &gt; 0 &amp;&amp; len2 &gt; 0 &amp;&amp; base1 + len1 == base2; // 将第一个 run 复制到 tem T[] a = this.a; // 出于性能考虑, 将类中的对象用本地变量形式声明出来 T[] tmp = ensureCapacity(len1); // 声明游标 cursor1 和 cursor2 分别指向两个序列头部 int cursor1 = tmpBase; // 第一个 run 的起始索引 int cursor2 = base2; // 第二个 run 的起始索引 int dest = base1; System.arraycopy(a, base1, tmp, cursor1, len1); // 对一些极端情况的处理 a[dest++] = a[cursor2++]; if (--len2 == 0) &#123; // 如果 run2 只有一个元素 System.arraycopy(tmp, cursor1, a, dest, len1); return; &#125; if (len1 == 1) &#123; // 如果 run1 只有一个元素 System.arraycopy(a, cursor2, a, dest, len2); // 将 run2 放入合适位置后在其后面加上 run1 的元素 a[dest + len2] = tmp[cursor1]; return; &#125; Comparator&lt;? super T&gt; c = this.c; // 使用局部变量, 提高性能 int minGallop = this.minGallop; outer: while (true) &#123; // 一次元素比较中, 某个 run 的元素小, 算这个 run 赢了一次 int count1 = 0; // 第一个 run 赢的次数 int count2 = 0; // 第二个 run 赢的次数 /* * D如果忽略 count1 和 count2 下面的循环就是经典的合并操作. */ do &#123; assert len1 &gt; 1 &amp;&amp; len2 &gt; 0; if (c.compare(a[cursor2], tmp[cursor1]) &lt; 0) &#123; a[dest++] = a[cursor2++]; // 一个 run 赢了之后, 另一个 run 的 count 清零 // 所以 count 的实际意义为连赢的次数. count2++; count1 = 0; if (--len2 == 0) break outer; &#125; else &#123; a[dest++] = tmp[cursor1++]; count1++; count2 = 0; if (--len1 == 1) break outer; &#125; &#125; while ((count1 | count2) &lt; minGallop); /* * 某一个 run 连胜的次数太多了(&gt; minGallop), 进入 gallop 模式. * 接下来不再逐个比较, 而是通过 gallopRight 和 gallopLeft 比较. * 目的是加快合并的过程. */ do &#123; assert len1 &gt; 1 &amp;&amp; len2 &gt; 0; // gallopRight 返回的是索引的偏移量 // 在此循环的逻辑下, 此返回值也恰好是 run1 连续赢的次数 count1 = gallopRight(a[cursor2], tmp, cursor1, len1, 0, c); if (count1 != 0) &#123; System.arraycopy(tmp, cursor1, a, dest, count1); dest += count1; cursor1 += count1; len1 -= count1; if (len1 &lt;= 1) // len1 == 1 || len1 == 0 break outer; &#125; a[dest++] = a[cursor2++]; if (--len2 == 0) break outer; // 同理, run2 count2 = gallopLeft(tmp[cursor1], a, cursor2, len2, 0, c); if (count2 != 0) &#123; System.arraycopy(a, cursor2, a, dest, count2); dest += count2; cursor2 += count2; len2 -= count2; if (len2 == 0) break outer; &#125; a[dest++] = tmp[cursor1++]; if (--len1 == 1) break outer; // 动态调整minGallop的值 minGallop--; &#125; while (count1 &gt;= MIN_GALLOP | count2 &gt;= MIN_GALLOP); if (minGallop &lt; 0) minGallop = 0; // 离开 gallop 模式惩罚 // 主要是为了优化, 避免连赢不多的情况进入 gallop minGallop += 2; &#125; // End of &quot;outer&quot; loop this.minGallop = minGallop &lt; 1 ? 1 : minGallop; // 写回字段 if (len1 == 1) &#123; assert len2 &gt; 0; System.arraycopy(a, cursor2, a, dest, len2); a[dest + len2] = tmp[cursor1]; // Last elt of run 1 to end of merge &#125; else if (len1 == 0) &#123; throw new IllegalArgumentException( &quot;Comparison method violates its general contract!&quot;); &#125; else &#123; assert len2 == 0; assert len1 &gt; 1; System.arraycopy(tmp, cursor1, a, dest, len1); &#125; &#125; /** * 与 mergeLo 对称 */ private void mergeHi(int base1, int len1, int base2, int len2) &#123; assert len1 &gt; 0 &amp;&amp; len2 &gt; 0 &amp;&amp; base1 + len1 == base2; // Copy second run into temp array T[] a = this.a; // For performance T[] tmp = ensureCapacity(len2); int tmpBase = this.tmpBase; System.arraycopy(a, base2, tmp, tmpBase, len2); int cursor1 = base1 + len1 - 1; // Indexes into a int cursor2 = tmpBase + len2 - 1; // Indexes into tmp array int dest = base2 + len2 - 1; // Indexes into a // Move last element of first run and deal with degenerate cases a[dest--] = a[cursor1--]; if (--len1 == 0) &#123; System.arraycopy(tmp, tmpBase, a, dest - (len2 - 1), len2); return; &#125; if (len2 == 1) &#123; dest -= len1; cursor1 -= len1; System.arraycopy(a, cursor1 + 1, a, dest + 1, len1); a[dest] = tmp[cursor2]; return; &#125; Comparator&lt;? super T&gt; c = this.c; // Use local variable for performance int minGallop = this.minGallop; // &quot; &quot; &quot; &quot; &quot; outer: while (true) &#123; int count1 = 0; // Number of times in a row that first run won int count2 = 0; // Number of times in a row that second run won /* * Do the straightforward thing until (if ever) one run * appears to win consistently. */ do &#123; assert len1 &gt; 0 &amp;&amp; len2 &gt; 1; if (c.compare(tmp[cursor2], a[cursor1]) &lt; 0) &#123; a[dest--] = a[cursor1--]; count1++; count2 = 0; if (--len1 == 0) break outer; &#125; else &#123; a[dest--] = tmp[cursor2--]; count2++; count1 = 0; if (--len2 == 1) break outer; &#125; &#125; while ((count1 | count2) &lt; minGallop); /* * One run is winning so consistently that galloping may be a * huge win. So try that, and continue galloping until (if ever) * neither run appears to be winning consistently anymore. */ do &#123; assert len1 &gt; 0 &amp;&amp; len2 &gt; 1; count1 = len1 - gallopRight(tmp[cursor2], a, base1, len1, len1 - 1, c); if (count1 != 0) &#123; dest -= count1; cursor1 -= count1; len1 -= count1; System.arraycopy(a, cursor1 + 1, a, dest + 1, count1); if (len1 == 0) break outer; &#125; a[dest--] = tmp[cursor2--]; if (--len2 == 1) break outer; count2 = len2 - gallopLeft(a[cursor1], tmp, tmpBase, len2, len2 - 1, c); if (count2 != 0) &#123; dest -= count2; cursor2 -= count2; len2 -= count2; System.arraycopy(tmp, cursor2 + 1, a, dest + 1, count2); if (len2 &lt;= 1) // len2 == 1 || len2 == 0 break outer; &#125; a[dest--] = a[cursor1--]; if (--len1 == 0) break outer; minGallop--; &#125; while (count1 &gt;= MIN_GALLOP | count2 &gt;= MIN_GALLOP); if (minGallop &lt; 0) minGallop = 0; minGallop += 2; // Penalize for leaving gallop mode &#125; // End of &quot;outer&quot; loop this.minGallop = minGallop &lt; 1 ? 1 : minGallop; // Write back to field if (len2 == 1) &#123; assert len1 &gt; 0; dest -= len1; cursor1 -= len1; System.arraycopy(a, cursor1 + 1, a, dest + 1, len1); a[dest] = tmp[cursor2]; // Move first elt of run2 to front of merge &#125; else if (len2 == 0) &#123; throw new IllegalArgumentException( &quot;Comparison method violates its general contract!&quot;); &#125; else &#123; assert len1 == 0; assert len2 &gt; 0; System.arraycopy(tmp, tmpBase, a, dest - (len2 - 1), len2); &#125; &#125; /** * 为 tmp 分配空间 * 出于性能考虑, 以指数方式增加 */ private T[] ensureCapacity(int minCapacity) &#123; if (tmpLen &lt; minCapacity) &#123; // 计算最小的大于 minCapacity 的 2 的幂 int newSize = minCapacity; newSize |= newSize &gt;&gt; 1; newSize |= newSize &gt;&gt; 2; newSize |= newSize &gt;&gt; 4; newSize |= newSize &gt;&gt; 8; newSize |= newSize &gt;&gt; 16; newSize++; if (newSize &lt; 0) // 不太可能, int 溢出 newSize = minCapacity; else newSize = Math.min(newSize, a.length &gt;&gt;&gt; 1); @SuppressWarnings(&#123;&quot;unchecked&quot;, &quot;UnnecessaryLocalVariable&quot;&#125;) T[] newArray = (T[])java.lang.reflect.Array.newInstance (a.getClass().getComponentType(), newSize); tmp = newArray; tmpLen = newSize; tmpBase = 0; &#125; return tmp; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"}]},{"title":"TCP","slug":"TCP","date":"2021-06-09T08:51:54.000Z","updated":"2022-04-13T13:31:48.410Z","comments":true,"path":"2021/06/09/TCP/","link":"","permalink":"https://tang7o.cn/2021/06/09/TCP/","excerpt":"","text":"1. 简介TCP是一个面向连接的、可靠的、基于字节流的传输层协议。 面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的； 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端； 字节流：消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃。 2. 报文头格式 源端口：数据从哪来 目的端口：要到哪里去 序列号：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。 确认应答号：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。 数据偏移：表示 TCP 报文段的首部长度，4 位二进制最大表示15，由于TCP首部包含个可变长度选项，需要指定这个 TCP 报文段到底有多长。它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。该字段的单位是4字节，所以TCP首部最大154 = *60字节。 控制位： URG：表示本报文段中发送的数据是否包含紧急数据。为 1 时表示紧急指针有效，为 0 则忽略紧急指针。 ACK：表示确认字段是否有效。为 1 表示有效，0 表示无效，带 ACK 标志的TCP报文段称为确认报文段。 PSH：提示接收端需立即从 TCP 接收缓冲区中读走数据，为接收后续数据腾出空间。为 1 表示对方应当立即把数据提交给上层应用，如果应用程序不将接收到的数据读走，就会一直停留在 TCP 接收缓冲区中。 RST：重置连接标志，用于重置由于主机崩溃或其他原因而出现错误的连接。或者用于拒绝非法的报文段和拒绝连接请求，带 RST 标志的 TCP 报文段称为复位报文段。 SYN：建立连接时用来同步序号。SYN=1 说明这是一个请求建立连接或同意建立连接的报文。只有在前两次握手中 SYN 才置为1，带 SYN 标志的 TCP 报文段称为同步报文段。 FIN：通知对方本端要关闭连接了，标记数据是否发送完毕。如果 FIN=1 告诉对方释放连接，带FIN标志的TCP报文段称为结束报文段。 窗口：用来告知发送端：接受端的缓存大小，以此控制发送端发送数据的速度，从而达到流量控制。16bit。 校验和：奇偶校验，此校验和是对整个的 TCP 报文段，包括 TCP 头部和 TCP 数据，以 16 位字进行计算所得。由发送端计算和存储，并由接收端进行验证。提供额外的可靠性。 紧急指针：标记数据为紧急数据。 3. TCP 和 UDPTCP 和 UDP 区别： 连接 TCP 是面向连接的传输层协议，传输数据前先要建立连接。 UDP 是不需要连接，即刻传输数据。 服务对象 TCP 是一对一的两点服务，即一条连接只有两个端点。 UDP 支持一对一、一对多、多对多的交互通信 可靠性 TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。 UDP 是尽最大努力交付，不保证可靠交付数据。 拥塞控制、流量控制 TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。 首部开销 TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。 传输方式 TCP 是流式传输，没有边界，但保证顺序和可靠。 UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。 分片不同 TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了一个分片，则就需要重传所有的数据包，这样传输效率非常差，所以通常 UDP 的报文应该小于 MTU。 应用场景 TCP 常用于 FTP 文件传输、HTTP/HTTPS。 UDP 常用于视频、音频、广播通信。 4. 三次握手 一开始客户端跟服务器都处于 closed 状态，然后服务端主动监听某个客户端端口，此时服务端处于listen 状态。 客户端随机初始化序列号 seq = client_isn，同时将 SYN = 1 表示这是SYN 报文，接着把该 SYN 报文发给服务器，注意此时报文不包含引用层数据，客户端处于 syn-sent状态。 服务端收到客户端的 SYN报文后也随机初始化个序号 seq = server_isn，并且将确认序号 ACK = client_isn + 1，接着把 SYN = 1跟 ACK = 1，然后该报文发送给客户端，服务器处于 syn-rcvd状态。 客户端收到服务器的报文后，将 ACK = 1，确认应答号 ACK = server_isn + 1，然后把报文发送给服务器，本次报文可发送数据，同时客户端处于established 状态。 服务器收到客户端的应答报文后，也进入 established 状态。 客户端和服务端建立好了连接，可以相互发送数据。 这里你可能发现了客户端跟服务器的初始化序列号是各自随机的，原因是网络中的报文会重发、会延迟、也有可能丢失，为避免相互影响干脆各用各的为好。同时通过流程发现前两次握手是不带数据的，第三次可携带数据。 4.1 为什么握手需要三次？ 避免历史连接 客户端建立连接时发送多次 SYN 报文，由于网络拥堵可能旧的 SYN 报文比新的 SYN 报文先到服务器，服务器不管新旧，收到就回复 SYN + ACK 给客户端，三次握手情况下客户端可以根据序列号或超时时间判断回复的连接是否是历史连接，如果是历史连接直接发送 RST 报文给服务端来终止连接。 同步双方序列号 TCP 协议的通信双方都在维护各自的序列号，且必须要让对方知道。只有通过三次握手才可以实现。 避免服务端资源浪费 二次握手情况下，如果客户端的 SYN 阻塞导致重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效连接，造成不必要的资源浪费。而三次握手发现无效连接可在第三次给服务器端发送终止指令。 5. 四次挥手 客户端停止发送数据并且发出释放连接的报文，报文中FIN = 1，FIN 报文段即使不携带数据，也要消耗一个序号，此时序列号 seq = u ，u = 前面已经传输过来数据最后一个字节序号加 1，客户端进入 FIN-WAIT-1 状态。 服务器收到连接释放报文，发出确认报文，ACK = 1，应答确认号 ACK = u + 1，并且带上自己的序列号 seq = v，此时服务端就进入了 CLOSE-WAIT 状态。TCP 服务器通知高层的应用进程进入半闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个 CLOSE-WAIT 状态持续的时间。 客户端收到服务器的确认请求后，此时客户端就进入 FIN-WAIT-2 状态，等待服务器发送连接释放报文，在这之前还需要接受服务器发送的最后的数据。 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN = 1，ACK = u + 1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为 seq = w，此时服务器就进入了 LAST-ACK 状态，等待客户端的确认。 客户端收到服务器的连接释放报文后必须发出确认，ACK = 1，ACK = w + 1，seq = u + 1，此时客户端就进入了TIME-WAIT 状态，服务端进入 CLOSED 状态。注意此时 TCP 连接还没有释放，经过 2MSL 时间后自动进入 CLOSED 状态。 5.1 为什么挥手需要四次？其实分析下整个关闭的流程就知道为什么必须是四次挥手而不是三次挥手了。 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据出去了但是还是能接收数据。 服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，意思是不再接受数据了，但服务端可能还有数据需往外发送，等服务端不再发送数据时才发送 FIN 报文给客户端来表示同意现在关闭连接。这里注意服务端的 ACK 跟 FIN 是分开发的。 客户端收到服务端的 ACK 后，再给服务端发送 ACK，最终客户端跟服务器都进入close 状态。 5.2 TIME-WAIT 为什么是 2MSL？ MSL: Maximum Segment Lifetime 报文最大生存时间，意思是网络传输的报文在网络上存在的最长时间，超过这个时间报文将被丢弃。 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的 MSL。 TIME-WAIT 是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。 5.3 为什么需要 TIME-WAIT 状态？主动发起关闭连接的一方，才有 TIME-WAIT 状态。 需要 TIME-WAIT 状态，主要有两个原因： 防止旧的数据包被接收：上一次连接时候如果有网络震荡导致服务端数据在网络游荡，如果因为 time_wait 时间太短，新的连接可能会重新接受到游荡的消息。有了延迟时间可以避免消耗游荡的数据。 确保「被动关闭连接」的一方能正常关闭：TIME-WAIT 作用是等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。 TIME-WAIT 过大的危害： 占用内存资源 占用端口资源 避免 TIME_WAIT 过多： 取消短连接，改用长连接方式。 设定阈值，一旦超过阈值系统会将所有 TIME-WAIT 连接重置。 修改客户端程序代码。 短连接：通信双方有数据交互时，就建立一个 TCP 连接，数据发送完成后，则断开此 TCP 连接. 长连接：数据发送完成后发检测包以维持此连接，直到主动断开连接。","categories":[{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"},{"name":"TCP","slug":"网络/TCP","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/TCP/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://tang7o.cn/tags/TCP/"}]},{"title":"JVM","slug":"JVM","date":"2021-05-24T07:07:20.000Z","updated":"2022-04-13T13:31:48.038Z","comments":true,"path":"2021/05/24/JVM/","link":"","permalink":"https://tang7o.cn/2021/05/24/JVM/","excerpt":"","text":"1. 简介:JVM(Java Virtual Machine), Java 虚拟机. JVM 是一种用于计算机设备的规范, 它是一个虚拟出来的计算机, 是通过在实际计算机上仿真模拟各种计算机功能来实现的. JVM 的位置: 2. JVM 运行时数据区 2.1 Java堆 (heap)对大多数应用来说, Java堆 (heap) 是 Java虚拟机所管理的内存中最大的一块. Java 堆是被所有线程共享的一段内存区域, 在虚拟机启动时创建, 此内存区域的唯一作用就是存放对象实例, 几乎所有的对象实例都在这里分配内存. Java堆是垃圾收集器 (GC) 管理的主要区域, 因此很多时候也被叫做 “GC堆”. 如果从内存回收的角度看, 由于现在的收集器基本都是采用的分代收集算法, 所以 Java堆 还可以细分为: 新生代和老年代, 新生代又可以细分为 Eden空间, From Survivor空间, To Survivor空间(8 : 1 : 1). 根据 Java 虚拟机规范的规定, Java堆可以出于物理上不连续的内存空间中, 只要逻辑上连续即可. 在实现时, 既可以实现成固定大小的, 又可以是可扩展的, 当前主流的虚拟机是按照可扩展来实现的. 如果在堆中没有内存完成实例分配, 并且堆也无法再扩展时, 将会抛出 OutOfMemoryError 异常。 可以通过以下的参数调整 Java堆的大小. 控制参数: -Xms设置堆的最小空间大小. -Xmx设置堆的最大空间大小. -XX:NewSize设置新生代最小空间大小. -XX:MaxNewSize设置新生代最大空间大小. -XX:PermSize设置永久代最小空间大小. -XX:MaxPermSize设置永久代最大空间大小. -Xss设置每个线程的堆栈大小. 永久代是 HotSpot虚拟机特有的概念, 在方法区的一种实现, 在 JDK8 中被完全废弃, 改用在本地内存中实现的元空间代替. 虽然没有直接设置老年代的参数, 但是可以通过设置堆空间大小和新生代空间大小两个参数来直接控制. 老年代空间大小 = 堆空间大小 - 新生代最大空间大小 2.2 方法区 (Method Area)方法区 (Method Area) 和 Java堆 一样是各个线程共享的内存区域. 它用于存储已经被虚拟机加载的类信息, 常量, 静态变量, 即时编译器编译后的代码等数据. Java虚拟机规范对这个区域的限制非常宽松, 出了和 Java堆一样不需要连续的内存空间和可以选择固定大小或者可扩展外, 还可以选择不实现垃圾收集. 相对而言, 垃圾收集行为在这个区域是比较少出现的, 这个区域的内存回收主要目标是针对常量池的回收和对类型的卸载. 根据Java虚拟机规范的规定, 当方法区无法满足内存分配需求时, 将抛出OutOfMemoryError异常. 2.3 程序计数器 (Program Counter Register)程序计数器 (Program Counter Register) 是一块较小的内存空间, 可以看作当前线程所执行字节码的行号指示器, 字节码解释器工作时通过改变计数器的值选取下一条执行指令, 分支,循环, 跳转, 线程恢复等功能都需要依赖计数器完成, 是唯一在虚拟机规范中没有规定内存溢出情况的区域. 由于 Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式实现的, 在任何一个确定的时间, 一个处理器 (对多核处理器来说是一个内核) 只会执行一条线程中的指令. 因此, 为了线程切换后能恢复到正确的执行位置, 每个线程都需要有一个独立的程序计数器, 各条线程之间的计数器互不影响, 独立存储, 我们称这种内存为 “线程私有” 的内存. 2.4 JVM栈 (JVM Stacks)JVM栈 (JVM Stacks) 与程序计数器一样是 线程私有 的, 它的生命周期和线程相同, JVM 栈描述的是 Java 方法执行的内存模型: 每个方法被执行的时候都会创建一个栈帧 (Stack Frame) 用于存储方法的局部变量表, 操作栈, 动态链接, 方法出口等信息. 每一个方法被调用至执行完成的过程, 就对应着一个栈帧在虚拟机中从入栈到出栈的过程. 在 java虚拟机规范中, 对这个区域规定了两种异常: 如果线程请求的栈深度大于虚拟机所允许的深度, 将抛出 StackOverflowError 异常; 如果虚拟机栈可以动态扩展, 当扩展无法申请到足够的内存时会抛出 OutOfMemoryError 异常. 2.5 本地方法栈 (Native Method Stacks)本地方法栈 (Native Method Stacks) 和虚拟机栈发挥的作用非常相似, 其区别不过是虚拟机栈为虚拟机执行 Java 方法 (字节码) 服务, 而本地方法栈则是为虚拟机使用 Native 方法服务. 虚拟机规范中对本地方法栈中方法的使用的语言, 使用方式和数据结构并没有强制规定, 因此具体的虚拟机可以自由实现它. 与虚拟机栈一样, 本地方法区域也会抛出 StackOverflowError 和 OutOfMemoryError 异常. 3. 垃圾收集3.1 简介垃圾收集 Garbage Collection 通常被称为 “GC”. JVM中, 程序计数器, 虚拟机栈, 本地方法栈都是随线程而生随线程而灭, 栈帧随着方法的进入和退出做入栈和出栈操作, 实现了自动的内存清理, 因此, 我们的内存垃圾回收主要集中于 java 堆和方法区中, 在程序运行期间, 这部分内存的分配和使用都是动态的. 3.2 对象存活判断判断对象是否存活有二种方式: 引用计数: 每个对象有一个引用计数属性, 新增一个引用时 + 1, 引用释放时 - 1, 计数为 0 可回收. 此方法实现简单, 但是无法解决循环引用问题. 可达性分析: 从 GC Roots 开始向下搜索, 搜索走过的路径称为引用链. 当一个对象到 GC Roots 没有任何引用链相连时, 则会被表为垃圾. 可作为 GC Roots 的对象: 虚拟机栈和本地方法栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 引用类型: 强引用: 最常见的引用, 例如 Object object = new Object() 就属于强引用. 只要对象有强引用指向且 GC Roots 可达, 在内存回收时即使濒临内存耗尽也不会被回收. 软引用: 弱于强引用, 描述非必需对象. 在系统将发生内存溢出前, 会把软引用关联的对象加入回收范围以获取更多的空间. 常用来缓存服务器中间计算结果及不需要实时保存的用户行为. 弱引用: 弱于软引用, 描述非必需对象. 弱引用关联的对象只能生存到下次 YGC(对新生代进行 GC) 前, 当垃圾收集器开始工作时无论当前内存是否足够都会回收被弱引用关联的对象. 由于 YGC 具有不确定性, 因此弱引用何时被回收也不能确定. 虚引用: 最弱的引用, 定义完成后无法通过该引用获取对象. 唯一目的就是为了在对象被回收时收到一个通知. 虚引用必须与引用队列联合使用, 垃圾回收时如果出现虚引用, 就会在回收对象前把这个虚引用加入引用队列. 3.2 GC 算法3.2.1 标记 - 清除算法“标记 - 清除” (Mark - Sweep)算法, 如它的名字一样, 算法分为 “标记” 和 “清除” 二个阶段: 首先标记出所有要被回收的对象, 在标记完成后统一回收所有被标记的对象. 标记 - 清除是最基础的 GC 算法, 后续的收集算法都是基于这种思路并对其缺点进行改进而得到的. 缺点: 标记和清除的效率都不高. 标记 - 清除之后会产生大量的不连续的内存碎片, 空间碎片太多可能会导致: 当程序运行过程中无法分配一个较大的空间而提前触发 GC. 3.2.2 复制算法为了解决内存碎片化问题, 将可用的内存分为大小相等的两块, 每次只用其中一块. 当这一块内存用完了, 就将还存活的对象复制到另一块上, 再把已使用过的内存空间一次清理掉. 缺点: 浪费了一半的内存空间. 3.2.3 标记 - 整理算法标记 - 整理算法: 与标 - 清除算法类似, 只不过标记后不是直接对可回收的对象进行清理, 而是让所有存活的对象向一端移动, 然后清理掉端边界以外的内存. 缺点: 移动活对象, 尤其是在老年代这种都有大量对象存活的区域, 是一种极为负重的操作, 而且移动必须全程暂停用户线程. 3.3 垃圾收集器3.3.1 Serial收集器最基础,最稳定以及效率高的收集器, 单线程工作, 只用一条 GC 线程进行垃圾回收, 进行垃圾收集必须停止一切用户线程(Stop The World). 简单高效, 对于内存受限的环境它是所有收集器中额外内存消耗最小的, 对于处理器核心较少的环境, Serial 由于没有线程交互开销, 可获得最高的单线程收集效率. 适合客户端使用. 3.3.2 ParNew 收集器ParNew收集器其实就是Serial收集器的多线程版本. 清理过程需要 Stop The World. ParNew 追求”低停顿时间”, 与 Serial 唯一的区别就是使用了多线程进行垃圾收集, 在多 CPU 环境下性能比 Serial 会有一定的提升; 但线程切换需要额外开销, 因此在单 CPU 环境下表现不如 Serial. 3.3.3 Parallel 收集器Parallel Scavenge收集器类似ParNew收集器, Parallel收集器更关注系统的吞吐量, 吞吐量就是处理器用于运行用户代码的时间与处理器消耗总时间的比值. 3.3.4 Serial Old 垃圾收集器Serial 的老年代版本, 都是单线程收集器, 只启用一条 GC 线程. 和 Serial 的区别: Serial Old 工作在老年代, 使用 “标记-整理”算法; Serial 工作在新生代, 使用复制算法. 3.3.5 Parallel Old 收集器Parallel Old是Parallel Scavenge收集器的老年代版本, 使用多线程和”标记-整理” 算法, 在 JDK 1.6 提供. 3.3.6 CMS 收集器CMS(Concurrent Mark Sweep)收集器,以获取最短回收停顿时间为目标, 基于标记-清除算法, 过程相对复杂, 分为四个步骤: 初始标记: Stop The World, 仅使用一条初始标记线程对所有与 GC Roots 直接关联的对象进行标记. 并发标记: 使用多条标记线程, 与用户线程并发执行. 此过程进行可达性分析, 标记出所有废弃对象, 速度很慢. 重新标记: Stop The World, 使用多条标记线程并发执行, 将并发标记期间出现的废弃对象标记出来. 并发清除: 只使用一条 GC 线程, 与用户线程并发执行, 清除标记的对象. 这个过程非常耗时. 优点: 并发收集, 低停顿 缺点: 并发阶段会降低吞吐量 无法处理浮动垃圾, 导致频繁 Full GC 产生空间碎片 3.3.7 G1 收集器G1 是一款面向服务端应用的垃圾收集器, 它没有新生代和老年代的概念, 而是将堆划分为一块块独立的 Region. 当要进行垃圾收集时, 首先计算每个 Region 中垃圾的数量, 每次都从垃圾回收价值最大的 Region 开始回收, 因此可以获得最大的回收效率. 从整体上看, G1 是基于”标记-整理”算法实现的收集器, 从局部 (两个 Region 之间) 上看是基于”复制”算法实现的, 这意味着运行期间不会产生内存碎片. 每个 Region 中都有一个 Remembered Set, 用于记录本区域中所有对象的引用所在的区域, 进行可达性分析时, 只要在 GC Roots 中再加上 Remembered Set 即可防止对整个堆内存进行遍历. 如果不计算维护 Remembered Set 的操作, G1 收集器的工作过程可以分为一下几个步骤: 初始标记: Stop The World, 仅使用一条初始标记线程对所有与 GC Roots 直接关联的对象进行标记. 并发标记: 使用一条标记线程, 与用户线程并发执行. 此过程进行可达性分析, 标记出所有废弃对象, 速度很慢. 最终标记: Stop The world, 使用多条线程并发执行. 筛选回收: 回收废弃对象, 此时也要 Stop The world, 并使用多条筛选回收线程并发执行. 4. 内存分配与回收策略对象只要分配在新生代的 Eden 区域, 少数情况下可能直接分配在老年代, 分配规则不固定, 取决于当前使用的垃圾收集器组合以及相关的参数配置. 4.1 对象优先在 Eden 分配大多数情况下, 对象在新生代 Eden 区中分配, 当 Eden 没有足够的内存空间进行分配时, 虚拟机将发起一次 Minor GC. Minor GC 和 Major GC/Full GC: Minor GC: 回收新生代 (包括 Eden 和 Survivor 区域), 因为 Java 对象大多都具备朝生息灭的特性, 所以 Minor GC 非常频繁, 一般回收速度也比较快. Major GC/Full GC: 回收老年代, 出现了 Major GC 经常会伴随着至少一次的 Minor GC, 但非绝对. Major GC 的速度一般会比 Minor GC 慢 10 倍以上. 在 JVM 规范中, Major GC 和 Full GC 没有正式的定义, 所以有人也简单的认为 Major GC 清理老年代, Full GC 清理整个内存堆. 4.2 大对象直接进入老年代大对象是指需要大量连续内存空间的 Java 对象, 如很长的字符串或数据. 出现大对象会导致内存还有不少空间就提前触发垃圾收集以获取足够的连续空间来”放置”它们. 虚拟机提供了一个 -XX:PretenureSizeThreshold 参数, 使大于设置值的对象直接在老年代分配, 避免在 Eden 以及两个 Survivor 区之间发生大量的内存复制. 4.3 长期存活的对象进入老年代JVM 给每个对象定义了一个对象年龄计数器, 新生代发生 Minor GC 后, 存活下来的对象年龄 + 1, 当年龄超过一定值时, 就将该对象移入老年代. 使用 -XX:MaxTenuringThreshold 设置新生代的最大年龄, 只要超过该参数的新生代对象都会被转移到老年代中去. 4.4 动态对象年龄判定如果当新生代的 Survivor 中, 相同年龄的所有对象大小的总和大于 Survivor 空间的一半, 年龄大于等于该年龄的对象就可以直接进入老年代, 无序等到 MaxTenuringThreshold 中要求的值. 注意: 计算的年龄是累计和. 例如: 年龄 1 的对象占 33% 年龄 2 的对象占 33% 年龄 3 的对象占 34% 年龄 1 + 年龄 2 = 33% + 33% = 66% &gt; 50% 所以年龄大于等于 2 的对象都会进入老年代. 4.5 空间分配担保只要老年代的连续空间大于新生代对象总大小或者历届晋升的平均大小, 就会进行 Minor GC, 否则进行 Full GC. 通过清理老年代中废弃数据来扩大老年代空间, 以便给新生代作担保. 这个过程就是分配担保. 4.6 触发 Full GC 的情况 调用 System.gc() 方法 此方法的调用是建议 JVM 进行 Full GC, 只是建议并非一定. 老年代空间不足 老年代空间不足时会触发 Full GC, 若 Full GC 后空间依然不足, 会抛出: java.lang.OutOfMemoryError: Java heap space. 永久代空间不足 JVM 规范中运行时数据区域中的方法区, 在 HotSpot 虚拟机中也被称为永久代, 存放一下类信息, 常量, 静态变量等数据, 当系统要加载的类, 反射的类, 和调用的方法比较多使, 永久代可能会被占满, 会触发 Full GC. 如果经过 Full GC 空间依然不足, 会抛出: java.lang.OutOfMemoryError: PermGen space CMS GC 时出现 promotion failed 和 concurrent mode failure promotion failed, 就是上文所说的担保失败, 而 concurrent mode failure 是执行 CMS GC 的过程中同时有对象要放入老年代, 而此时老年代空间不足造成的. 统计得到的 Minor GC 晋升到旧生代的平均大小大于老年代的剩余空间","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://tang7o.cn/categories/Java/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://tang7o.cn/tags/JVM/"}]},{"title":"Java集合LinkedList","slug":"Java集合LinkedList","date":"2021-05-06T11:33:38.000Z","updated":"2022-04-13T13:31:48.149Z","comments":true,"path":"2021/05/06/Java集合LinkedList/","link":"","permalink":"https://tang7o.cn/2021/05/06/Java%E9%9B%86%E5%90%88LinkedList/","excerpt":"","text":"1.概述1.1 说明作者水平有限, 如有错误还望各位指正. 本文源码来自: JDK8. 1.2 简介LinkedList 是非线程安全的, 允许元素为 null 的双向链表. 底层结构是链表, 增删效率较高, 随机访问元素效率较差, 适用于增删为主的场景 (和 ArrayList 相反). 1.3 继承关系 因部分类/接口在 ArrayList 中介绍过了, 本文不再介绍. AbstractSequentialList: 和 AbstractList 相似, 不再过多介绍. Deque: 提供了双向链表操作. 2. 源码2.1 字段12345678910111213141516171819202122232425262728293031323334/** * 元素数量 */transient int size = 0; /** * 头节点 */ transient Node&lt;E&gt; first; /** * 尾节点 */ transient Node&lt;E&gt; last;/** * 具体节点, 内部类 * 用于存储元素 */ private static class Node&lt;E&gt; &#123; // 该节点的元素 // 可以为 null E item; // 下一个节点 Node&lt;E&gt; next; // 上一个节点 Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; 2.2 构造方法12345678910111213141516/** * 创建一个空链表 * 因为没有具体数据, 所以并不需要做什么 */public LinkedList() &#123;&#125;/** * 调用 addAll() 将 c 中的元素加入链表中 */public LinkedList(Collection&lt;? extends E&gt; c) &#123; // 这个 this() 是为了可维护性. // 如果不加默认调用 super() this(); addAll(c);&#125; 2.3 辅助方法因增删改查等主要方法都会调用这几个辅助方法, 因此先介绍一下. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176/** * 在头部添加一个元素. */ private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; // 如果原来是空链表, 将尾节点也指向加入的元素 if (f == null) last = newNode; else // 不是空链表, 更新节点 f.prev = newNode; size++; // 结构性修改次数+1 // 用于判断是否存在并发操作 // ArrayList 中有相关介绍 modCount++; &#125; /** * 在尾部添加一个元素. * 和上一个方法相似 */ void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; &#125; /** * 在非空节点 succ 之前插入元素 */ void linkBefore(E e, Node&lt;E&gt; succ) &#123; // 保证 succ 非空 final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; // succ 前一个节点为空, 表示 succ 是头节点, 更新头节点为 newNode if (pred == null) first = newNode; else // 更新节点信息. pred.next = newNode; size++; modCount++; &#125; /** * 删除链表的第一个节点, 返回元素值 * 该节点非空 */ private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // 置为 null, 方便 GC 回收垃圾 first = next; // 如果链表就这一个元素, 将链表置为空链表 if (next == null) last = null; else next.prev = null; size--; modCount++; return element; &#125; /** * 删除最后一个节点, 返回元素值 */ private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // 方便 GC 回收 last = prev; // 如果就这一个元素 if (prev == null) first = null; else prev.next = null; size--; modCount++; return element; &#125; /** * 删除非空节点 x, 返回元素值 */ E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; // 如果 x 是头节点 if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; // 如果 x 是尾节点 if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element; &#125; /** * 返回指定位置的节点(非空). */ Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // 一种优化, 看指定位置属于前半段还是后半段 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125; &#125; /** * 位置索引检查, 超界抛 IndexOutOfBoundsException * 用于 add 和 迭代器 */private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; /** * 位置索引检查 * @return 有效索引: true, 否则: false */ private boolean isPositionIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt;= size; &#125; /** * 元素索引检查 * 一般用于查找 */ private void checkElementIndex(int index) &#123; if (!isElementIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; /** * 说明参数是否是现有元素的索引 */ private boolean isElementIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt; size; &#125; 2.4 增123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113/** * 在链表头部插入元素 * * @param e 要添加的元素 */ public void addFirst(E e) &#123; linkFirst(e); &#125; /** * 在链表尾部插入元素 * * 等价于 add() * * @param e 要添加的元素 */ public void addLast(E e) &#123; linkLast(e); &#125; /** * 插入指定元素，返回操作结果,默认添加到末尾作为最后一个元素 * * @param e 要添加到此链表中的元素 * @return true 如果添加成功 */ public boolean add(E e) &#123; linkLast(e); return true; &#125; /** * 在此链表的指定位置插入元素 * * @param index 要插入指定元素的索引 * @param element 要插入的元素 * @throws IndexOutOfBoundsException 索引超界 */ public void add(int index, E element) &#123; // 索引检查 checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index)); &#125; /** * 将集合插入到链表尾部 * * @param c 包含要添加到此链表中的元素的集合 * @return &#123;@code true&#125; 如果此链表因调用而更改 * @throws NullPointerException 如果指定的集合是空的 */ public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c); &#125; /** * 将集合从指定位置开始插入 * * @param index 在哪个索引处前插入指定集合中的第一个元素 * @param c 包含要添加到此链表中的元素的集合 * @return &#123;@code true&#125; 如果该链表因调用而更改 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; * @throws NullPointerException 如果指定的集合是空的 */ public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; //检查索引是否正确（0&lt;=index&lt;=size） checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; //若没有元素要添加，直接返回false if (numNew == 0) return false; //succ指向当前需要插入节点的位置，pred指向其前一个节点 Node&lt;E&gt; pred, succ; //如果是在末尾开始添加，当前节点后一个节点初始化为null，前一个节点为尾节点 if (index == size) &#123; succ = null; pred = last; &#125; else &#123; //如果不是从末尾开始添加，当前位置的节点为指定位置的节点，前一个节点为要添加的节点的前一个节点 succ = node(index); pred = succ.prev; &#125; //遍历数组并添加到列表中 for (Object o : a) &#123; @SuppressWarnings(&quot;unchecked&quot;) E e = (E) o; //将元素值e，前继节点pred“封装”为一个新节点newNode Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); //如果原链表为null，则新插入的节点作为链表首节点 if (pred == null) first = newNode; else pred.next = newNode; //如果存在前节点，前节点会向后指向新加的节点 pred = newNode; //pred指针向后移动，指向下一个需插入节点位置的前一个节点 &#125; //如果是从最后开始添加的，则最后添加的节点成为尾节点 if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; //如果不是从最后开始添加的，则最后添加的节点向后指向之前得到的后续第一个节点 succ.prev = pred; //当前，后续的第一个节点也应改为向前指向最后一个添加的节点 &#125; size += numNew; modCount++; return true; &#125; 接下来的方法都是 Deque 的添加操作, 几乎都是调用的上面的方法不再过多叙述 123456789101112131415161718192021222324252627282930313233343536373839404142 /** * 和 add(e) 一样 */ public boolean offer(E e) &#123; return add(e); &#125; /** * 从链表头部插入元素 * * @param e 要插入的元素 * @return 始终返回 true * @since 1.6 */ public boolean offerFirst(E e) &#123; addFirst(e); return true; &#125; /** * 从尾部插入元素 * * @param e 要插入的元素 * @return 始终返回 true * @since 1.6 */ public boolean offerLast(E e) &#123; addLast(e); return true; &#125; /** * 等价于 addFirst * 不能说是完全一样, 只能说是一模一样 * * @param e the element to push * @since 1.6 */ public void push(E e) &#123; addFirst(e); &#125; 2.5 删123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152/** * 从链表头部删除一个节点 * * @return 删除的元素 * @throws NoSuchElementException 链表为空 */ public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f); &#125; /** * 从链表尾部删除一个节点, 链表为空抛出异常 */ public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l); &#125; /** * 删除指定元素 * 如果有多个只删除第一个 * * @param o 要从链表重视删除的元素 * @return &#123;@code true&#125; 如果链表包含此元素. */ public boolean remove(Object o) &#123; // 元素是否为 null if (o == null) &#123; // 遍历 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125; /** * 删除指定位置的元素 * * @param index 要删除的元素的索引 * @return 被删除的元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */ public E remove(int index) &#123; // 检查索引 checkElementIndex(index); // 1. 获取指定位置的节点 // 2. 调用删除节点函数 return unlink(node(index)); &#125; /** * 从链表头部删除一个节点. * 返回删除的元素 * 和 removeFirst 的区别: 链表为空 poll 返回null, removeFirst 抛出异常 * * @return 链表为空返回 null, 否则返回删除的元素 * @since 1.5 */ public E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; /** * 从链表头部删除一个元素 * 同 removeFirst */ public E remove() &#123; return removeFirst(); &#125; /** * 删除第一个元素 * 同 removeFirst */ public E pop() &#123; return removeFirst(); &#125; /** * 删除链表的第一个节点(如果有), 返回其存储的元素 * 如果链表为空, 返回 null */ public E pollFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; /** * 删除链表的最后一个节点(如果有), 返回其存储的元素 * 如果链表为空, 返回 null */ public E pollLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : unlinkLast(l); &#125; /** * 删除链表中第一个指定元素, 返回操作结果 * * @param o 要从链表中删除的元素(如果存在) * @return &#123;@code true&#125; 如果链表包含此元素 * @since 1.6 */ public boolean removeFirstOccurrence(Object o) &#123; return remove(o); &#125; /** * 删除链表中最后一个指定元素, 返回操作结果 * * @param o 要从链表中删除的元素(如果存在) * @return &#123;@code true&#125; 如果链表包含此元素 * @since 1.6 */ public boolean removeLastOccurrence(Object o) &#123; // 指定元素是否为 null if (o == null) &#123; // 从尾查找元素第一次出现的节点 for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (x.item == null) &#123; // 删除该节点 unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125; 2.6 改1234567891011121314151617/** * 修改指定位置的元素, 返回修改前的值 * * @param index 要修改的元素的索引 * @param element 要储存在指定位置的元素 * @return 修改前的元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */ public E set(int index, E element) &#123; // 检查索引 checkElementIndex(index); Node&lt;E&gt; x = node(index); E oldVal = x.item; // 修改值 x.item = element; return oldVal; &#125; 2.7 查123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * 获取链表头节点的值 * * @return 链表头节点的值 * @throws NoSuchElementException 链表为空 */public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item;&#125;/** * 获取链表尾部的值 */public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item;&#125;/** * 获取链表指定位置的元素 * * @param index 指定位置 * @return 指定位置的元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; 索引异常 */public E get(int index) &#123; // 判断元素索引 checkElementIndex(index); return node(index).item;&#125;/** * 获取链表头节点存储的元素, 不会删除节点 * * @return 头节点的元素, 如果链表为空返回 null * @since 1.5 */public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item;&#125;/** * 获取链表头节点存储的元素, 不会删除节点 * 链表为空抛出异常 * * @return 头节点存储的元素 * @throws NoSuchElementException if this list is empty * @since 1.5 */public E element() &#123; return getFirst();&#125;/** * 返回列表第一个元素, 不删除 * 列表为空返回 null * @return the first element of this list, or &#123;@code null&#125; * if this list is empty * @since 1.6 */public E peekFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125;/** * 返回链表最后一个元素, 不删除 * 链表为空返回 null * @return the last element of this list, or &#123;@code null&#125; * if this list is empty * @since 1.6 */public E peekLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : l.item;&#125; 2.8 迭代器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135 /** * 返回该链表从指定位置开始的迭代器. * 迭代器是 fail-fast: 创建迭代器之后的任何时候, 链表发生结构性修改后, 迭代器会抛出 ConcurrentModificationException. 面对并发修改时, 迭代器会快速失败. * 返回的是内部类 ListItr * @param index 迭代器返回的第一个元素的索引 * @return 此链表 index(包含)之后的所有元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */ public ListIterator&lt;E&gt; listIterator(int index) &#123; checkPositionIndex(index); return new ListItr(index); &#125; private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; ListItr(int index) &#123; // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; nextIndex++; return lastReturned.item; &#125; public boolean hasPrevious() &#123; return nextIndex &gt; 0; &#125; public E previous() &#123; checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); lastReturned = next = (next == null) ? last : next.prev; nextIndex--; return lastReturned.item; &#125; public int nextIndex() &#123; return nextIndex; &#125; public int previousIndex() &#123; return nextIndex - 1; &#125; public void remove() &#123; checkForComodification(); if (lastReturned == null) throw new IllegalStateException(); Node&lt;E&gt; lastNext = lastReturned.next; unlink(lastReturned); if (next == lastReturned) next = lastNext; else nextIndex--; lastReturned = null; expectedModCount++; &#125; public void set(E e) &#123; if (lastReturned == null) throw new IllegalStateException(); checkForComodification(); lastReturned.item = e; &#125; public void add(E e) &#123; checkForComodification(); lastReturned = null; if (next == null) linkLast(e); else linkBefore(e, next); nextIndex++; expectedModCount++; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); while (modCount == expectedModCount &amp;&amp; nextIndex &lt; size) &#123; action.accept(next.item); lastReturned = next; next = next.next; nextIndex++; &#125; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125;/** * 反向迭代器 */ public Iterator&lt;E&gt; descendingIterator() &#123; return new DescendingIterator(); &#125; /** * 重写了 next remove 等方法, 使其按照从尾向前的顺序迭代 */ private class DescendingIterator implements Iterator&lt;E&gt; &#123; private final ListItr itr = new ListItr(size()); public boolean hasNext() &#123; return itr.hasPrevious(); &#125; public E next() &#123; return itr.previous(); &#125; public void remove() &#123; itr.remove(); &#125; &#125; 2.9 序列化123456789101112131415161718192021222324252627282930313233/** * 序列化 */private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException &#123; // 默认序列化 s.defaultWriteObject(); // 写入元素数量 s.writeInt(size); // 序列化所有元素 for (Node&lt;E&gt; x = first; x != null; x = x.next) s.writeObject(x.item);&#125;/** * 反序列化 */@SuppressWarnings(&quot;unchecked&quot;)private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // 默认反序列化 s.defaultReadObject(); // 读取元素数量 int size = s.readInt(); // 遍历链表, 读取所有元素并尾部插入 for (int i = 0; i &lt; size; i++) linkLast((E)s.readObject());&#125; 2.10 其他API123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162/** * 判断链表是否包含指定元素 * * @param o 要测试的元素 * @return 如果包含返回 true */ public boolean contains(Object o) &#123; return indexOf(o) != -1; &#125; /** * 查询链表中首次出现指定元素的下标 * 如果链表中没有指定元素, 返回 -1 * 指定元素可以为 null * * @param o 指定元素 * @return 没有此元素, 返回 -1 * 有则返回第一次出现的下标 */ public int indexOf(Object o) &#123; int index = 0; // 元素是否为null if (o == null) &#123; // 遍历 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) return index; index++; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1; &#125; /** * 逆序获取指定元素首次出现的位置 * 上个方法反过来 */ public int lastIndexOf(Object o) &#123; int index = size; if (o == null) &#123; // 遍历链表，逆序查找指定元素 for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (x.item == null) return index; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (o.equals(x.item)) return index; &#125; &#125; return -1; &#125; /** * 返回链表包含的元素数量 * * @return 元素数量 */ public int size() &#123; return size; &#125; /** * 清空链表 */ public void clear() &#123; // 遍历链表, 删除所有节点, 方便 GC 回收 for (Node&lt;E&gt; x = first; x != null; ) &#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x.prev = null; x = next; &#125; // 首尾节点值为 null first = last = null; // 元素数量置 0 size = 0; modCount++; &#125;/** * 父类克隆方法 */ @SuppressWarnings(&quot;unchecked&quot;) private LinkedList&lt;E&gt; superClone() &#123; try &#123; return (LinkedList&lt;E&gt;) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; throw new InternalError(e); &#125; &#125; /** * 克隆, 浅拷贝 * * @return 返回此链表的一个浅拷贝 */ public Object clone() &#123; LinkedList&lt;E&gt; clone = superClone(); // 置为空链表 clone.first = clone.last = null; clone.size = 0; clone.modCount = 0; // 添加链表的所有元素 for (Node&lt;E&gt; x = first; x != null; x = x.next) clone.add(x.item); return clone; &#125; /** * 返回包含链表所有数据的数组 * 返回的数组是&quot;安全&quot;的, 返回的数组和此链表不存在关联 * 返回类型为 Object[], 使用时可能需要强制转换. */ public Object[] toArray() &#123; // 新开一个大小为 size 的数组 Object[] result = new Object[size]; int i = 0; // 将链表中的元素存入数组 for (Node&lt;E&gt; x = first; x != null; x = x.next) result[i++] = x.item; return result; &#125; /** * 返回指定类型的包含链表所有元素的数组. * * @param a 给的数组 * 如果 a 足够大, 将链表元素存入 a 返回, 否则新开一个和 a 类型相同的大小和链表元素个数相同的数组, 将链表元素存入返回. * @return 包含链表所有元素的数组 * @throws ArrayStoreException 如果指定的类型不是元素类型的父类 * @throws NullPointerException 所给数组为 null */ @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T[] toArray(T[] a) &#123; // 所给数组不够大, 新开一个 if (a.length &lt; size) a = (T[])java.lang.reflect.Array.newInstance( a.getClass().getComponentType(), size); int i = 0; Object[] result = a; // 遍历链表, 存入元素 for (Node&lt;E&gt; x = first; x != null; x = x.next) result[i++] = x.item; // 将 a[size] 置为 null(如果有的话), 对以后确定列表的长度很有用, 但只在调用方知道列表中不包含任何 null 元素时才有用. if (a.length &gt; size) a[size] = null; return a; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"}]},{"title":"Java集合HashMap","slug":"Java集合HashMap","date":"2021-04-30T11:58:42.000Z","updated":"2022-04-13T13:31:48.134Z","comments":true,"path":"2021/04/30/Java集合HashMap/","link":"","permalink":"https://tang7o.cn/2021/04/30/Java%E9%9B%86%E5%90%88HashMap/","excerpt":"","text":"1. 概述1.1 说明作者水平有限, 如有错误还望各位指正. 本文源码来自: JDK8. 1.2 简介HashMap 底层基于散列算法实现, 采用 key/value 存储结构, 每个 key 对应唯一的 value, 允许 key 和 value 为null, null 的哈希值为 0. 非线程安全. JDK 1.8 之前, HashMap 底层数据结构为 数组+链表, JDK1.8 引入红黑树优化过长的链表. 当链表长度大于等于 8 且 hash 桶的长度大于等于 64 时, 会将链表优化为红黑树, 查找效率从$O(n)$优化为$O(logn)$. 1.3 继承关系 Cloneable: 可以被克隆 Serializable: 可以序列化 AbstractMap: 具有 Map 的所有功能 2. 源码2.1 源码注释 允许 key, value 为null, null 的哈希值为 0. 不要轻易的修改负载因子, 负载因子过高会导致链表过长, 查询时间复杂度增高, 负载因子过低会导致 hash 桶的数量过多, 空间复杂度增高. Hash 表每次扩容长度为之前的 2 倍. Hash 表的长度只能为 2 的整数次幂. HashMap 是多线程不安全的. 尽量设置 HashMap 的初始容量, 防止多次 resize. 2.2 字段2.2.1 常量字段123456789101112131415161718192021222324252627282930313233/** * 默认的初始容量(桶的长度). */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16/** * 最大容量 * 长度必须为2的整数幂 */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/** * 默认负载因子. */static final float DEFAULT_LOAD_FACTOR = 0.75f;/** * 链表数目 超过 此值, 才会将链表转为红黑树 * 8 个的时候不转换 */static final int TREEIFY_THRESHOLD = 8;/** * 链表数目小于等于此值, 改为链表存储 */static final int UNTREEIFY_THRESHOLD = 6;/** * 最小树形化容量 * 当存储的键值对 大于等于 此值时, 才能将链表转为红黑树 */static final int MIN_TREEIFY_CAPACITY = 64; 2.2.2 实例字段1234567891011121314151617181920212223242526272829303132333435/** * hash 桶数组 * 长度必须为 2 的幂 */transient Node&lt;K,V&gt;[] table;/** * HashMap将数据转换成set的另一种存储形式, 这个变量主要用于迭代功能 */transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;/** * 存储的键值对的数量 */transient int size;/** * 结构性修改的次数, fail-fast 机制. */transient int modCount;/** * 扩容阈值, 键值对数目超过此值, 容量扩为原来的二倍. * * @serial */int threshold;/** * HashMap 的负载因子, 可计算出当前table长度下的扩容阈值: threshold = loadFactor * table.length * * @serial */final float loadFactor; 2.2.3 内部类实现红黑树的内部类源码于 2.11 中显示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139/** * JDK 1.6 用 Entry 描述键值对, JDK 1.8 改用 Node */static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; // hash 值 final int hash; // key 不可变 final K key; V value; // 下一个节点 Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; final class KeySet extends AbstractSet&lt;K&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;K&gt; iterator() &#123; return new KeyIterator(); &#125; public final boolean contains(Object o) &#123; return containsKey(o); &#125; public final boolean remove(Object key) &#123; return removeNode(hash(key), key, null, false, true) != null; &#125; public final Spliterator&lt;K&gt; spliterator() &#123; return new KeySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super K&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125;&#125;final class Values extends AbstractCollection&lt;V&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;V&gt; iterator() &#123; return new ValueIterator(); &#125; public final boolean contains(Object o) &#123; return containsValue(o); &#125; public final Spliterator&lt;V&gt; spliterator() &#123; return new ValueSpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super V&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.value); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125;&#125;final class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new EntryIterator(); &#125; public final boolean contains(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Node&lt;K,V&gt; candidate = getNode(hash(key), key); return candidate != null &amp;&amp; candidate.equals(e); &#125; public final boolean remove(Object o) &#123; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Object value = e.getValue(); return removeNode(hash(key), key, value, true, true) != null; &#125; return false; &#125; public final Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; spliterator() &#123; return new EntrySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125;&#125; 2.3 辅助方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108/** * 计算 hash 值. * 和 h &gt;&gt;&gt; 16(对 h 无符号右移 16 位) 异或, 是为了让 hash 值更散列. * 为什么用 ^ 而不是 | &amp; 也是同样的道理. */ static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; /** * 计算大于等于 cap 的最小的 2 的幂. * 神奇的位运算. */ static final int tableSizeFor(int cap) &#123; // 如果不 - 1, 得到的结构为大于 cap 的最小的2的幂 int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; /** * Map.putAll 和 Map constructor 的实现需要的方法. * * @param m 指定的 Map * @param evict 初始化 map 时用 false, 否则使用 true. */ final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); // 如果 m 中有数据 if (s &gt; 0) &#123; // table 是否初始化 if (table == null) &#123; // pre-size // 根据 m 中的键值对个数, 计算扩容阈值(threshold) float ft = ((float)s / loadFactor) + 1.0F; // 最大为 MAXIMUM_CAPACITY int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); // 必须为 2 的次幂 // 计算第一个不小于 t 的 2 的幂 if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) // 初始化过了, 并且键值对大于扩容阈值(threshold) // 扩容 resize(); // 数据存入 HashMap 中. for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125; &#125; /** * 链表转为红黑树 */ final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; // 表为 null, 或者存储的键值对数目没有达到阈值, 不符合转为红黑树的条件, 扩容 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); // 符合条件且 hash 对应的桶不为空 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; // 红黑树的头, 尾节点 TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; // 遍历链表 // 将链表转为红黑树 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); // 红黑树头节点 if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); // 把数据插入到红黑树 if ((tab[index] = hd) != null) hd.treeify(tab); &#125; &#125; // 创建一个链表结点 Node&lt;K, V&gt; newNode(int hash, K key, V value, Node&lt;K, V&gt; next) &#123; return new Node&lt;&gt;(hash, key, value, next); &#125; // 替换一个链表节点 Node&lt;K, V&gt; replacementNode(Node&lt;K, V&gt; p, Node&lt;K, V&gt; next) &#123; return new Node&lt;&gt;(p.hash, p.key, p.value, next); &#125; // 创建一个红黑树节点 TreeNode&lt;K, V&gt; newTreeNode(int hash, K key, V value, Node&lt;K, V&gt; next) &#123; return new TreeNode&lt;&gt;(hash, key, value, next); &#125; // 替换一个红黑树节点 TreeNode&lt;K, V&gt; replacementTreeNode(Node&lt;K, V&gt; p, Node&lt;K, V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next); &#125; 2.4 构造方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 使用指定的容量和负载因子构造一个空HashMap * * @param initialCapacity 容量 * @param loadFactor 负载因子 * @throws IllegalArgumentException 如果指定容量为负数 */ public HashMap(int initialCapacity, float loadFactor) &#123; // 容量为负 if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); // 容量超过最大值, 置为最大值 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 负载因子为负或者为 NaN if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; // 容量必须为2 的次幂 // 计算第一个不小于 initialCapacity 的2的幂 this.threshold = tableSizeFor(initialCapacity); &#125; /** * 只指定了初始容量 和 默认的负载因子构造一个空HashMap * * @param initialCapacity 初始容量 * @throws IllegalArgumentException 初始容量为负 */ public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /** * 使用指定的初始化容量（16）和默认负载因子(0.75)构造一个空HashMap */ public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; /** * 使用指定 Map m 构造新的 HashMap. 使用指定的初始化容量 16 和默认负载因子(0.75) * * @param m 指定的 Map * @throws NullPointerException m 为 null */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; 2.5 增123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122/** * 将指定键值对插入 map 中, 如果已存在更新其value * 1. 通过 hash(Object key) 计算哈希值. * 2. 通过 putVal(hash(key), key, value, false, true) 实现插入. * 3. 返回 putVal 的结果 * * @param key 键值对的 key * @param value 键值对的 value * @return 如果存在此键值对, 返回旧的 value, 否则返回 null(旧的 value 有可能为 null) */ public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; /** * Map.put 和其他相关方法的实现 * 1. 如果哈希表为空, 通过 resize() 创建一个新的 * 2. 如果指定参数hash在表中没有对应的桶, 即为没有碰撞, 直接将键值对插入到哈希表中即可. * 3. 如果有碰撞, 遍历桶, 找到key映射的节点 * 3.1桶中的第一个节点就匹配了, 将桶中的第一个节点记录起来. * 3.2如果桶中的第一个节点没有匹配, 且桶中结构为红黑树, 则调用红黑树对应的方法插入键值对. * 3.3如果不是红黑树, 那么就肯定是链表.遍历链表, 如果找到了key映射的节点, 就记录这个节点, 退出循环.如果没有找到, 在链表尾部插入节点. * 插入后, 如果链的长度大于等于TREEIFY_THRESHOLD这个临界值, 则使用treeifyBin方法把链表转为红黑树. * 4. 如果找到了key映射的节点, 且节点不为null * 4.1记录节点的vlaue. * 4.2如果参数onlyIfAbsent为false, 或者oldValue为null, 替换value, 否则不替换. * 4.3返回记录下来的节点的value. * 5. 如果没有找到key映射的节点（2, 3 步中讲了, 这种情况会插入到hashMap中）, 插入节点后size会加1, 这时要检查size是否大于临界值threshold, 如果大于会使用resize方法进行扩容. * * @param hash key 的哈希值 * @param key 要插入的键值对的 key * @param value 要插入的键值对的 value * @param onlyIfAbsent 是否保留旧的 value * @param evict 如果为 false, 表示 table 还没创建. * @return 如果 value 被替换, 返回旧的 value, 否则返回 null */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // 使用局部变量, 题高性能 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 哈希表为空, 用 resize 创建一个新的. if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // key 对应的桶为空, 直接插入 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; // key 对应的桶不为空, 即发生了碰撞 Node&lt;K,V&gt; e; K k; // 判断桶中的第一个元素 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 桶是红黑树结构 else if (p instanceof TreeNode) // 调用红黑树的插入方法 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 桶是链表结构 for (int binCount = 0; ; ++binCount) &#123; // 遍历到链表尾部 if ((e = p.next) == null) &#123; // 插入 p.next = newNode(hash, key, value, null); // 插入后的链表长度是否达到阈值, 判断是否转为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 转为红黑树 treeifyBin(tab, hash); break; &#125; // 插入的键值对和之前的相同, 不做处理 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 发生了碰撞 if (e != null) &#123; // existing mapping for key V oldValue = e.value; // 是否替换旧的 value if (!onlyIfAbsent || oldValue == null) e.value = value; // 访问后回调 // afterNodeAccess, afterNodeInsertion, afterNodeRemoval 这三个方法在 HashMap 中都是空方法, // 是为了继承 HashMap 的 LinkedHashMap 服务的, LinkedHashMap 保留插入的顺序. 用于 LinkedHashMap 操作时的回调. afterNodeAccess(e); // 返回旧值 return oldValue; &#125; &#125; // 结构性修改次数 + 1 ++modCount; // 是否需要扩容 if (++size &gt; threshold) resize(); // 插入后回调 // 在 HashMap 中是个空方法 afterNodeInsertion(evict); return null; &#125; /** * 将指定 map 中的所有键值对插入到 hashMap 中. 如有碰撞覆盖原有 value * * @param 指定的 map * @throws NullPointerException 如果 map 为 null */ public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; putMapEntries(m, true); &#125;/** * 如果不存在指定 key 的映射, 添加指定的键值对 * * @param key 指定的 key * @param value 指定的 value * @return 如果存在 key 的映射返回旧值, 否则返回 null */ @Override public V putIfAbsent(K key, V value) &#123; return putVal(hash(key), key, value, true, true); &#125; 2.6 删123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104 /** * 删除 hashMap 中 key 映射的 node * 1. 计算 key 的哈希值 * 2. 通过 removeNode 方法实现功能 * 3. 返回数据 * * @param key 要删除的键值对的 key * @return 没有映射到 node, 返回 null, 否则返回对应的 value */ public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125; /** * Map.remove 和相关方法的实现 * * @param hash key 的哈希值 * @param key the key * @param value 如果 matchValue 为 true, value 也作为确定被删除的 node 的条件 * @param matchValue 如果为 true, value 也作为确定被删除 node 的条件 * @param movable 删除后是否移动节点 * @return the node, or null if none */ final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; // 如果 table 不为空, 且 key 对应的桶不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; // 第一个元素 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; // key 对应的桶使用红黑树实现 if (p instanceof TreeNode) // 调用红黑树相关的方法 node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; // 链表 // 遍历 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // 如果找到的 node 不为 null 且 (matchValue 为 false || node.value 和参数 value 匹配) if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; // 如果桶用红黑树实现 if (node instanceof TreeNode) // 调用红黑树的删除方法 ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); // 链表结构, 第一个就是要删除的节点 else if (node == p) tab[index] = node.next; else // 链表结构, 且要删除的节点不是第一个 p.next = node.next; // 修改相关的值 ++modCount; --size; // 在 HashMap 中, 该方法为空方法, // 为 HashMap 的子类, LinkedHashMap 服务 afterNodeRemoval(node); return node; &#125; &#125; return null; &#125; /** * 清空 HashMap */ public void clear() &#123; Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125; &#125;/** * 删除指定 key 和 value 的键值对 * * @param key * @param value * @return 删除成功返回 true */ @Override public boolean remove(Object key, Object value) &#123; return removeNode(hash(key), key, value, true, true) != null; &#125; 2.7 查123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 返回指定 key 的 value, 如果 value 为 null, 返回 null, * 1. 通过 hash(Object key) 计算哈希值 * 2. 通过 getNode(int hash, Object key) 获取 value * 3. 如果 node 为 null, 返回 null, 否则返回 node.value */ public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; /** * 根据 key 获取 key 对应的键值对 * 1. * * @param hash key 的哈希值 * @param key 指定的 key * @return 返回 node, 没有返回 null */ final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; // 使用局部变量, 提高性能 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 哈希表不为空, key 对应的桶不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // 检查第一个节点 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; // 检查后续节点(如果有) // 当前的桶用红黑树实现, 调用红黑树的 get 方法 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; // 不是红黑树, 链表 // 遍历 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; // 没找到 return null; &#125;/** * 获取指定 key 映射的 node 的值, 如果没有映射到, 返回默认值 defaultValue * * @param key 指定 key * @param defaultValue 默认值 * @return 找到返回节点的值, 否则返回默认值 */ @Override public V getOrDefault(Object key, V defaultValue) &#123; Node&lt;K, V&gt; e; return (e = getNode(hash(key), key)) == null ? defaultValue : e.value; &#125; 2.8 改123456789101112131415161718192021222324252627282930313233343536373839/** * 使用 newValue 替换 key 和 oldValue 映射到的键值对中的 value * * @param key * @param oldValue * @param newValue * @return 替换成功, 返回true */@Overridepublic boolean replace(K key, V oldValue, V newValue) &#123; Node&lt;K, V&gt; e; V v; if ((e = getNode(hash(key), key)) != null &amp;&amp; ((v = e.value) == oldValue || (v != null &amp;&amp; v.equals(oldValue)))) &#123; e.value = newValue; afterNodeAccess(e); return true; &#125; return false;&#125;/** * 使用参数 value 替换 key 映射到的键值对中的 value * * @param key * @param value * @return 替换成功, 返回true */@Overridepublic V replace(K key, V value) &#123; Node&lt;K, V&gt; e; if ((e = getNode(hash(key), key)) != null) &#123; V oldValue = e.value; e.value = value; afterNodeAccess(e); return oldValue; &#125; return null;&#125; 2.9 resize()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113/** * 对 table 进行初始化或者扩容 * table 为null, 进行初始化, 否则扩容 * 扩容后的容量为之前的 2 倍, 扩容后节点的位置要么在 原位置 要么在 原位置+旧容量 * 扩容步骤: * 1. 计算扩容后的容量, 扩容阈值. * 2. 修改扩容阈值为新值 * 3. 根据扩容后的容量新建 table * 4. 将旧 table 中的元素复制到新 table 中 * * @return the table */final Node&lt;K,V&gt;[] resize() &#123; // 原来的 table Node&lt;K,V&gt;[] oldTab = table; // 原来的容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 原来的扩容阈值 int oldThr = threshold; int newCap, newThr = 0; // 原来的容量 &gt; 0, 扩容 if (oldCap &gt; 0) &#123; // 原来的容量已达到最大值, 无法扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; // 将扩容阈值设为 正无穷 threshold = Integer.MAX_VALUE; // 返回原来的表 return oldTab; &#125; // 容量扩容为之前的 2 倍 // 如果扩容后的容量小于最大容量, 且原来的容量大于默认容量, 扩容阈值扩大为之前的 2 倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 初始化 else if (oldThr &gt; 0) // 新的容量设为 旧的扩容阈值 newCap = oldThr; else &#123; // 使用默认容量 newCap = DEFAULT_INITIAL_CAPACITY; // 计算默认容量的扩容阈值 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的扩容阈值 if (newThr == 0) &#123;// 在当上面的条件判断中, 只有oldThr &gt; 0成立时, newThr == 0 // 计算得到的扩容阈值 float ft = (float)newCap * loadFactor; //当新容量&lt; MAXIMUM_CAPACITY且ft &lt; (float)MAXIMUM_CAPACITY, 新的临界值为ft, 否则为Integer.MAX_VALUE newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; // 更新扩容阈值 threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) // 根据新的容量 新建个表 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; // 修改 table 为新表 table = newTab; // 如果原来的 table 中有数据, 复制数据 if (oldTab != null) &#123; // 遍历旧表的每个 hash 桶 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; // 用 e 记录旧桶, 如果旧桶不为 bull if ((e = oldTab[j]) != null) &#123; // 旧桶置为 null oldTab[j] = null; // 判断第一个元素 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 旧桶用红黑树实现 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 旧桶用链表实现 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; // 遍历旧桶 do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引 + 旧容量 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 复制数据, 索引未变 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 复制数据, 索引为 原索引 + 旧容量 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 2.10 克隆和序列化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119/** * 浅拷贝。 * clone方法虽然生成了新的HashMap对象, 新的HashMap中的table数组虽然也是新生成的, 但是数组中的元素还是引用以前的HashMap中的元素. * 这就导致在对HashMap中的元素进行修改的时候, 即对数组中元素进行修改, 会导致原对象和clone对象都发生改变, 但进行新增或删除就不会影响对方, 因为这相当于是对数组做出的改变, clone对象新生成了一个数组. * * @return hashMap的浅拷贝 */@SuppressWarnings(&quot;unchecked&quot;)@Overridepublic Object clone() &#123; HashMap&lt;K,V&gt; result; try &#123; result = (HashMap&lt;K,V&gt;)super.clone(); &#125; catch (CloneNotSupportedException e) &#123; // this shouldn&#x27;t happen, since we are Cloneable throw new InternalError(e); &#125; result.reinitialize(); result.putMapEntries(this, false); return result;&#125;/** * 将此 HashMap 的信息序列化到 java.io.ObjectOutputStream */private void writeObject(java.io.ObjectOutputStream s) throws IOException &#123; int buckets = capacity(); // Write out the threshold, loadfactor, and any hidden stuff s.defaultWriteObject(); // 写入总容量 s.writeInt(buckets); // 写入实际容量 s.writeInt(size); // 写入键值对 internalWriteEntries(s);&#125;// 序列化 键值对void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException &#123; Node&lt;K,V&gt;[] tab; if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; s.writeObject(e.key); s.writeObject(e.value); &#125; &#125; &#125;&#125;/** * 反序列化 */private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException &#123; // Read in the threshold (ignored), loadfactor, and any hidden stuff s.defaultReadObject(); // 初始化 reinitialize(); // 负载因子不合法 抛出异常 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new InvalidObjectException(&quot;Illegal load factor: &quot; + loadFactor); s.readInt(); // 读取并忽略桶数 int mappings = s.readInt(); // 读出实际容量 size // 容量不合法, 抛出异常 if (mappings &lt; 0) throw new InvalidObjectException(&quot;Illegal mappings count: &quot; + mappings); else if (mappings &gt; 0) &#123; // (if zero, use defaults) // Size the table using given load factor only if within // range of 0.25...4.0 // 调整 hashMap 大小 float lf = Math.min(Math.max(0.25f, loadFactor), 4.0f); // 负载因子 float fc = (float)mappings / lf + 1.0f; // 初步计算的总容量 // 处理后的总容量 int cap = ((fc &lt; DEFAULT_INITIAL_CAPACITY) ? DEFAULT_INITIAL_CAPACITY : (fc &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)fc)); // 计算的扩容阈值 float ft = (float)cap * lf; // 处理后的扩容阈值 threshold = ((cap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; MAXIMUM_CAPACITY) ? (int)ft : Integer.MAX_VALUE); // Check Map.Entry[].class since it&#x27;s the nearest public type to // what we&#x27;re actually creating. SharedSecrets.getJavaOISAccess().checkArray(s, Map.Entry[].class, cap); @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] tab = (Node&lt;K,V&gt;[])new Node[cap]; table = tab; // 读出 key 和 value, 并插入 HashMap 中 for (int i = 0; i &lt; mappings; i++) &#123; @SuppressWarnings(&quot;unchecked&quot;) K key = (K) s.readObject(); @SuppressWarnings(&quot;unchecked&quot;) V value = (V) s.readObject(); putVal(hash(key), key, value, false, false); &#125; &#125;&#125;/** * 初始化 HashMap, 由clone和readObject调用. */void reinitialize() &#123; table = null; entrySet = null; keySet = null; values = null; modCount = 0; threshold = 0; size = 0;&#125; 2.11 红黑树因时间原因只是简单的注释了一下方法的作用, 具体实现之后再补充吧. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585 /** * JDK1.8 新增. 用来支持红黑树的实现 * 红黑树的性质: * 1. 节点为红色或黑色 * 2. 根节点为黑色 * 3. 所有叶子为黑色 * 4. 每个红色节点必须有两个黑色字节点(从根节点到每个叶子的路径上不能出现连续的两个红色节点) * 5. 从任一节点到其每个叶子节点的所有简单路径包含相同数目的黑色节点 */ static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // 父节点 TreeNode&lt;K,V&gt; left; // 左节点 TreeNode&lt;K,V&gt; right; // 右节点 TreeNode&lt;K,V&gt; prev; // 前节点 boolean red; // true 表示该节点为红色, false 表示该节点为黑色 TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; /** * 获取根节点 */ final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; &#125; /** * 确保 root 是桶的第一个元素, 将 root 移到桶中第一个 */ static &lt;K,V&gt; void moveRootToFront(Node&lt;K,V&gt;[] tab, TreeNode&lt;K,V&gt; root) &#123; int n; if (root != null &amp;&amp; tab != null &amp;&amp; (n = tab.length) &gt; 0) &#123; int index = (n - 1) &amp; root.hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index]; if (root != first) &#123; Node&lt;K,V&gt; rn; tab[index] = root; TreeNode&lt;K,V&gt; rp = root.prev; if ((rn = root.next) != null) ((TreeNode&lt;K,V&gt;)rn).prev = rp; if (rp != null) rp.next = rn; if (first != null) first.prev = root; root.next = first; root.prev = null; &#125; assert checkInvariants(root); &#125; &#125; /** * 寻找哈希值为 h, key 为 k 的节点 */ final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.find(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); return null; &#125; /** * 获取哈希值为 h, key 为 k 的节点, 通过 root 查找. */ final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123; return ((parent != null) ? root() : this).find(h, k, null); &#125; /** * 比较2个对象的大小 */ static int tieBreakOrder(Object a, Object b) &#123; int d; if (a == null || b == null || (d = a.getClass().getName(). compareTo(b.getClass().getName())) == 0) d = (System.identityHashCode(a) &lt;= System.identityHashCode(b) ? -1 : 1); return d; &#125; /** * 将链表转为红黑树 */ final void treeify(Node&lt;K,V&gt;[] tab) &#123; TreeNode&lt;K,V&gt; root = null; for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (root == null) &#123; x.parent = null; x.red = false; root = x; &#125; else &#123; K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; root = balanceInsertion(root, x); break; &#125; &#125; &#125; &#125; moveRootToFront(tab, root); &#125; /** * 红黑树转为链表 */ final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd; &#125; /** * 添加一个键值对 */ final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125; &#125; /** * 删除键值对 */ final void removeTreeNode(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, boolean movable) &#123; int n; if (tab == null || (n = tab.length) == 0) return; int index = (n - 1) &amp; hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index], root = first, rl; TreeNode&lt;K,V&gt; succ = (TreeNode&lt;K,V&gt;)next, pred = prev; if (pred == null) tab[index] = first = succ; else pred.next = succ; if (succ != null) succ.prev = pred; if (first == null) return; if (root.parent != null) root = root.root(); if (root == null || (movable &amp;&amp; (root.right == null || (rl = root.left) == null || rl.left == null))) &#123; tab[index] = first.untreeify(map); // too small return; &#125; TreeNode&lt;K,V&gt; p = this, pl = left, pr = right, replacement; if (pl != null &amp;&amp; pr != null) &#123; TreeNode&lt;K,V&gt; s = pr, sl; while ((sl = s.left) != null) // find successor s = sl; boolean c = s.red; s.red = p.red; p.red = c; // swap colors TreeNode&lt;K,V&gt; sr = s.right; TreeNode&lt;K,V&gt; pp = p.parent; if (s == pr) &#123; // p was s&#x27;s direct parent p.parent = s; s.right = p; &#125; else &#123; TreeNode&lt;K,V&gt; sp = s.parent; if ((p.parent = sp) != null) &#123; if (s == sp.left) sp.left = p; else sp.right = p; &#125; if ((s.right = pr) != null) pr.parent = s; &#125; p.left = null; if ((p.right = sr) != null) sr.parent = p; if ((s.left = pl) != null) pl.parent = s; if ((s.parent = pp) == null) root = s; else if (p == pp.left) pp.left = s; else pp.right = s; if (sr != null) replacement = sr; else replacement = p; &#125; else if (pl != null) replacement = pl; else if (pr != null) replacement = pr; else replacement = p; if (replacement != p) &#123; TreeNode&lt;K,V&gt; pp = replacement.parent = p.parent; if (pp == null) root = replacement; else if (p == pp.left) pp.left = replacement; else pp.right = replacement; p.left = p.right = p.parent = null; &#125; TreeNode&lt;K,V&gt; r = p.red ? root : balanceDeletion(root, replacement); if (replacement == p) &#123; // detach TreeNode&lt;K,V&gt; pp = p.parent; p.parent = null; if (pp != null) &#123; if (p == pp.left) pp.left = null; else if (p == pp.right) pp.right = null; &#125; &#125; if (movable) moveRootToFront(tab, r); &#125; /** * 给节点太多的桶分割 * * @param map the map * @param tab the table for recording bin heads * @param index the index of the table being split * @param bit the bit of hash to split on */ final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; if (loHead != null) &#123; if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125; &#125; /* ------------------------------------------------------------ */ // Red-black tree methods, all adapted from CLR // 左旋 static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateLeft(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) &#123; TreeNode&lt;K,V&gt; r, pp, rl; if (p != null &amp;&amp; (r = p.right) != null) &#123; if ((rl = p.right = r.left) != null) rl.parent = p; if ((pp = r.parent = p.parent) == null) (root = r).red = false; else if (pp.left == p) pp.left = r; else pp.right = r; r.left = p; p.parent = r; &#125; return root; &#125; // 右旋 static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateRight(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) &#123; TreeNode&lt;K,V&gt; l, pp, lr; if (p != null &amp;&amp; (l = p.left) != null) &#123; if ((lr = p.left = l.right) != null) lr.parent = p; if ((pp = l.parent = p.parent) == null) (root = l).red = false; else if (pp.right == p) pp.right = l; else pp.left = l; l.right = p; p.parent = l; &#125; return root; &#125; // 保证插入后平衡 static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceInsertion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) &#123; x.red = true; for (TreeNode&lt;K,V&gt; xp, xpp, xppl, xppr;;) &#123; if ((xp = x.parent) == null) &#123; x.red = false; return x; &#125; else if (!xp.red || (xpp = xp.parent) == null) return root; if (xp == (xppl = xpp.left)) &#123; if ((xppr = xpp.right) != null &amp;&amp; xppr.red) &#123; xppr.red = false; xp.red = false; xpp.red = true; x = xpp; &#125; else &#123; if (x == xp.right) &#123; root = rotateLeft(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &#125; if (xp != null) &#123; xp.red = false; if (xpp != null) &#123; xpp.red = true; root = rotateRight(root, xpp); &#125; &#125; &#125; &#125; else &#123; if (xppl != null &amp;&amp; xppl.red) &#123; xppl.red = false; xp.red = false; xpp.red = true; x = xpp; &#125; else &#123; if (x == xp.left) &#123; root = rotateRight(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &#125; if (xp != null) &#123; xp.red = false; if (xpp != null) &#123; xpp.red = true; root = rotateLeft(root, xpp); &#125; &#125; &#125; &#125; &#125; &#125; // 删除后平衡 static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceDeletion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) &#123; for (TreeNode&lt;K,V&gt; xp, xpl, xpr;;) &#123; if (x == null || x == root) return root; else if ((xp = x.parent) == null) &#123; x.red = false; return x; &#125; else if (x.red) &#123; x.red = false; return root; &#125; else if ((xpl = xp.left) == x) &#123; if ((xpr = xp.right) != null &amp;&amp; xpr.red) &#123; xpr.red = false; xp.red = true; root = rotateLeft(root, xp); xpr = (xp = x.parent) == null ? null : xp.right; &#125; if (xpr == null) x = xp; else &#123; TreeNode&lt;K,V&gt; sl = xpr.left, sr = xpr.right; if ((sr == null || !sr.red) &amp;&amp; (sl == null || !sl.red)) &#123; xpr.red = true; x = xp; &#125; else &#123; if (sr == null || !sr.red) &#123; if (sl != null) sl.red = false; xpr.red = true; root = rotateRight(root, xpr); xpr = (xp = x.parent) == null ? null : xp.right; &#125; if (xpr != null) &#123; xpr.red = (xp == null) ? false : xp.red; if ((sr = xpr.right) != null) sr.red = false; &#125; if (xp != null) &#123; xp.red = false; root = rotateLeft(root, xp); &#125; x = root; &#125; &#125; &#125; else &#123; // symmetric if (xpl != null &amp;&amp; xpl.red) &#123; xpl.red = false; xp.red = true; root = rotateRight(root, xp); xpl = (xp = x.parent) == null ? null : xp.left; &#125; if (xpl == null) x = xp; else &#123; TreeNode&lt;K,V&gt; sl = xpl.left, sr = xpl.right; if ((sl == null || !sl.red) &amp;&amp; (sr == null || !sr.red)) &#123; xpl.red = true; x = xp; &#125; else &#123; if (sl == null || !sl.red) &#123; if (sr != null) sr.red = false; xpl.red = true; root = rotateLeft(root, xpl); xpl = (xp = x.parent) == null ? null : xp.left; &#125; if (xpl != null) &#123; xpl.red = (xp == null) ? false : xp.red; if ((sl = xpl.left) != null) sl.red = false; &#125; if (xp != null) &#123; xp.red = false; root = rotateRight(root, xp); &#125; x = root; &#125; &#125; &#125; &#125; &#125; /** * 检查是否符合红黑树 */ static &lt;K,V&gt; boolean checkInvariants(TreeNode&lt;K,V&gt; t) &#123; TreeNode&lt;K,V&gt; tp = t.parent, tl = t.left, tr = t.right, tb = t.prev, tn = (TreeNode&lt;K,V&gt;)t.next; if (tb != null &amp;&amp; tb.next != t) return false; if (tn != null &amp;&amp; tn.prev != t) return false; if (tp != null &amp;&amp; t != tp.left &amp;&amp; t != tp.right) return false; if (tl != null &amp;&amp; (tl.parent != t || tl.hash &gt; t.hash)) return false; if (tr != null &amp;&amp; (tr.parent != t || tr.hash &lt; t.hash)) return false; if (t.red &amp;&amp; tl != null &amp;&amp; tl.red &amp;&amp; tr != null &amp;&amp; tr.red) return false; if (tl != null &amp;&amp; !checkInvariants(tl)) return false; if (tr != null &amp;&amp; !checkInvariants(tr)) return false; return true; &#125; &#125;&#125; 2.12 其他API123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117 /** * 返回存储的键值对的数量 * * @return 存储的键值对的数量 */ public int size() &#123; return size; &#125; /** * 返回 HashMap 的负载因子 */ final float loadFactor() &#123; return loadFactor; &#125;/** * 返回 HashMap 的容量 */ final int capacity() &#123; return (table != null) ? table.length : (threshold &gt; 0) ? threshold : DEFAULT_INITIAL_CAPACITY; &#125; /** * 如果 Map 中没有键值映射对返回 ture * * @return &lt;tt&gt;true&lt;/tt&gt; 如果 Map 中没有键值对返回 ture */ public boolean isEmpty() &#123; return size == 0; &#125; /** * 判断 map 中是否包含 key 为指定参数的键值对 * * @param key 指定的 key * @return 有返回ture */ public boolean containsKey(Object key) &#123; return getNode(hash(key), key) != null; &#125; /** * 如果hashMap中的键值对有一对或多对的value为参数value, 返回true * * @param value 参数value * @return 如果hashMap中的键值对有一对或多对的value为参数value, 返回true */ public boolean containsValue(Object value) &#123; Node&lt;K, V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; //遍历数组table for (int i = 0; i &lt; tab.length; ++i) &#123; //遍历桶中的node for (Node&lt;K, V&gt; e = tab[i]; e != null; e = e.next) &#123; if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; &#125; &#125; return false; &#125; /** * 返回hashMap中所有key的视图. * 改变hashMap会影响到set, 反之亦然. * 如果当迭代器迭代set时, hashMap被修改(除非是迭代器自己的remove()方法), 迭代器的结果是不确定的. * set支持元素的删除, 通过Iterator.remove, Set.remove, removeAll, retainAll, clear操作删除hashMap中对应的键值对. * 不支持add和addAll方法. * * @return 返回hashMap中所有key的set视图 */ public Set&lt;K&gt; keySet() &#123; Set&lt;K&gt; ks = keySet; if (ks == null) &#123; ks = new KeySet(); keySet = ks; &#125; return ks; &#125; /** * 返回hashMap中所有value的collection视图 * 改变hashMap会改变collection, 反之亦然. * 如果当迭代器迭代collection时, hashMap被修改（除非是迭代器自己的remove()方法）, 迭代器的结果是不确定的. * collection支持元素的删除, 通过Iterator.remove, Collection.remove, removeAll, retainAll, clear操作删除hashMap中对应的键值对. * 不支持add和addAll方法. * * @return 返回hashMap中所有key的collection视图 */ public Collection&lt;V&gt; values() &#123; Collection&lt;V&gt; vs = values; if (vs == null) &#123; vs = new Values(); values = vs; &#125; return vs; &#125; /** * 返回hashMap中所有键值对的set视图 * 改变hashMap会影响到set, 反之亦然. * 如果当迭代器迭代set时, hashMap被修改(除非是迭代器自己的remove()方法), 迭代器的结果是不确定的. * set支持元素的删除, 通过Iterator.remove, Set.remove, removeAll, retainAll, clear操作删除hashMap中对应的键值对. * 不支持add和addAll方法. * * @return 返回hashMap中所有键值对的set视图 */ public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es; &#125; 3. 有关问题1. 为什么链表转红黑树的阈值是 8 ?阈值为 8 是在时间和空间上权衡的结果. 红黑树节点大小为链表节点的 2 倍, 在节点太少时, 红黑树查找性能优势并不明显, 付出 2 倍的空间代价作者觉得不值得. 在理想的情况下, 使用随机的哈希值, 节点分布在 hash 桶中的频率准循泊松分布, 按照泊松分布的公式计算,链表中不同节点个数的概率为: 个数 概率 0 0.60653066 1 0.30326533 2 0.07581633 3 0.01263606 4 0.00157952 5 0.00015795 6 0.00001316 7 0.00000094 8 0.00000006 节点个数为 8 的概率为 0.00000006, 这个概率足够低了, 并且到 8 个节点时, 红黑树的性能也开始展现出来. 2. 为什么红黑树转链表的阈值为 6 而不是 8 呢?如果这样设置了, 当节点个数在 8 左右徘徊时, 会频繁的进行 链表 和 红黑树 的转换, 造成性能的损耗. 3. threshold 除了用于存放扩容阈值还有其他作用吗?新建 HashMap 时, 还会用来存初始化时的容量. HashMap 直到我们第一次插入节点时, 才会对 table 进行初始化, 避免不必要的空间浪费. 4. HashMap 的初始容量, 和容量限制默认初始容量为 16, HashMap 的容量必须为 2 的 N 次方, HashMap 会根据我们传入的容量计算第一个大于等于该容量的 2 的幂. 5. HashMap 怎么计算容量的12345678910static final int tableSizeFor(int cap) &#123; // 处理 n 本来就是 2 的幂的情况 int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; $&gt;&gt;&gt;$ : 无符号右移. 以 0010 0110 举例： ​ n 0010 0110n&gt;&gt;&gt;1 0001 0011 n|n&gt;&gt;&gt;1 0011 0111 我们可以看到 n|n&gt;&gt;&gt;1 将n的最高位和次高位都置为了 1. 同理 n|n&gt;&gt;&gt;2 会将 n 的高 4 位置为 1. 经过上述函数的运算后, 会将 n 由 $001X XXXX$ 变成 $0011 1111$, 也就是说将 n 的低位全置为 1. 这时候在对 n 进行 + 1, 就可以得到一个比 n 大的 2 的幂. 开头的 - 1, 是为了处理 n 本来就是 2 的幂的情况. 6. HashMap的容量必须为 2 的幂, 为什么?HashMap 通过 (n - 1) &amp; hash 计算索引, 当 n 为 2 的幂时, n - 1 的底位都是 1, 此时任何值和 n - 1进行 &amp; 运算的结果都为该值的低位, 实现了均匀分布. 为什么用位运算(&amp;) 而不是取余(%) 计算索引呢? 位运算比取余快得多. 7. HashMap 插入数据的流程? 8. HashMap 怎么计算哈希值的?12345static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 拿到 key 的 hashCode, 并将 hashCode 的高 16 位和 hashCode 进行异或运算. 8.1 为什么要和 hashCode 的高 16 位进行异或运算?索引是通过 (n - 1) &amp; hash 计算得到的. 为了在 n 比较小的时候, 让高位也参加运算, 使索引更散列. 9. resize() 扩容怎么计算新的索引, 为什么?通过 e.hash &amp; oldCap == 0 计算新索引, 如果为 true 索引不变, 否则索引变为 旧索引 + 旧容量. 索引是通过 (n - 1) &amp; hash 计算得到的. 扩容之后 (n - 1) 比之前多一位 1, 大小为 旧容量. 10. HashMap 是线程安全的吗?不是, HashMap 在多并发下存在数据覆盖, 遍历同时进行修改会抛出 ConcurrentModificationException 异常. JDK1.8 之前还存在死循环问题. 11. JDK1.8 主要进行了哪些优化? 底层数据结构从 “数组+链表” 改成 “数组+链表+红黑树”, 优化了哈希冲突严重时, 链表过长的查询性能: $O(n) - &gt; O(logn)$ 计算 table 初始容量的方法发生了改变, 老方法是从 1 开始不断的左移, 直到大于等于指定的容量. 优化了 hash 值的计算方式. 12345678910// JDK 1.7static int hash(int h) &#123; h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125;// JDK 1.8static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 扩容是的插入方式从”头插入”改为”尾插入”, 避免了并发死循环. 扩容计算节点索引从 “h &amp; (length-1)” 改成 “hash &amp; oldCap” 12. HashMap 和其他 Map 的区别Hashtable: 早期的线程安全 Map, 直接通过在方法加 synchronized 实现线程安全, 效率较低. 不允许键值为null CocurrentHashMap: 线程安全的 Map, 通过 synchronized + CAS 实现线程安全. 不允许键值为null LiknedHashMap: HashMap的子类, 通过 head, tail 维持双向链表, 通过 Entry 的 after, before维护节点的顺序. 允许键值为null, 非线程安全. TreeMap: 通过实现 Comparator 实现自定义顺序的 Map, 如果没有指定, 按 key 的升序排序, key 如果没有实现 Comparable 接口, 则抛出异常.不允许键值为null. 非线程安全. HashMap: 最常用的 Map, 非线程安全, 无序, 允许键值为null.","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"}]},{"title":"Java集合ArrayList","slug":"Java集合ArrayList","date":"2021-04-18T12:30:24.000Z","updated":"2022-04-13T13:31:48.119Z","comments":true,"path":"2021/04/18/Java集合ArrayList/","link":"","permalink":"https://tang7o.cn/2021/04/18/Java%E9%9B%86%E5%90%88ArrayList/","excerpt":"","text":"1. 概述1.1 说明作者小白一枚, 水平有限, 如有错误还望各位指正. 本文章中源码来自: JDK8. 1.2 简介ArrayList 是容量可变的非线程安全列表, 使用数组实现. 适用于查询为主的场景, 提供了增加, 删除, 更改, 遍历的方法. 1.3 继承关系 RandomAccess: 标记接口, 标记实现该接口的集合使用索引遍历比迭代器更快. Serializable: 标记接口, 标记实现该接口的类可以序列化. Cloneable: 标记接口, 标记实现该接口的类可以调用 clone 方法, 否则会抛出 CloneNotSupportedException (克隆不被支持)异常. Iterable: 实现此接口允许对象成为 “for-each循环” 语句的目标. Collection: Java 集合体系的根接口, 重写了 Iterable 接口的 spliterator 方法, 定义了集合基本的待实现方法. AbstractCollection: 重写了 Conllection 接口中基础的方法, 减少具体集合类的实现成本. 部分方法需要具体集合自我实现, 如 add 方法. List: 重写了 Collection 接口的 spliterator 方法, 定义了 sort, copyOf, replaceAll, of 方法. 添加了一些待实现方法, 如: addAll, get, set等. AbstractList: 重写了 List 中的大部分方法, 作用与 AbstractCollection 类似. 2 源码2.1 字段123456789101112131415161718192021222324252627282930313233 /** * 序列化版本标识，序列化和反序列化时使用 */private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始容量. */ private static final int DEFAULT_CAPACITY = 10; /** * 用于 ArrayList 空实例的共享空数组实例. */ private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; /** * 用于默认大小空实例的共享空数组实例. * 我们将其与 EMPTY_ELEMENTDATA 区分开来, 以了解添加第一个元素时应该膨胀多少 */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** * 存储 ArrayList 元素的数组缓冲区. * ArrayList 的容量是此数组的长度. * 当添加第一个元素时, 任何 emementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA 的空 ArrayList 都将被扩展为 DEFAULT_CAPACITY. */ transient Object[] elementData; // non-private to simplify nested class access /** * ArrayList 的大小. */ private int size; 2.2 构造方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 构造具有指定初始容量的空列表。 * * @param initialCapacity 列表的初始容量 * @throws 如果容量为负数, 抛出 IllegalArgumentException */public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; // 指定大小大于0 创建指定大小的列表 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; // 指定大小为 0, 指向同一个空列表, 可以减少内存的使用 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; // 指定大小小于 0, 抛出 IllegalArgumentException 异常. throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); &#125;&#125;/** * 无参构造 * 创建一个大小为 10 的列表. */public ArrayList() &#123; // 当添加第一个元素时, 任何指向 DEFAULTCAPACITY_EMPTY_ELEMENTDATA 的空 ArrayList 都将被扩展为容量为 DEFAULT_CAPACITY(10)的列表. this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125;/** * 按照集合迭代器返回元素的顺序, 构造一个包含指定集合元素的列表. * * @param c 要将其元素放入此列表的集合. * @throws 如果参数为null, 抛出 NullPointerException */public ArrayList(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); if ((size = a.length) != 0) &#123; if (c.getClass() == ArrayList.class) &#123; elementData = a; &#125; else &#123; elementData = Arrays.copyOf(a, size, Object[].class); &#125; &#125; else &#123; // 指向空数组. elementData = EMPTY_ELEMENTDATA; &#125;&#125; 2.3 添加2.3.1 添加单个元素1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889 /** * 将指定的元素追加到此列表的末尾。 * * @param e 要添加的元素 * @return true (由 Collection.add 指定) */ public boolean add(E e) &#123; // 检查是否需要扩容 ensureCapacityInternal(size + 1); elementData[size++] = e; return true; &#125; /** * 在列表的指定位置插入一个元素, 该位置之后的元素后移一位. * * @param index 要插入的位置的索引 * @param element 插入的元素 * @throws 索引超出边界,抛出 IndexOutOfBoundsException */ public void add(int index, E element) &#123; // 判断索引是否超出界限, 超出抛出 IndexOutOfBoundsException 异常. rangeCheckForAdd(index); ensureCapacityInternal(size + 1); System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; &#125; private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; // 如果是用空参数创建的列表, 第一次添加数据时将其扩展为容量最小为 DEFAULT_CAPACITY(10) 的列表. if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity; &#125; private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); &#125; private void ensureExplicitCapacity(int minCapacity) &#123; // 用于记录列表被修改的次数. // 用来限制用户在迭代时修改列表, 造成数据错乱. modCount++; // 扩容, 可能溢出 if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125; /** * 列表的最大容量. * 有些虚拟机在数组中保存 header word 头部字, 用于存储数组的容量, 占八位.因此,列表的最大容量为 Integer.MAX_VALUE - 8 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * 扩容, 确保至少可以容纳 minCapacity 个元素 * * @param minCapacity 所需最小容量 */ private void grow(int minCapacity) &#123; // 存在整数溢出的可能 int oldCapacity = elementData.length; // 扩大 1.5 倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) // 可能整数溢出 // 可能 newCapacity &lt; minCapacity newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity);// 通过 System.arraycopy 方法将原数组拷贝到容量为 newCapacity 的新数组中 elementData = Arrays.copyOf(elementData, newCapacity); &#125; private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; 2.3.2 批量添加1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 将指定集合中的所有元素按指定集合的迭代器返回的顺序追加到此列表的末尾 * 添加过程中的元素有发生改变的可能. */public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0;&#125;/** * 从指定位置开始, 将指定集合中的元素插入此列表. 该位置及其之后的元素后移. */public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; // 判断索引是否超出界限, 超出抛出 IndexOutOfBoundsException 异常. rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0;&#125;/** * 判断索引是否超出界限. */private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125; 2.4 删除2.4.1 删除单个元素123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778 /** * 删除指定位置的元素. * 其后元素前移. * * @param index 要删除元素的索引 * @return 被删除的元素 * @throws 超出边界,抛出 IndexOutOfBoundsException */ public E remove(int index) &#123; // 判断索引是否超界 rangeCheck(index);// 列表修改次数加一 modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) // 将elemenData中index+1及其后面的元素都向前移动一个下标 System.arraycopy(elementData, index+1, elementData, index, numMoved); // 根据上一步的操作, size-1位置的对象向前移动了一个下标 // 如果没有elementData[--size]==null, 可能会导致内存泄漏, 若没有这一步操作, 该内存一直指向之前的元素, GC 不会认为它是垃圾, 故无法回收内存造成内存泄漏. elementData[--size] = null; return oldValue; &#125; /** * 检查索引是否在范围内. * 和 添加元素 时的检查函数的区别为: 此函数不检查索引是否为负数, 并且索引不能为 size. 因为在执行此方法之前数组会检查索引, 如果为负数会抛出 ArrayIndexOutOfBoundsException. */ private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; /** * 从列表中删除指定元素的第一个匹配, 如果列表中没有此元素, 则保持列表不变 * null 也被当作一个元素 * @param o 指定删除的元素 * @return true 如果删除了指定元素 */ public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; // 删除该位置元素, 其后元素前移 fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; // 删除该位置元素, 其后元素前移 fastRemove(index); return true; &#125; &#125; return false; &#125; /* * 删除当前位置的元素, 其后元素前移 */ private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; // 删除的元素不是最后一个 if (numMoved &gt; 0) // 索引后的元素前移 System.arraycopy(elementData, index+1, elementData, index, numMoved); // 同上, 让 GC 回收内存. elementData[--size] = null; &#125; 2.4.2 批量操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/** * 删除列表中索引介于 [fromIndex, toIndex) 的元素. * 索引为 fromIndex 的元素会被删除, 索引为 toIndex 的元素会被保留 * @throws 超界抛 IndexOutOfBoundsException */protected void removeRange(int fromIndex, int toIndex) &#123; // 修改次数 + 1 modCount++; // toIndex(包括)之后的元素数量 int numMoved = size - toIndex; // 将 toIndex(包括)之后的所有元素复制到 fromIndex(包括)之后. System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // 删除后的元素数量 int newSize = size - (toIndex-fromIndex); // GC!! 干活了 for (int i = newSize; i &lt; size; i++) &#123; elementData[i] = null; &#125; size = newSize;&#125;/** * 从此列表中删除指定集合中包含的所有元素 * * @param c 指定的集合 * @return 如果在删除期间此 列表 因调用而更改, 返回 true * @throws 如果集合中的元素和列表元素不兼容, 抛出 ClassCastException * @throws 指定集合为null, 抛出 NullPointerException */public boolean removeAll(Collection&lt;?&gt; c) &#123; // 非空检验 Objects.requireNonNull(c); return batchRemove(c, false);&#125;/** * 从此列表中 保留 指定集合中包含的所有元素 * 和上个方法的区别为一个删除, 一个保留 * 具体差异: 传入 batchRemove 的参数不同 */public boolean retainAll(Collection&lt;?&gt; c) &#123; // 非空检验 Objects.requireNonNull(c); return batchRemove(c, true);&#125;private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) &#123; final Object[] elementData = this.elementData; int r = 0, w = 0; boolean modified = false; try &#123; for (; r &lt; size; r++) // 将需要保留的元素前移 if (c.contains(elementData[r]) == complement) elementData[w++] = elementData[r]; &#125; finally &#123; // 即使 c.contains() 抛出异常, 也要于AbstractCollection 保持行为兼容性 // 备注：ArrayList重写了AbstractCollection中的removeAll方法，removeAll调用了batchRemove if (r != size) &#123; // 可能因 try 中的循环出现了异常 // 可能其他线程调用了该列表 // 将多出来的元素复制到 try 保留的元素后面. System.arraycopy(elementData, r, elementData, w, size - r); w += size - r; &#125; if (w != size) &#123; // GC 干活 for (int i = w; i &lt; size; i++) elementData[i] = null; // 这里为什么不是 + 1? // 若有读者知道原因, 还望在评论区告知. modCount += size - w; size = w; modified = true; &#125; &#125; return modified;&#125;/** * 清空列表中的元素. * 执行完成后, 列表为空(全为null) */public void clear() &#123; modCount++; // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0;&#125; 2.5 修改123456789101112131415161718/** * 用指定元素替换列表中指定位置的元素. * * @param index 指定位置的索引 * @param element 存在指定位置的新元素 * @return 指定位置时旧元素 * @throws 索引超界 IndexOutOfBoundsException */public E set(int index, E element) &#123; // 和 remove 用的同一个索引检查函数 rangeCheck(index); // 更换新元素, 返回旧元素 E oldValue = elementData(index); elementData[index] = element; return oldValue;&#125; 2.6 查找12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758 // 位置访问操作// 告诉编译器忽略 unchecked 警告信息@SuppressWarnings(&quot;unchecked&quot;) E elementData(int index) &#123; return (E) elementData[index]; &#125; /** * 获取列表指定位置的元素. * * @param index 要获取的元素的索引 * @return 指定位置的元素 * @throws 索引超界, 抛出 IndexOutOfBoundsException */ public E get(int index) &#123; // 同 remove, set rangeCheck(index); // 这里应该是方便强制类型转换. return elementData(index); &#125; /** * 返回指定元素第一次出现的索引 * 如果列表中没有此元素, 返回 -1 * contains 方法就是调用的此方法: return indexOf(o) &gt;= 0; */ public int indexOf(Object o) &#123; if (o == null) &#123; // null 也当成一个元素 for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; /** * 返回指定元素最后一次出现的索引 * 如果列表中没有此元素, 返回 -1 */ public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; 2.7 序列化和反序列化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 /** * 序列化 */ private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // fail-fast, 后续判断是否有并发处理 int expectedModCount = modCount; // 序列化没有标记 static, transient的字段包括 size. s.defaultWriteObject(); // 序列化 size s.writeInt(size); // 按序 序列化所有元素 for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125;// 有其他线程修改列表 if (modCount != expectedModCount) &#123; // 抛出 fail-fast 异常. throw new ConcurrentModificationException(); &#125; &#125; /** * 反序列化 */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // 反序列化没有标记 static, transient的字段包括 size. s.defaultReadObject(); // 反序列化 size s.readInt(); if (size &gt; 0) &#123; // 根据 size 扩容. int capacity = calculateCapacity(elementData, size); SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity); ensureCapacityInternal(size); Object[] a = elementData; // 反序列化元素并加入列表中. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125; &#125; 2.8 其他API2.8.1 排序 (sort)12345678910111213141516 // 重写于 List 接口@Override// 消除 unchecked 警告 @SuppressWarnings(&quot;unchecked&quot;) public void sort(Comparator&lt;? super E&gt; c) &#123; // fail-fast, 后续判断是否有并发处理 final int expectedModCount = modCount; // 排序, 底层使用 TimSort 实现, XXXX Arrays.sort((E[]) elementData, 0, size, c); // ArrayList被并发处理, 抛出异常 if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; // 修改次数 + 1 modCount++; &#125; 2.8.2 转为数组 (toArray)1234567891011121314151617181920212223242526272829303132333435 /** * 按正确顺序包含此列表中所有元素的数组 * 返回的数组为 elementData 的复制, 修改返回的数组不会对 elementData 造成影响. * * @return 按正确顺序包含此列表中所有元素的数组 */ public Object[] toArray() &#123; // 直接复制 elementData, 然后返回 return Arrays.copyOf(elementData, size); &#125; /** * 返回运行时指定数组类型的数组. * 如果指定数组的容量小于 size, 新建一个容量为size的数组返回. * 否则将数据复制到指定数组返回.* * @param a 指定数组, 如果 a 足够大(容量大于 size), 返回该数组, 否则返回一个相同类型的新数组. * * @return 包含列表元素的数组 * @throws 如果指定数组的类型不是列表元素类型的父类, 抛出 ArrayStoreException * @throws 指定数组为null, 抛出 NullPointerException */ @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) // 利用反射, 返回一个大小为size , 类型和 a 相同的新数组. return (T[]) Arrays.copyOf(elementData, size, a.getClass()); // 将数据复制到 a 中 System.arraycopy(elementData, 0, a, 0, size); // 将 a[size] 置为 null(如果有的话), 对以后确定列表的长度很有用, 但只在调用方知道列表中不包含任何 null 元素时才有用. if (a.length &gt; size) a[size] = null; return a; &#125; 2.8.3 克隆 (clone)1234567891011121314151617/** * 返回此 ArrayList 实例的副本, 浅拷贝 * 返回 Object 使用时需要强制转换 * @return 此 ArrayList 的副本 */public Object clone() &#123; try &#123; ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); // 通过 Arrays.copyOf 拷贝数据. v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; throw new InternalError(e); &#125;&#125; 2.8.4 subList123456789101112/** * 返回此列表 [fromIndex,toIndex) 之间的数据的 视图(SubList 类). * 如果 formIndex 和 toIndex 相等, 返回列表为空. * 返回的列表中的 elementData 和此列表的 elementData 是同一个. * 通过传递子视图可以将列表的操作用作范围操作, 比如: 删除一部分元素可以用, list.subList(from, to).clear(); * */public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, 0, fromIndex, toIndex);&#125; 2.8.5 遍历方式ArrayList 可以通过 for, foreach, foreach-lambda, iterator进行遍历. iterator 又可分为 Iterator 和 ListIterator, 他们分别由内部类 Itr 和 ListItr 实现. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051List&lt;String&gt; strList = new ArrayList&lt;String&gt;(4); strList.add(&quot;1&quot;); strList.add(&quot;2&quot;); strList.add(&quot;3&quot;); // for遍历 for (int i = 0; i &lt; strList.size(); i++) &#123; System.out.println(strList.get(i)); &#125; // foreach // 备注: 只要实现Iterable接口, 就能使用foreach for (String s : strList) &#123; System.out.println(s); &#125; // foreach-lambda遍历 strList.forEach(System.out::println); // iterator遍历 Iterator&lt;String&gt; iterator = strList.iterator(); while (iterator.hasNext())&#123; String str = iterator.next(); System.out.println(str); // 下一次出现ConcurrentModificationException // 问题是因为list的iterator方法返回的是ArrayList的内部类Itr // Itr里面的expectedModCount会与ArrayList的modCount进行比较 // 剩下的就不言而喻 strList.remove(str); // 进行iterator遍历时, 如果进行remove等操作, 调用iterator的方法 // 而不是ArrayList的方法 // iterator.remove(); &#125; // ListIterator可以进行顺序, 逆序遍历, 可以指定index位置开始遍历 ListIterator&lt;String&gt; iterator = strList.listIterator(); while (iterator.hasNext())&#123; System.out.println(iterator.next()); &#125; iterator = strList.listIterator(strList.size()); while (iterator.hasPrevious())&#123; System.out.println(iterator.previous()); iterator.remove(); &#125; // 使用并行遍历, 可以将元素放在不同的迭代器进行并行遍历 Spliterator&lt;String&gt; spliterator = strList.spliterator(); // split, 分而治之, 类似算法里面的分治 Spliterator&lt;String&gt; otherSpliterator = spliterator.trySplit(); spliterator.forEachRemaining(System.out::println); otherSpliterator.forEachRemaining(System.out::println); 3. 一些问题3.1 elementData 为什么用 transient 修饰?transient 用来表示一个域不是该对象序列化的一部分, 当一个对象被序列化的时候, transient 修饰的变量的值是不包括在序列化的表示中的. 但是 ArrayList 又是可序列化的类, elementData 是 ArrayList 具体存放元素的成员, 用 transient 修饰岂不是无法正确序列化, 反序列化了? 其实ArrayList 是通过 writeObject 和 readObject 实现序列化和反序列化. ArrayList 在序列化的时候会调用 writeObject, 将 size 和 elementData 写入 java.io.ObjectOutputStream; 反序列化时再调用 readObject 从 java.io.ObjectOutputStream 获取 size 和 element, 再恢复到 elementData. 为什么不直接对 elementData 序列化呢? 我们知道 elementData 的大小是动态变化的, 绝大多数时候 elementData 的大小要比它存的数据要多, 也就是说 elementData 里面有空数据, 序列化时我们当然不想将这些空数据序列化, 因此 ArrayList 采用了上述的方法序列化, 而不是直接序列化 elementData. 3.2 elementData 为什么是 Object 而不是泛型 E? Java 中泛型的运用的目的是实现对象的重用, 泛型 T 和 Object 类在编写时没有太区别, 只是 JVM 中没有 T 的概念, T 只是存在于编程写时, 进入 JVM 运行时, JVM 会对泛型进行擦除, 也就是替换 T 为第一个限定的类型, 如果没有限定类型就会替换为 Object. Object 可以实例化, 泛型不能实例化. 从反射方面来说, 返回一个泛型的实例时, 不需要经过强制转换, Object 则需要强制转换. 3.3 modCount 的作用modCount 继承于父类 AbstractList, 源码如下: 123456789101112131415161718192021222324252627/** * The number of times this list has been &lt;i&gt;structurally modified&lt;/i&gt;. * Structural modifications are those that change the size of the * list, or otherwise perturb it in such a fashion that iterations in * progress may yield incorrect results. * * &lt;p&gt;This field is used by the iterator and list iterator implementation * returned by the &#123;@code iterator&#125; and &#123;@code listIterator&#125; methods. * If the value of this field changes unexpectedly, the iterator (or list * iterator) will throw a &#123;@code ConcurrentModificationException&#125; in * response to the &#123;@code next&#125;, &#123;@code remove&#125;, &#123;@code previous&#125;, * &#123;@code set&#125; or &#123;@code add&#125; operations. This provides * &lt;i&gt;fail-fast&lt;/i&gt; behavior, rather than non-deterministic behavior in * the face of concurrent modification during iteration. * * &lt;p&gt;&lt;b&gt;Use of this field by subclasses is optional.&lt;/b&gt; If a subclass * wishes to provide fail-fast iterators (and list iterators), then it * merely has to increment this field in its &#123;@code add(int, E)&#125; and * &#123;@code remove(int)&#125; methods (and any other methods that it overrides * that result in structural modifications to the list). A single call to * &#123;@code add(int, E)&#125; or &#123;@code remove(int)&#125; must add no more than * one to this field, or the iterators (and list iterators) will throw * bogus &#123;@code ConcurrentModificationExceptions&#125;. If an implementation * does not wish to provide fail-fast iterators, this field may be * ignored. */protected transient int modCount = 0; modCount 是记录此列表结构修改的次数. 结构修改是指那些改变列表大小的修改, 或者以某种方式扰乱列表, 使得正在进行的迭代可能产生不正确的结果. 此字段由迭代器和 listiterator 方法返回的迭代器和列表迭代器实现使用. 如果此字段的值意外更改, 迭代器会抛出 ConcurrentModificationException 响应next, remove, previous, set 或者 add操作. 提供了快速失败的行为, 而不是在迭代过程中面对并发修改的不确定性行为. 原理: 迭代器将此刻的 modCount 记录下来, 迭代器进行相关操作时查看现在的 modCount 和记录下来的值是否一致, 如果不一致说明发生了并发修改, 抛出异常. 具体实现: 调用 list.iterator() 时返回一个 ArrayList 的内部类 Itr. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/** * Returns an iterator over the elements in this list in proper sequence. * * &lt;p&gt;The returned iterator is &lt;a href=&quot;#fail-fast&quot;&gt;&lt;i&gt;fail-fast&lt;/i&gt;&lt;/a&gt;. * * @return an iterator over the elements in this list in proper sequence */public Iterator&lt;E&gt; iterator() &#123; return new Itr();&#125;/** * An optimized version of AbstractList.Itr */private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; Itr() &#123;&#125; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings(&quot;unchecked&quot;) public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; @Override @SuppressWarnings(&quot;unchecked&quot;) public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; expectedModCount 的初始值为 modCount (记录当前的修改次数) hasNext的判断条件为: cursor!=size 当前迭代的位置不是最大容量返回 true. next 和 remove 操作之前都会检查 expectedModCount 和 modCount 是否相等, 不相等会抛出 ConcurrentModificationException. 如果没有这步操作, 可能会抛出 ArrayIndexOutOfBoundsException 异常(迭代时列表被并发删除了部分数据). 3.4 为什么 hugeCapacity() 会返回 Integer.MAX_VALUE?MAX_ARRAY_SIZE 不是 Integer.MAX_VALUE - 8 吗, 为什么 hugeCapacity() 还返回 Integer.MAX_VALUE? 前文提到: MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8 是因为部分虚拟机在数组中保存 header word 头部字占用 8 个空间. 在这些虚拟机中分配大于IMAX_ARRAY_SIZE 的空间会导致 OOM, 而在其他的虚拟机中则可以正常扩容. 而 gorw 方法要确保至少可以容纳 minCapacity 个元素. 又因为 newCapacity &gt; MAX_ARRAY_SIZE, 因此只能将列表扩容到 Integer.MAX_VALUE. 3.5 retainAll 和 removeall中 ,modCount 为什么加 size - w其他结构性修改操作中, modCount 的值都是 + 1, 为什么在 retainAll 和 removeAll 中加的却是 size - w? 因为 modCount 只是记录结构修改的次数 ,加 1 和加 size - w 区别不大? 如果有大佬知道原因还望告知.","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"}]},{"title":"Java中的栈","slug":"Java中栈的实现","date":"2021-03-06T01:38:43.000Z","updated":"2022-04-13T13:31:48.084Z","comments":true,"path":"2021/03/06/Java中栈的实现/","link":"","permalink":"https://tang7o.cn/2021/03/06/Java%E4%B8%AD%E6%A0%88%E7%9A%84%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"刷力扣时发现很少有人用Stack建栈,大部分都用双端队列接口Deque,出于对知识的渴望（就是菜）查阅了相关资料记录一下。 Stack类Java 中的 Stack 类从 Vector 类继承，底层是用数组实现的线程安全的栈。不过Java中用来表达栈的功能（push/pop/peek），更适用的是使用双端队列接口Deque，并用实现类ArrayDeque/LinkedList来进行初始化。 12Deque&lt;Object&gt; stack = new ArrayDeque&lt;&gt;();Deque&lt;Object&gt; stack = new ArrayList&lt;&gt;(); 使用Deque而不用Stack的原因 设计方面：Java中的类只能继承一个类，而可以实现多个接口，因此用双端队列 Deque 来建栈比使用 Stack 要灵活的多。 不一致性：Stack 类扩展了 Vector 类，该类允许你按索引访问元素，与Stack的操作不一致。 而Deque接口不允许使用索引访问元素，Deque 接口允许的操作与 FIFO 或 LIFO 数据结构允许的一致。 从性能来说：Stack 扩展的 Vector 类是线程安全的，其实多数情况下并不需要做到线程安全，因此没有必要使用Stack。毕竟保证线程安全需要上锁，有额外的系统开销。另外，使用不必要的功能扩展其他类会使对象膨胀，从而可能会花费大量额外的内存和性能开销。 迭代顺序：Stack 和 Deque 的迭代顺序完全相反。Deque 的迭代顺序更符合栈。 123456789101112Stack&lt;Integer&gt; stack = new Stack&lt;&gt;();stack.push(1);stack.push(2);stack.push(3);System.out.println(new ArrayList&lt;&gt;(stack)); // prints 1, 2, 3Deque&lt;Integer&gt; deque = new ArrayDeque&lt;&gt;();deque.push(1);deque.push(2);deque.push(3);System.out.println(new ArrayList&lt;&gt;(deque)); // prints 3, 2, 1 ArrayDeque 和 LinkedList 哪个更好？ArrayDeque：底层使用数组存储，容量不够时需要扩容和数组拷贝，通常容量不会填满，会有空间浪费； LinkedList：底层使用链表存储，每次push都需要new Node节点，并且node节点里面有prev和next成员，也会有额外的空间占用。 那么在用作栈时ArrayDeque 和 LinkedList 哪个更好？ 注意到 ArrayDeque 源码注释中有一句话：This class is likely to be faster than {@link Stack} when used as a stack,and faster than {@link LinkedList} when used as a queue. ArrayDeque用作栈时比Stack快没有疑问，用作队列的时候似乎也会比LinkedList快！ 经过测试后发现，ArrayDeque 确实比 LinkedList 要快一点，但是区别不大 总结ArrayDeque会略胜一筹，不过差别通常可以忽略，笔者更倾向于使用 ArrayDeque","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"}]},{"title":"Arrays.sort()","slug":"Arrays-sort","date":"2020-11-27T02:07:03.000Z","updated":"2022-04-13T13:31:47.906Z","comments":true,"path":"2020/11/27/Arrays-sort/","link":"","permalink":"https://tang7o.cn/2020/11/27/Arrays-sort/","excerpt":"","text":"基本用法Arrays.sort(int[] a)对数组 a 中所有元素按从小到大的顺序排序。 12345678public static void main(String[] args) &#123; int[] a = &#123;4, 6, 1, 8, 1, 3, 48, 3, 54&#125;; Arrays.sort(a); for (int c : a) &#123; System.out.print(c + &quot; &quot;); &#125; &#125;//输出: 1 1 3 3 4 6 8 48 54 Arrays.sort(int[] a,int fromIndex,int toIndex)对数组 a 中的下标从 formIndex 到 toIndex - 1 的元素按从小到大的顺序排序。 123456789public static void main(String[] args) &#123; int[] a = &#123;4, 6, 1, 8, 1, 3, 48, 3, 54&#125;; //对a[3] - a[6]排序 Arrays.sort(a,3,7); for (int c : a) &#123; System.out.print(c + &quot; &quot;); &#125; &#125;//输出：4 6 1 1 3 8 48 3 54 自定义排序Arrays.sort(int[] a,Comparator&lt;? Super T&gt; c) 用Comparator借口实现自定义排序。 123456789101112public static void main(String[] args) &#123; Integer[] a = &#123;4, 6, 1, 8, 1, 3, 48, 3, 54&#125;; Arrays.sort(a, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; //返回值&gt;0 交换 return o2 - o1; // 不建议上面的这种写法，这样写容易超出 Integer.MAX_VALUE ，下面的写法更好 return o2 &gt; o1 ? 1 : -1; &#125; &#125;); &#125; 和下面的写法等价 12345public static void main(String[] args) &#123; Integer[] a = &#123;4,6,1,8,1,3,48,3,54&#125;; //(Comparator&lt;Integer&gt;) 可省略 Arrays.sort(a, (Comparator&lt;Integer&gt;) (o1, o2) -&gt; o2 &gt; o1 ? 1 : -1;); &#125; Arrays.sort() 和 C++ 中的sort() 的区别Arrays.sort() 自定义排序时，返回值 &gt;0 交换二个元素的位置。C++ 中的 sort() 与之相反。","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"}]},{"title":"Meisell-Lehmer-筛选素数(模板)","slug":"Meisell-Lehmer-筛选素数","date":"2020-10-16T13:41:30.000Z","updated":"2022-04-13T13:31:48.177Z","comments":true,"path":"2020/10/16/Meisell-Lehmer-筛选素数/","link":"","permalink":"https://tang7o.cn/2020/10/16/Meisell-Lehmer-%E7%AD%9B%E9%80%89%E7%B4%A0%E6%95%B0/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899//Meisell-Lehmer#include&lt;cstdio&gt;#include&lt;cmath&gt;using namespace std;#define LL long longconst int N = 5e6 + 2;bool np[N];int prime[N], pi[N];int getprime()&#123; int cnt = 0; np[0] = np[1] = true; pi[0] = pi[1] = 0; for(int i = 2; i &lt; N; ++i) &#123; if(!np[i]) prime[++cnt] = i; pi[i] = cnt; for(int j = 1; j &lt;= cnt &amp;&amp; i * prime[j] &lt; N; ++j) &#123; np[i * prime[j]] = true; if(i % prime[j] == 0) break; &#125; &#125; return cnt;&#125;const int M = 7;const int PM = 2 * 3 * 5 * 7 * 11 * 13 * 17;int phi[PM + 1][M + 1], sz[M + 1];void init()&#123; getprime(); sz[0] = 1; for(int i = 0; i &lt;= PM; ++i) phi[i][0] = i; for(int i = 1; i &lt;= M; ++i) &#123; sz[i] = prime[i] * sz[i - 1]; for(int j = 1; j &lt;= PM; ++j) phi[j][i] = phi[j][i - 1] - phi[j / prime[i]][i - 1]; &#125;&#125;int sqrt2(LL x)&#123; LL r = (LL)sqrt(x - 0.1); while(r * r &lt;= x) ++r; return int(r - 1);&#125;int sqrt3(LL x)&#123; LL r = (LL)cbrt(x - 0.1); while(r * r * r &lt;= x) ++r; return int(r - 1);&#125;LL getphi(LL x, int s)&#123; if(s == 0) return x; if(s &lt;= M) return phi[x % sz[s]][s] + (x / sz[s]) * phi[sz[s]][s]; if(x &lt;= prime[s]*prime[s]) return pi[x] - s + 1; if(x &lt;= prime[s]*prime[s]*prime[s] &amp;&amp; x &lt; N) &#123; int s2x = pi[sqrt2(x)]; LL ans = pi[x] - (s2x + s - 2) * (s2x - s + 1) / 2; for(int i = s + 1; i &lt;= s2x; ++i) ans += pi[x / prime[i]]; return ans; &#125; return getphi(x, s - 1) - getphi(x / prime[s], s - 1);&#125;LL getpi(LL x)&#123; if(x &lt; N) return pi[x]; LL ans = getphi(x, pi[sqrt3(x)]) + pi[sqrt3(x)] - 1; for(int i = pi[sqrt3(x)] + 1, ed = pi[sqrt2(x)]; i &lt;= ed; ++i) ans -= getpi(x / prime[i]) - i + 1; return ans;&#125;LL lehmer_pi(LL x)&#123; if(x &lt; N) return pi[x]; int a = (int)lehmer_pi(sqrt2(sqrt2(x))); int b = (int)lehmer_pi(sqrt2(x)); int c = (int)lehmer_pi(sqrt3(x)); LL sum = getphi(x, a) +(LL)(b + a - 2) * (b - a + 1) / 2; for (int i = a + 1; i &lt;= b; i++) &#123; LL w = x / prime[i]; sum -= lehmer_pi(w); if (i &gt; c) continue; LL lim = lehmer_pi(sqrt2(w)); for (int j = i; j &lt;= lim; j++) sum -= lehmer_pi(w / prime[j]) - (j - 1); &#125; return sum;&#125;int main() &#123; init(); LL n; while(~scanf(&quot;%lld&quot;,&amp;n)) &#123; printf(&quot;%lld\\n&quot;,lehmer_pi(n)); &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"模板","slug":"ACM/模板","permalink":"https://tang7o.cn/categories/ACM/%E6%A8%A1%E6%9D%BF/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"模板","slug":"模板","permalink":"https://tang7o.cn/tags/%E6%A8%A1%E6%9D%BF/"}]},{"title":"@Slf4j","slug":"Slf4j","date":"2020-09-19T02:01:01.000Z","updated":"2022-04-13T13:31:48.381Z","comments":true,"path":"2020/09/19/Slf4j/","link":"","permalink":"https://tang7o.cn/2020/09/19/Slf4j/","excerpt":"","text":"@Slf4j 可以代替 private final Logger logger = LoggerFactory.getLogger(LoggerTest.class); 需要在pom中引用后才可以使用:12345&lt;!--可以引入日志 @Slf4j注解--&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; 如果使用@Slf4j注解后找不到变量log, 需要在编译器中安装lombok插件.","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://tang7o.cn/tags/SpringBoot/"}]},{"title":"SpringBootJPA之@Entity,@Table,@Id,@Column","slug":"SpringBootJPA之-Entity和-Table注解-1","date":"2020-09-18T11:43:49.000Z","updated":"2022-04-13T13:31:48.397Z","comments":true,"path":"2020/09/18/SpringBootJPA之-Entity和-Table注解-1/","link":"","permalink":"https://tang7o.cn/2020/09/18/SpringBootJPA%E4%B9%8B-Entity%E5%92%8C-Table%E6%B3%A8%E8%A7%A3-1/","excerpt":"","text":"@Entity: 表明该类为一个实体类 一般标注在类前. 参数: name: 表示其所对应的数据库中的表名 @Table: 声明此对象映射到数据库的数据表，通过它可以为实体指定表 一般标注在类前. 参数: 1.name: 用来命名当前实体类对应的数据库表的名字. 2.catalog: 指定table数据库中的路径，这里指数据库名 3.uniqueConstraints： 可以创建单个字段或者联合的唯一约束，只有在创建表成功时才执行 4.indexes：索引，可以指定联合索引，也是只有表生成成功才有效 @Id:注释指定表的主键 一般标注在属性前.也可以标注在属性的getter方法前. 参数: 1.TABLE：容器指定用底层的数据表确保唯一; 2.SEQUENCE：使用数据库德SEQUENCE列莱保证唯一(Oracle数据库通过序列来生成唯一ID); 3.IDENTITY：使用数据库的IDENTITY列莱保证唯一; 4.AUTO：由容器挑选一个合适的方式来保证唯一; 5.NONE：容器不负责主键的生成，由程序来完成. @Column: 用来标识实体类中属性与数据表中字段的对应关系 一般标注在属性前.也可以标注在属性的getter方法前. 参数: 1.name: 定义了被标注字段在数据库表中所对应字段的名称; 2.nullable: 表示该字段是否可以为null值，默认为true。 3.insertable: 表示在使用“INSERT”脚本插入数据时，是否需要插入该字段的值。 4.updatable: 表示在使用“UPDATE”脚本插入数据时，是否需要更新该字段的值。insertable和updatable属性一般多用于只读的属性，例如主键和外键等。这些字段的值通常是自动生成的。 5.columnDefinition（大多数情况，几乎不用）: 表示创建表时，该字段创建的SQL语句，一般用于通过Entity生成表定义时使用。（也就是说，如果DB中表已经建好，该属性没有必要使用。） 6.table: 表示当映射多个表时，指定表的表中的字段。默认值为主表的表名。 7.length: 表示字段的长度，当字段的类型为varchar时，该属性才有效，默认为255个字符。 8.precision和scale: 当字段类型为double时，precision表示数值的总长度，scale表示小数点所占的位数。 举个例子:12345678910111213141516171819202122232425262728293031323334@Entity @Table(name = &quot;user&quot;) //这二个注解有可以写成 @Entity(name = &quot;user&quot;), 因为类名与表名一致(不区分大小写),也可以省略public class User &#123; @Id @Column(name = &quot;id&quot;) //如果属性名与表中的列名一致可以不写此注解 int id; private String username; private String password; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://tang7o.cn/tags/SpringBoot/"}],"author":"Tang7O"},{"title":"求问1到n的因数个数的和","slug":"求问1到n的因数个数的和","date":"2020-05-16T05:48:01.000Z","updated":"2022-04-13T13:31:49.138Z","comments":true,"path":"2020/05/16/求问1到n的因数个数的和/","link":"","permalink":"https://tang7o.cn/2020/05/16/%E6%B1%82%E9%97%AE1%E5%88%B0n%E7%9A%84%E5%9B%A0%E6%95%B0%E4%B8%AA%E6%95%B0%E7%9A%84%E5%92%8C/","excerpt":"","text":"题目连接 123456789101112int main()&#123; ll n; cin &gt;&gt; n; ll ans = 0; for (ll l = 1, r = 0; l &lt;= n; l = r + 1) &#123; r = n / (n / l); ans += 1ll * (r - l + 1) * (n / l); &#125; cout&lt;&lt;ans&lt;&lt;endl; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"模板","slug":"ACM/模板","permalink":"https://tang7o.cn/categories/ACM/%E6%A8%A1%E6%9D%BF/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Win10下 Java环境变量配置","slug":"win10下-java环境变量配置","date":"2020-04-13T13:08:02.000Z","updated":"2022-04-13T13:31:48.737Z","comments":true,"path":"2020/04/13/win10下-java环境变量配置/","link":"","permalink":"https://tang7o.cn/2020/04/13/win10%E4%B8%8B-java%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/","excerpt":"","text":"本文转载于：https://www.cnblogs.com/cnwutianhao/p/5487758.html Win10下 Java环境变量配置 首先，你应该已经安装了 Java 的 JDK 了（如果没有安装JDK，请跳转到此网址：http://www.oracle.com/technetwork/java/javase/downloads/index-jsp-138363.html） 接下来主要讲怎么配置 Java 的环境变量，也是为了以后哪天自己忘记了做个备份 （注：win10的Java环境变量配置和其他的windows版本稍有不同） 在电脑桌面 右键点击 “此电脑”的“属性”选项 选择“高级系统设置”选项 点击下面的“环境变量”选项 接下来就是具体的配置过程： 点击“系统变量”下面的”新建“选项 在”变量名“处填上”Java_Home“ ”变量值“为JDK安装路径，笔者的路径是”D:\\Program Files\\Java\\jdk1.8.0_91“ 点击”确定“选项 在”系统变量“中找到”Path“ 选中”Path“点击”编辑“选项 选择右边的“编辑文本”，将引号里面的全部复制“%Java_Home%\\bin;%Java_Home%\\jre\\bin;”，到“变量值”栏的最前面，“确定” 在“系统变量”栏，“新建”，“变量名”为“CLASSPATH”，“变量值”为“.;%Java_Home%\\bin;%Java_Home%\\lib\\dt.jar;%Java_Home%\\lib\\tools.jar”，“确定” 点击“环境变量”最下面的“确定”选项 回到电脑桌面，按快捷键“Win+R”，输入“cmd” 检查Java环境是否配置成功 输入”java” 输入”javac” 输入”java -version” 如果上面的三幅图都看见了，恭喜，环境变量配置好了！","categories":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"环境配置","slug":"环境配置","permalink":"https://tang7o.cn/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"求一个数所有的因子个数和因子和","slug":"求一个数所有的因子个数和因子和","date":"2020-04-10T10:25:56.000Z","updated":"2022-04-13T13:31:49.112Z","comments":true,"path":"2020/04/10/求一个数所有的因子个数和因子和/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E6%B1%82%E4%B8%80%E4%B8%AA%E6%95%B0%E6%89%80%E6%9C%89%E7%9A%84%E5%9B%A0%E5%AD%90%E4%B8%AA%E6%95%B0%E5%92%8C%E5%9B%A0%E5%AD%90%E5%92%8C/","excerpt":"","text":"B站学习视频（图片来源） 1.所有因子个数如果一个数是因数，就不断除这个数，保存这个因子次方的数 temp++；运用所有因子个数计算公式（见上图），保存因子个数的 ans不断乘（ temp+1 ）。注意 :当最后，在 x 不断除因数得到的值有两种情况： x == 1，这说明 x 没有其他因子了。 x != 1, 这时 x 为其一个素数因子（且这个因子大于 根号x ）,所以最后再乘（1+1）。代码学习链接 12345678910111213141516ll dcpCount(ll x)&#123;//所有因子的个数（包括1） ll ans = 1; for(ll i = 2; i * i &lt;= x; i++)&#123; if(x % i == 0)&#123; ll temp = 0; while(x % i == 0)&#123; x /= i; temp++; &#125; ans *= (temp+1);//运用上面的公式，计算所有因子的个数 &#125; &#125; if(x &gt; 1) ans *= 2; return ans;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"求三角形外心坐标","slug":"求三角形外心坐标","date":"2020-04-10T10:24:58.000Z","updated":"2022-04-13T13:31:49.125Z","comments":true,"path":"2020/04/10/求三角形外心坐标/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E6%B1%82%E4%B8%89%E8%A7%92%E5%BD%A2%E5%A4%96%E5%BF%83%E5%9D%90%E6%A0%87/","excerpt":"","text":"转载于:原文链接 给定三角形三个顶点的坐标，如何求三角形的外心的坐标呢？ 例如 ：给定a（x1,y1） b（x2,y2） c（x3,y3）求外接圆心坐标O（x，y） 首先，外接圆的圆心是三角形三条边的垂直平分线的交点，我们根据圆心到顶点的距离相等，可以列出以下方程： $(x1-x)(x1-x)-(y1-y)(y1-y)=(x2-x)(x2-x)+(y2-y)(y2-y)$ $(x2-x)(x2-x)+(y2-y)(y2-y)=(x3-x)(x3-x)+(y3-y)(y3-y)$ 2.化简得到： ​ $2(x2-x1)x+2*(y2-y1)y=x2^2+y2^2-x1^2-y1^2$ ​ $2(x3-x2)x+2*(y3-y2)y=x3^2+y3^2-x2^2-y2^2$ ​ 令$A1=2*(x2-x1)；$ $ B1=2*(y2-y1)$ $C1=x2^2+y2^2-x1^2-y1^2$ $A2=2*(x3-x2)$ $B2=2*(y3-y2)$ $C2=x3^2+y3^2-x2^2-y2^2$ ​ 即 $A1*x+B1y=C1$ $ A2*x+B2y=C2$ 3.最后根据克拉默法则： $x=((C1B2)-(C2B1))/((A1B2)-(A2B1))$ $y=((A1C2)-(A2C1))/((A1B2)-(A2B1))$ 因此，x，y为最终结果； 对于空间中的三角形，只不过最后解方程组的时候是三元方程组 1234567891011121314151617int main()&#123; double x1, x2, x3, y1, y2, y3; cin&gt;&gt;x1&gt;&gt;y1&gt;&gt;x2&gt;&gt;y2&gt;&gt;x3&gt;&gt;y3; double A1 = 2 * (x2 - x1), B1 = 2 * (y2 - y1), C1 = x2 * x2 - x1 * x1 - y1 * y1 + y2 *y2, A2 = 2 * (x3 - x2), B2 = 2 * (y3 - y2), C2 = x3 * x3 - x2 * x2 - y2 * y2 + y3 * y3; double x,y; x=((C1*B2)-(C2*B1))/((A1*B2)-(A2*B1)); y=((A1*C2)-(A2*C1))/((A1*B2)-(A2*B1)); printf(&quot;%.3lf %.3lf\\n&quot;,x,y); return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"模板","slug":"ACM/模板","permalink":"https://tang7o.cn/categories/ACM/%E6%A8%A1%E6%9D%BF/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"distinct-subsequences 求S有多少个不同的子串与T相同","slug":"distinct-subsequences-求s有多少个不同的子串与t相同","date":"2020-04-10T10:24:16.000Z","updated":"2022-04-13T13:31:48.487Z","comments":true,"path":"2020/04/10/distinct-subsequences-求s有多少个不同的子串与t相同/","link":"","permalink":"https://tang7o.cn/2020/04/10/distinct-subsequences-%E6%B1%82s%E6%9C%89%E5%A4%9A%E5%B0%91%E4%B8%AA%E4%B8%8D%E5%90%8C%E7%9A%84%E5%AD%90%E4%B8%B2%E4%B8%8Et%E7%9B%B8%E5%90%8C/","excerpt":"","text":"转载: 原文 Given a string S and a string T, count the number of distinct subsequences ofT inS. A subsequence of a string is a new string which is formed from the original string by deleting some (can be none) of the characters without disturbing the relative positions of the remaining characters. (ie,&quot;ACE&quot; is a subsequence of&quot;ABCDE&quot; while &quot;AEC&quot; is not). Here is an example:S = &quot;rabbbit&quot;, T = &quot;rabbit&quot; Return 3. 简单翻译一下，给定两个字符串S和T，求S有多少个不同的子串与T相同。S的子串定义为在S中任意去掉0个或者多个字符形成的串。 递归求解： 首先找到在S中与T的第一个字符相同的字符，从这个字符开始，递归地求S和T剩下的串。T为空串时，返回1。因为空串本身是另外一个串的一个子序列。这个算法实现简单，但是果然不出意料，大集合超时。 1234567891011121314151617public int numDistinct(String S, String T) &#123; // Start typing your Java solution below // DO NOT write main() function if (S.length() == 0) &#123; return T.length() == 0 ? 1 : 0; &#125; if (T.length() == 0) &#123; return 1; &#125; int cnt = 0; for (int i = 0; i &lt; S.length(); i++) &#123; if (S.charAt(i) == T.charAt(0)) &#123; cnt += numDistinct(S.substring(i + 1), T.substring(1)); &#125; &#125; return cnt; &#125; 遇到这种两个串的问题，很容易想到DP。但是这道题的递推关系不明显。可以先尝试做一个二维的表int[][] dp，用来记录匹配子序列的个数（以S =&quot;rabbbit&quot;,T = &quot;rabbit&quot;为例）： r a b b b i t 1 1 1 1 1 1 1 1 r 0 1 1 1 1 1 1 1 a 0 0 1 1 1 1 1 1 b 0 0 0 1 2 3 3 3 b 0 0 0 0 1 3 3 3 i 0 0 0 0 0 0 3 3 t 0 0 0 0 0 0 0 3 从这个表可以看出，无论T的字符与S的字符是否匹配，dp[i][j] = dp[i][j - 1].就是说，假设S已经匹配了j - 1个字符，得到匹配个数为dp[i][j - 1]（即若S[j]!=T[i]，则该出现次数等于T[0-i]在S[0-(j-1)]出现的次数）.现在无论S[j]是不是和T[i]匹配，匹配的个数至少是dp[i][j - 1]。除此之外，当S[j]和T[i]相等时，我们可以让S[j]和T[i]匹配，然后让S[j - 1]和T[i - 1]去匹配（T[0-(i-1)]在S[0-(j-1)]出现的次数*(T[i]==S[j])=1)所以递推关系为： dp[0][0] = 1; // T和S都是空串. dp[0][1 … S.length() - 1] = 1; // T是空串，S只有一种子序列匹配。 dp[1 … T.length() - 1][0] = 0; // S是空串，T不是空串，S没有子序列匹配。 dp[i][j] = dp[i][j - 1] + (T[i - 1] == S[j - 1] ? dp[i - 1][j - 1] : 0).1 &lt;= i &lt;= T.length(), 1 &lt;= j &lt;= S.length() 1234567891011121314151617181920212223class Solution &#123;public: int numDistinct(string S, string T) &#123; if(S.empty()T.empty()) return 0; if(S.length()&lt;T.length()) return 0; int dp[T.length()+1][S.length()+1]; dp[0][0]=1; for(int i=1;i&lt;=T.length();i++)&#123; dp[i][0]=0; &#125; for(int j=1;j&lt;=S.length();j++)&#123; dp[0][j]=1; &#125; for(int i=1;i&lt;=T.length();i++)&#123; for(int j=1;j&lt;=S.length();j++)&#123; dp[i][j]=dp[i][j-1]; if(T[i-1]==S[j-1]) dp[i][j]+=dp[i-1][j-1]; &#125; &#125; return dp[T.length()][S.length()]; &#125;&#125;;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"题目","slug":"ACM/题目","permalink":"https://tang7o.cn/categories/ACM/%E9%A2%98%E7%9B%AE/"}],"tags":[{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"}]},{"title":"判断四个点是否可以组成一个正方形","slug":"判断四个点是否可以组成一个正方形","date":"2020-04-10T10:20:38.000Z","updated":"2022-04-13T13:31:48.851Z","comments":true,"path":"2020/04/10/判断四个点是否可以组成一个正方形/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E5%88%A4%E6%96%AD%E5%9B%9B%E4%B8%AA%E7%82%B9%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E7%BB%84%E6%88%90%E4%B8%80%E4%B8%AA%E6%AD%A3%E6%96%B9%E5%BD%A2/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233double Distance(int x1,int y1,int x2,int y2)&#123;//求边长 return sqrt(pow((x1-x2),2)+pow((y1-y2),2));&#125;bool IsRightAngle(int x1,int y1,int x2,int y2,int x3,int y3)&#123;//判断是否为直角 if((x2-x1)*(x3-x1)+(y2-y1)*(y3-y1)==0) return true; return false;&#125;bool IsSquare(int x1,int y1,int x2,int y2,int x3,int y3,int x4,int y4)&#123;//判断是否为正方形 if(x1==x2&amp;&amp;x2==x3) return false; double s12=Distance(x1,y1,x2,y2); double s13=Distance(x1,y1,x3,y3); double s14=Distance(x1,y1,x4,y4); double s23=Distance(x2,y2,x3,y3); double s24=Distance(x2,y2,x4,y4); double s34=Distance(x3,y3,x4,y4); if(s12==s13&amp;&amp;s24==s34&amp;&amp;s12==s24)&#123; if(IsRightAngle(x1,y1,x2,y2,x3,y3)) return true; else return false; &#125; if(s12==s14&amp;&amp;s23==s34&amp;&amp;s12==s23)&#123; if(IsRightAngle(x1,y1,x2,y2,x4,y4)) return true; else return false; &#125; if(s13==s14&amp;&amp;s23==s24&amp;&amp;s13==s23)&#123; if(IsRightAngle(x1,y1,x3,y3,x4,y4)) return true; else return false; &#125; return false;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"模板","slug":"ACM/模板","permalink":"https://tang7o.cn/categories/ACM/%E6%A8%A1%E6%9D%BF/"}],"tags":[{"name":"模板","slug":"模板","permalink":"https://tang7o.cn/tags/%E6%A8%A1%E6%9D%BF/"}]},{"title":"区间DP","slug":"区间dp","date":"2020-04-10T10:19:52.000Z","updated":"2022-04-13T13:31:48.866Z","comments":true,"path":"2020/04/10/区间dp/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E5%8C%BA%E9%97%B4dp/","excerpt":"","text":"区间dp就是在区间上进行动态规划，求解一段区间上的最优解。主要是通过合并小区间的 最优解进而得出整个大区间上最优解的dp算法。 核心思路：既然要求解在一个区间上的最优解，那么把这个区间分割成一个个小区间，求解每个小区间的最优解，再合并小区间得到大区间即可。所以在代码实现上，我可以枚举区间长度len为每次分割成的小区间长度（由短到长不断合并），内层枚举该长度下可以的起点，自然终点也就明了了。然后在这个起点终点之间枚举分割点，求解这段小区间在某个分割点下的最优解。 核心代码：12345678for(int len = 2;len&lt;=n;len++)&#123;//枚举长度 for(int j = 1;j+len&lt;=n+1;j++)&#123;//枚举起点，ends&lt;=n int ends = j+len - 1; for(int i = j;i&lt;ends;i++)&#123;//枚举分割点，更新小区间最优解 dp[j][ends] = min(dp[j][ends],dp[j][i]+dp[i+1][ends]+something); &#125; &#125; &#125; 例题poj 1651 —Multiplication Puzzle AC代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/*Time ：2019-10-16Author ：Tang7OE-mail：1747822506@qq.com*/#include #include #include #include #include #include #include #include #include #include #include #include using namespace std;#define mem(a, b) memset(a, b, sizeof(a))#define PI acos(-1)#define debug(a) cout &lt;&lt; (a) &lt;&lt; endltypedef long long ll;int dir8[8][2] = &#123; &#123; 1, 0 &#125;, &#123; 0, 1 &#125;, &#123; -1, 0 &#125;, &#123; 0, -1 &#125;, &#123; 1, 1 &#125;, &#123; 1, -1 &#125;, &#123; -1, 1 &#125;, &#123; -1, -1 &#125; &#125;;int dir4[4][2] = &#123; 1, 0, 0, 1, -1, 0, 0, -1 &#125;;const int INF = 0x3f3f3f3fLL;const long long LLF = 0x3f3f3f3f3f3f3f3fLL;const int MAXn = 1e5 + 15;const int mod = 1e9 + 7;//priority_queue, vector&gt;, greater&gt;&gt; q;int num[105];int n;int dp[105][105];int main()&#123; cin&gt;&gt;n; for(int i=1;i&lt;=n;i++) cin&gt;&gt;num[i]; for(int len=2;len&lt;n;len++)&#123; for(int i=2;i+len&lt;=n+1;i++)&#123; int j=i+len-1; dp[i][j]=INF; for(int k=i;k&lt;j;k++)&#123; dp[i][j]=min(dp[i][j],dp[i][k]+dp[k+1][j]+num[i-1]*num[k]*num[j]); &#125; &#125; &#125; cout&lt;&lt;dp[2][n]&lt;&lt;endl; return 0; &#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"扫描线","slug":"扫描线","date":"2020-04-10T10:18:39.000Z","updated":"2022-04-13T13:31:48.968Z","comments":true,"path":"2020/04/10/扫描线/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E6%89%AB%E6%8F%8F%E7%BA%BF/","excerpt":"","text":"题意:二维平面有n个平行于坐标轴的矩形,现在要求出这些矩形的总面积. 重叠部分只能算一次. 分析: 线段树的典型扫描线用法. 首先假设有下图两个矩阵,我们如果用扫描线的方法如何计算它们的总面积呢?首先我们将矩形的上下边分为上位边(即y坐标大的那条平行于x轴的边),和下位边(y坐标小的平行于x轴的边).然后我们把所有矩形的上下位边按照他们y坐标从小到大排序,可以得到4条扫描线:又因为上面2个矩形有4个不同的浮点数x坐标,所以我们需要把x坐标离散化,这样才能用线段树来维护信息.所以我们这样离散化:由上图可知,4个不同的x坐标把x轴分成了3段有效的区间.这里要注意我们线段树中每个叶节点(控制区间[L,L])不是指X[L]坐标,而是指区间[X[L],X[L+1]].线段树中其他节点控制的区间[L,R],也是指的x坐标轴的第L个区间到第R个区间的范围,也就是X[L]到X[R+1]坐标的范围. 然后我们Y坐标从小到大的顺序读入每条扫描线,并维护当前我们所读入的所有扫描线能有效覆盖X轴的最大长度sum[1].这里特别要注意如果我们读入的扫描线是矩形的下位边,那么我们就使得该范围的标记cnt位+1,如果是上位边,那么该范围的cnt就-1.所以如果cnt=0时,表示该节点控制的范围没有被覆盖,只要cnt!=0 就表示该节点控制的几块区间仍然被覆盖. 下面依次读入每条矩阵边,来一一分析,首先是读入第一条矩阵边:我们读入了矩形1的下位边,那么该区域的cnt就+1=1了,所以该区域[10,20]就被覆盖了,然后可以推出整个区域被覆盖的长度是10.再根据第二条扫描线离第一条扫描线的高度差为5.所以不管你第二条扫描线是哪个矩形的什么边,或者能覆盖到X轴的什么范围,我上图中蓝色的矩形面积肯定是要算到总面积里面去的.即总面积ret+=sum[1]*(扫描线2的高度-扫描线1的高度). (想想看是不是这样). 下面读第二条扫描线:由于第二条扫描线也是下位边,所以[15,20]和[20,25]的cnt+1.使得我们覆盖的范围变成了[10,25]了,并且第3条扫描线在20高度,所以这次我们必然增加的面积是上面深蓝色的长条=sum[1]*(扫描线3的高度-扫描线2的高度). 下面我们要读第三条扫描线了:由于第三条扫描线是区间[10,20]的上位边,所以对应区间的cnt要-1,所以使得区间[10,15]的cnt=0了,而[15,20]区间的cnt-1之后变成了1.[20,25]的cnt仍然为1,不变.所以当前覆盖的有效x轴长度为10,即区间[15,25].所以增加的面积是图中褐色的部分. 到此,矩形的面积和就算出来了.由于对于任一矩形都是先读下位边(cnt+1),再读上位边(cnt-1)的,所以在更新线段树的过程中,任意节点的cnt都是&gt;=0的. 例题poj 1151 Atlantis 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#include #include #include #include #include #include #include #include #include #include #include #include using namespace std;#define mem(a, b) memset(a, b, sizeof(a))#define PI acos(-1)#define debug(a) cout &lt;&lt; (a) &lt;&lt; endltypedef long long ll;int dir8[8][2] = &#123; &#123; 1, 0 &#125;, &#123; 0, 1 &#125;, &#123; -1, 0 &#125;, &#123; 0, -1 &#125;, &#123; 1, 1 &#125;, &#123; 1, -1 &#125;, &#123; -1, 1 &#125;, &#123; -1, -1 &#125; &#125;;int dir4[4][2] = &#123; 1, 0, 0, 1, -1, 0, 0, -1 &#125;;const int INF = 0x3f3f3f3fLL;const long long LLF = 0x3f3f3f3f3f3f3f3fLL;const int MAXn = 2e2 + 15;const int mod = 1e9 + 7;//priority_queue, vector&gt;, greater&gt;&gt; q;struct node &#123; double l, r, h; int d;&#125; line[MAXn];int mark[MAXn&lt;&lt;2];double sum[MAXn&lt;&lt;3];double x_i[MAXn];bool cmp_line(node a, node b)&#123; return a.h &lt; b.h;&#125;void init()&#123; mem(mark, 0); mem(sum, 0);&#125;void pushup(int i, int l, int r)&#123; if (mark[i]) sum[i] = x_i[r + 1 ] - x_i[l]; else sum[i] = sum[i &lt;&lt; 1] + sum[i &lt;&lt; 1 1];&#125;void update(int l, int r, int v, int i, int L, int R)&#123; if (l &lt;= L &amp;&amp; r &gt;= R) &#123; mark[i] += v; pushup(i, L, R); return; &#125; int mid = (L + R) &gt;&gt; 1; if (l &lt;= mid) update(l, r, v, i &lt;&lt; 1, L, mid); if (r &gt; mid) update(l, r, v, i &lt;&lt; 1 1, mid + 1, R); pushup(i, L, R);&#125;int main()&#123; int n, m, q, kase = 0; double x1, x2, y1, y2; while (cin &gt;&gt; q &amp;&amp; q) &#123; init(); n = m = 0; for (int i = 0; i &lt; q; i++) &#123; cin &gt;&gt; x1 &gt;&gt; y1 &gt;&gt; x2 &gt;&gt; y2; x_i[++n] = x1; x_i[++n] = x2; line[++m] = node&#123; x1, x2, y1, 1 &#125;; line[++m] = node&#123; x1, x2, y2, -1 &#125;; &#125; sort(x_i + 1, x_i + 1 + n); sort(line + 1, line + 1 + m, cmp_line); int k = unique(x_i + 1, x_i + 1 + n) - x_i - 1; double ans = 0; for (int i = 1; i &lt; m; i++) &#123; int l = lower_bound(x_i + 1, x_i + 1 + k, line[i].l) - x_i; int r = lower_bound(x_i + 1, x_i + 1 + k, line[i].r) - x_i-1; if (l &lt;= r) update(l, r, line[i].d, 1, 1, k - 1); ans += sum[1] * (line[i + 1].h - line[i].h); //cout&lt; &#125; printf(&quot;Test case #%d\\nTotal explored area: %.2f\\n\\n&quot;, ++kase, ans); &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"线段树","slug":"线段树","date":"2020-04-10T10:17:28.000Z","updated":"2022-04-13T13:31:49.166Z","comments":true,"path":"2020/04/10/线段树/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E7%BA%BF%E6%AE%B5%E6%A0%91/","excerpt":"","text":"线段树将区间分为若干个子区间，子区间又继续分，直到区间为一个点（l==r） 对于父区间 [l,r] ,其子区间为 [l,(l+r)/2] 和 [(l+r)/2+1,r] 线段树一般用于求区间的值，如区间最值，区间求和等。 代码实现中， 假设节点下标从1开始，若某节点下标为x，那么其左子区间下标为2x，右子区间下标为2x+1,父节点下标为x/2； 常用宏定义 123#define Mid ((l+r)&gt;&gt;1) //中间值 注意括号#define lson rt&lt;&lt;1,l,Mid //左结点#define rson rt&lt;&lt;11,Mid+1,r //右结点 建树建树从根节点开始，递归建立左右子树，直到叶子节点，然后反向赋值，父节点的值=F（左节点的值，右节点的值），这个F根据题意确定，若求区间最大值则为max，若求区间和则为sum。 12345678910void build(int rt,int l,int r) //建编号为rt的区间为[l,r]的树，主函数传进来的固定是(1,1,n)&#123; if(l==r)&#123; //叶子结点赋初值，注意下标，Max的是编号，val原数组的是l，看图可以理解 Max[rt] = val[l]; &#125;else&#123; //建左右子树 build(lson); build(rson); Max[rt] = max( Max[rt&lt;&lt;1], Max[rt&lt;&lt;11]); //父结点Max值为Max(左子结点，右子结点） &#125;&#125; 查询查询为区间查询（只是查询某个点的话不需要线段树），即在区间里查询某个特性值，每次查询都是从跟结点开始往下，根据查询区间和当前区间的区间位置判断是要去左右子区间查询，还是直接返回。如果被查询区间是查询区间的子区间则直接返回子区间的值，如在[1,6]里查询[1,12]就返回[1,6]的值，不再往下查询。 123456789101112void query(int rt,int l,int r,int L,int R) //在[l,r]里查询[L,R]的值，[L,R]一直不变，[l,r]变&#123; if(L &lt;= l &amp;&amp; r &lt;= R)&#123; ans1 = max(ans1,Max[rt]); ans2 = min(ans2,Min[rt]); &#125;else&#123; if( L &lt;= Mid) //查询区间在当前区间的左半区间有内容，如在[1,6]里查询[2,3] query(lson,L,R); if( R &gt; Mid) //同理去右子区间，注意不能有else，因为有横跨左右的情况，如[1,6]里查询[2,5] query(rson,L,R); &#125;&#125; 单点更新123456789101112void update(int rt,int l,int r,int pos,int num)&#123; if(l == r &amp;&amp; r == pos)&#123; //到对应的叶结点 Max[rt] = num; &#125;else&#123; if( pos &lt;= Mid) update(lson,pos,num); if( pos &gt; Mid) //或者直接else，点不可能同时在两个区间里 update(rson,pos,num); Max[rt] = max( Max[rt&lt;&lt;1], Max[rt&lt;&lt;11]); &#125;&#125; 区间更新12345678910111213141516171819202122232425void pushDown(int rt,int len)&#123; add[rt&lt;&lt;1] = add[rt&lt;&lt;11] = add[rt]; sum[rt&lt;&lt;1] = (len-(len&gt;&gt;1))*add[rt]; sum[rt&lt;&lt;11] = (len&gt;&gt;1)*add[rt]; add[rt] = 0;&#125; void update(int rt,int l,int r,int L,int R,int z)&#123; if(L &lt;= l &amp;&amp; r &lt;= R)&#123; add[rt] = z;//或 add[rt]+=z; 根据题意而定 sum[rt] = (r-l+1)*add[rt]; &#125;else&#123; if(add[rt]) pushDown(rt,r-l+1); if(L &lt;= Mid) update(lson,L,R,z); if(R &gt; Mid) update(rson,L,R,z); sum[rt] = sum[rt&lt;&lt;1] + sum[rt&lt;&lt;11]; &#125;&#125; 例题HDU 1166 敌兵布阵 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;#include &lt;map&gt;using namespace std;#define mem(a, b) memset(a, b, sizeof(a))#define PI acos(-1)typedef long long ll;int dir8[8][2] = &#123;&#123;1, 0&#125;, &#123;0, 1&#125;, &#123;-1, 0&#125;, &#123;0, -1&#125;, &#123;1, 1&#125;, &#123;1, -1&#125;, &#123;-1, 1&#125;, &#123;-1, -1&#125;&#125;;int dir4[4][2] = &#123;1, 0, 0, 1, -1, 0, 0, -1&#125;;const int INF = 0x3f3f3f3fll;const long long intF = 0x3f3f3f3f3f3f3f3fll;const int MAXn = 1e5 + 5;const int mod = 1e9 + 7;struct node&#123; int l, r, w, flag; int mid() &#123; return (r + l) / 2; &#125; int dis() &#123; return r - l + 1; &#125;&#125; a[MAXn * 4];void build(int k, int l, int r)&#123; a[k].l=l; a[k].r=r; a[k].w=0; a[k].flag=0; if (l == r) &#123; cin &gt;&gt; a[k].w; return; &#125; build(k &lt;&lt; 1, l ,a[k].mid()); build(k&lt;&lt;11, a[k].mid()+1, r ); a[k].w=a[k&lt;&lt;1].w+a[k&lt;&lt;11].w;&#125;void down(int k)&#123; a[k &lt;&lt; 1].w += a[k].flag * a[k &lt;&lt; 1].dis(); a[k &lt;&lt; 1 1].w += a[k].flag * a[k &lt;&lt; 1 1].dis(); a[k &lt;&lt; 1].flag += a[k].flag; a[k &lt;&lt; 1 1].flag += a[k].flag; a[k].flag = 0;&#125;void update(int k, int l, int r, int w)&#123; if(a[k].l==l&amp;&amp;a[k].r==a[k].l) &#123; a[k].w+=a[k].dis()*w; a[k].flag+=w; return ; &#125; if(a[k].flag) down(k); if(a[k].mid()&gt;=l) update(k&lt;&lt;1,l,r,w); if(a[k].mid()&lt;r) update(k&lt;&lt;11,l,r,w); a[k].w=a[k&lt;&lt;1].w+a[k&lt;&lt;11].w;&#125;int query(int k, int l, int r)&#123; if (a[k].l &gt;= l &amp;&amp; a[k].r &lt;= r) return a[k].w; if (a[k].flag) down(k); int sum = 0; if (a[k].mid() &gt;= l) sum += query(k &lt;&lt; 1, l, r); if (a[k].mid() &lt; r) sum += query(k &lt;&lt; 1 1, l, r); a[k].w = a[k &lt;&lt; 1].w + a[k &lt;&lt; 1 1].w; return sum;&#125;int main()&#123; //IN; ios::sync_with_stdio(false); cin.tie(0); cout.tie(0); int T,ii=0; cin &gt;&gt; T; while (T--) &#123; ii++; cout&lt;&lt;&quot;Case &quot;&lt;&lt;ii&lt;&lt;&quot;:&quot;&lt;&lt;endl; int n; cin&gt;&gt;n; build(1,1,n); while(1) &#123; string s; int i,j; cin&gt;&gt;s; if(s==&quot;End&quot;) break; cin&gt;&gt;i&gt;&gt;j; if(s==&quot;Sub&quot;) j=-j; if(s==&quot;Query&quot;)&#123; cout&lt;&lt;query(1,i,j)&lt;&lt;endl; continue; &#125; update(1,i,i,j); &#125; &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"扩展KMP","slug":"扩展kmp","date":"2020-04-10T10:13:42.000Z","updated":"2022-04-13T13:31:48.954Z","comments":true,"path":"2020/04/10/扩展kmp/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E6%89%A9%E5%B1%95kmp/","excerpt":"","text":"1、扩展KMP是什么？解决何种问题？与KMP算法的异同？ 拓展kmp是对KMP算法的扩展，它解决如下问题： 定义母串S，和字串T，设S的长度为n，T的长度为m，求T与S的每一个后缀的最长公共前缀，也就是说，设extend数组,extend[i]表示T与S[i,n-1]的最长公共前缀，要求出所有extend[i](0&lt;=i&lt;n)。 注意到，如果有一个位置extend[i]=m,则表示T在S中出现，而且是在位置i出现，这就是标准的KMP问题，所以说拓展kmp是对KMP算法的扩展，所以一般将它称为扩展KMP算法。 图例：-S=”aaaabaa”，T=”aaaaa”,首先，计算extend[0]时，需要进行5次匹配，直到发生失配。从而得知extend[0]=4。 下面计算extend[1]，在计算extend[1]时，是否还需要像计算extend[0]时从头开始匹配呢？答案是否定的，因为通过计算extend[0]=4，从而可以得出S[0,3]=T[0,3]，进一步可以得到 S[1,3]=T[1,3],计算extend[1]时，事实上是从S[1]开始匹配。 2、拓展kmp算法一般步骤 **1、**首先我们从左到右依次计算extend数组，在某一时刻，设extend[0...k]已经计算完毕，并且之前匹配过程中所达到的最远位置为P，所谓最远位置，严格来说就是i+extend[i]-1的最大值（0&lt;=i&lt;=k）,并且设取这个最大值的位置为po，如在上一个例子中,计算extend[1]时，P=3，po=0。 **2、**现在要计算extend[k+1],【注意啦！这里我们推的是k+1的公式，而在代码中是写的k的公式，会差一个1，不要搞错咯！】根据extend数组的定义，可以推断出S[po,P]=T[0,P-po],从而得到 S[k+1,P]=T[k-po+1,P-po],令len=next[k-po+1]，(这里len也就是可以从头开始匹配上的字符长度)，分两种情况讨论： 2.1 第一种情况：k+len &lt; P 2.1.1也就是说从T字符串的k - po + 1位置推断出的从T的0开头可以匹配的长度len并没有超过现有P的大小，而po - p之间的字符是可以被匹配的这一事实我们已经检验过，所以可以确保从k+1 ~ k + len的字符，确实可以从T头开始匹配len的长度 **2.1.2 ** 2.1.3上图中，S[k+1,k+len]=T[0,len-1]，然后S[k+len+1]一定不等于T[len]，因为如果它们相等，则有S[k+1,k+len+1]=T[k+po+1,k+po+len+1]=T[0,len],那么next[k+po+1]=len+1，这和next数组的定义不符(next[i]表示T[i,m-1]和T的最长公共前缀长度)，所以在这种情况下，不用进行任何匹配，就知道extend[k+1]=len。 **2.2 ** 第二种情况：k+len&gt;=P 2.2.1也就是说从T字符串的k - po + 1位置推断出的从T的0开头可以匹配的长度len已经超过了现有P的大小，而po - p之间的字符是可以被匹配的这一事实我们已经检验过，但超过p的部分我们并没有匹配过，所以不能确保从k +1~ k + len的字符是否可以从T头开始匹配len的长度，只能说至少可以确定k+1 ~ p是匹配的，而p + 1 ~ k + len的部分还需要进一步比对 。 **2.2.2 ** 2.2.3上图中，S[p+1]之后的字符都是未知的，也就是还未进行过匹配的字符串，所以在这种情况下，就要从S[P+1]和T[P-k+1]开始一一匹配，直到发生失配为止，当匹配完成后，如果得到的extend[k+1]+(k+1)大于P则要更新未知P和po。(得到的extend[k+1]+(k+1)至少都是p,要么就比p还大，所以在更新完extend之后，直接让p= extend即可）。 **3、**至此，拓展kmp算法的过程已经描述完成，事实上，计算next数组的过程和计算extend[i]的过程完全一样，将它看成是以T为母串，T为字串的特殊的拓展kmp算法匹配就可以了，计算过程中的next数组全是已经计算过的，所以按照上述介绍的算法计算next数组即可。 3、时间复杂度分析通过上面的算法介绍可以知道，对于第一种情况，无需做任何匹配即可计算出extend[i]，对于第二种情况，都是从未被匹配的位置开始匹配，匹配过的位置不再匹配，也就是说对于母串的每一个位置，都只匹配了一次，所以算法总体时间复杂度是O(n)的，同时为了计算辅助数组next[i]需要先对字串T进行一次拓展kmp算法处理，所以拓展kmp算法的总体复杂度为O(n+m)的。其中n为母串的长度，m为子串的长度。 4、核心代码模板1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950const int maxn = 100010; //字符串长度最大值int next[maxn], ex[maxn]; //ex数组即为extend数组//预处理计算next数组void GETNEXT(char *str)&#123; int i = 0, j, po, len = strlen(str); next[0] = len; //初始化next[0]，因为从0开头就可以匹配整个T，故为len /*与EXKMP代码不同处：无这句话*/ while(str[i] == str[i + 1] &amp;&amp; i + 1 &lt; len) //计算next[1] /*与EXKMP代码不同处：比较s1和s2*/ i++; next[1] = i;/*与EXKMP代码不同处：ex[0]=i*/ po = 1; //初始化po的位置 /*与EXKMP代码不同处：po = 0*/ for(i = 2; i &lt; len; i++)/*与EXKMP代码不同处：i从1开始*/ &#123; if(next[i - po] + i &lt; next[po] + po) //第一种情况，可以直接得到next[i]的值 /*与EXKMP代码不同处：next[i-po]+i next[i] = next[i - po];/*与EXKMP代码不同处：ex[i]=next[i-po];*/ else//第二种情况，要继续匹配才能得到next[i]的值 &#123; j = next[po] + po - i;/*与EXKMP代码不同处：j=ex[po]+po-i;*/ if(j &lt; 0)j = 0; //如果i&gt;po+next[po],则要从头开始匹配 while(i + j &lt; len &amp;&amp; str[j] == str[j + i]) //计算next[i] /*与EXKMP代码不同处：i+j j++; next[i] = j;/*与EXKMP代码不同处：ex[i]=j;*/ po = i; //更新po的位置 &#125; &#125;&#125;//计算extend数组void EXKMP(char *s1, char *s2)&#123; int i = 0, j, po, len = strlen(s1), l2 = strlen(s2); GETNEXT(s2);//计算子串的next数组 while(s1[i] == s2[i] &amp;&amp; i &lt; l2 &amp;&amp; i &lt; len) //计算ex[0] i++; ex[0] = i; po = 0; //初始化po的位置 for(i = 1; i &lt; len; i++) &#123; if(next[i - po] + i &lt; ex[po] + po) //第一种情况，直接可以得到ex[i]的值 ex[i] = next[i - po]; else//第二种情况，要继续匹配才能得到ex[i]的值 &#123; j = ex[po] + po - i; if(j &lt; 0)j = 0; //如果i&gt;ex[po]+po则要从头开始匹配 while(i + j &lt; len &amp;&amp; j &lt; l2 &amp;&amp; s1[j + i] == s2[j]) //计算ex[i] j++; ex[i] = j; po = i; //更新po的位置 &#125; &#125;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"整体二分（poj 2104）","slug":"整体二分（poj-2104）","date":"2020-04-10T10:12:12.000Z","updated":"2022-04-13T13:31:48.995Z","comments":true,"path":"2020/04/10/整体二分（poj-2104）/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E6%95%B4%E4%BD%93%E4%BA%8C%E5%88%86%EF%BC%88poj-2104%EF%BC%89/","excerpt":"","text":"所谓整体二分，需要数据结构题满足以下性质： 询问的答案具有可二分性 修改对判定答案的贡献相对独立，修改之间互不影响效果 修改如果对判定答案有贡献，则贡献为一确定的与判定标准无关的值 贡献满足交换律，结合律，具有可加性 题目允许离线操作 不妨先来考虑下一个简单易懂的?(?????)的排序算法(?为数值范围)这个方法是自己在思考整体二分的时候??的 虽然在实际应用上没什么意义 但是有助于理解整体二分的分治过程我们假设当前处理的区间里最小值不小于? 最大值不大于? 令???=(?+?)/2然后把当前区间扫描一遍 如果一个数不大于???就放到左子区间 否则放到右子区间如此下去 直到区间内只剩一个数或者? 与 ?相等 排序就完成了 现在回到静态区间第?小问题 和刚才那个排序算法类似 我们先二分一个答案???，如果区间内小于等于???的数的个数(记为???)不超过? 那么最终答案显然也是不超过???的，这类询问我们把它们划分到左子区间。而对于???大于?的 我们则把它们划分到右子区间 并且把?减去???，换句话说就是把小于等于???的数的贡献全部算上后之后就不用考虑了。可以发现这样划分的层数是???? 而每一层的询问个数是?个 再加上算贡献时用到的??? 所以复杂度是?(?????????) 以下是poj 2104的参考代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#include #include #include #include #include #include #include #include #include #include #include #include using namespace std;#define mem(a, b) memset(a, b, sizeof(a))#define PI acos(-1)#define debug(a) cout &lt;&lt; (a) &lt;&lt; endltypedef long long ll;int dir8[8][2] = &#123; &#123; 1, 0 &#125;, &#123; 0, 1 &#125;, &#123; -1, 0 &#125;, &#123; 0, -1 &#125;, &#123; 1, 1 &#125;, &#123; 1, -1 &#125;, &#123; -1, 1 &#125;, &#123; -1, -1 &#125; &#125;;int dir4[4][2] = &#123; 1, 0, 0, 1, -1, 0, 0, -1 &#125;;const int INF = 0x3f3f3f3fLL;const long long LLF = 0x3f3f3f3f3f3f3f3fLL;const int MAXn = 2e5 + 15;const int mod = 1e9 + 7;//priority_queue, vector&gt;, greater&gt;&gt; q;int n, m, c[MAXn], ans[MAXn],cnt; //c 树状数组， ans：答案struct node &#123; int ty, pos, x, y, k; //ty区别输入和询问， pos ：下标，x：左，y：右， k：第k小&#125; q[MAXn], q1[MAXn], q2[MAXn]; //q存储 ，q1：左区间，q2：右区间int lowbit(int x) // 求x最低位的1&#123; return x &amp; -x;&#125;void add(int x, int val) //更新树状数组&#123; while (x &lt;= n) &#123; c[x] += val; x += lowbit(x); &#125;&#125;int sum(int x) //求 1-x 的树状数组的值的和&#123; int sum = 0; while (x&gt;0) &#123; sum += c[x]; x -= lowbit(x); &#125; return sum;&#125;void solve(int l, int r, int L, int R) &#123; if (l &gt; r L &gt; R) return; if (L == R) &#123; //如果相等 更新答案 for (int i = l; i &lt;= r; i++) &#123; if (q[i].ty) &#123; ans[q[i].pos] = L; &#125; &#125; return; &#125; int mid = (L + R) &gt;&gt; 1, cnt1 = 0, cnt2 = 0; for (int i = l; i &lt;= r; i++) &#123; if (q[i].ty) &#123;//如果是询问 int temp = sum(q[i].y) - sum(q[i].x - 1); //temp ：q[i].x 到q[i].y 小于等于mid 的个数 if (temp &gt;= q[i].k) //如果小于等于mid的数大于k q1[++cnt1] = q[i];//放到左区间 else &#123; //反之 k减去temp 并放到右区间 q[i].k -= temp; q2[++cnt2] = q[i]; &#125; &#125; else &#123; //如果是输入 if(q[i].x&lt;=mid)&#123; //如果小于mid add(q[i].pos,q[i].y);// 更新树状数组 q1[++cnt1]=q[i];// 放到左区间 &#125; else q2[++cnt2]=q[i];//反之，放到右区间 &#125; &#125; for(int i=1;i&lt;=cnt1;i++)&#123; if(!q1[i].ty)&#123; //更新树状数组 add(q1[i].pos,-q1[i].y); &#125; &#125;//更新 q 数组 for(int i=1;i&lt;=cnt1;i++)&#123; q[l+i-1]=q1[i]; &#125; for(int i=1;i&lt;=cnt2;i++)&#123; q[l+i+cnt1-1]=q2[i]; &#125; solve(l,l+cnt1-1,L,mid);//左区间 solve(l+cnt1,r,mid+1,R);//右区间 return ;&#125;int main()&#123;//输入 cin&gt;&gt;n&gt;&gt;m; int l,r,k; for(int i=1;i&lt;=n;i++)&#123; cin&gt;&gt;k; q[++cnt]=node&#123;0,i,k,1,0&#125;; // ty==0 表示是输入 &#125; for(int i=1;i&lt;=m;i++)&#123; cin&gt;&gt;l&gt;&gt;r&gt;&gt;k; q[++cnt]=node&#123;1,i,l,r,k&#125;; //ty==1 表示是询问 &#125; solve(1,cnt,-INF,INF); for(int i=1;i&lt;=m;i++)//输出 cout&lt;&lt;ans[i]&lt;&lt;endl; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"LCA（在线ST+tarjan）模板","slug":"lca（在线sttarjan）模板","date":"2020-04-10T10:11:23.000Z","updated":"2022-04-13T13:31:48.590Z","comments":true,"path":"2020/04/10/lca（在线sttarjan）模板/","link":"","permalink":"https://tang7o.cn/2020/04/10/lca%EF%BC%88%E5%9C%A8%E7%BA%BFsttarjan%EF%BC%89%E6%A8%A1%E6%9D%BF/","excerpt":"","text":"在线ST123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;#include &lt;stack&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;#include &lt;map&gt;using namespace std;#define mem(a, b) memset(a, b, sizeof(a))#define PI acos(-1)#define DEBUG(a) cout &lt;&lt; (a) &lt;&lt; endltypedef long long ll;int dir8[8][2] = &#123;&#123;1, 2&#125;, &#123;2, 1&#125;, &#123;-1, 2&#125;, &#123;2, -1&#125;, &#123;-2, 1&#125;, &#123;-2, -1&#125;, &#123;-1, -2&#125;, &#123;1, -2&#125;&#125;;int dir4[4][2] = &#123;1, 0, 0, 1, -1, 0, 0, -1&#125;;const int INF = 0x3f3f3f3fLL;const long long LLF = 0x3f3f3f3f3f3f3f3fLL;const int MAXn = 4e4 + 15;const int mod = 1e9 + 7;//priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; q;struct node&#123; int u, v, w, next;&#125; edge[2 * MAXn];int head[MAXn];bool vis[MAXn];int dis[MAXn];int deep[2 * MAXn]; //深度int first[MAXn]; //首次出现位置int ver[2 * MAXn]; //遍历顺序int dp[MAXn * 2][25]; //dp[i][k]=a; 从 i 开始往后 1&lt;&lt;k 个数中最小深度的下标为 aint n, m, cnt = 1, k;void add(int u, int v, int w)//链式前向星&#123; edge[cnt] = &#123;u, v, w, head[u]&#125;; head[u] = cnt++;&#125;void init() //初始化&#123; mem(dis, 0); mem(vis, 0); mem(head, 0); cnt = 1;&#125;void DFS(int u, int dep)//深搜遍历&#123; vis[u] = 1; //标记为 1 表示已经遍历过次点 deep[cnt] = dep; //深度为dep ver[cnt] = u; // 遍历次序 first[u] = cnt++; //u 第一次出现的下坐标为 cnt for (int i = head[u]; i != 0; i = edge[i].next) //遍历 &#123; if (!vis[edge[i].v]) //如果没有遍历过，就遍历 &#123; dis[edge[i].v] = dis[u] + edge[i].w; //更新到根节点的距离 DFS(edge[i].v, dep + 1); ver[cnt] = u; //回溯（又回到了 u 点 deep[cnt++] = dep; &#125; &#125;&#125;void ST()//更新区间最小值&#123; for (int i = 1; i &lt;= cnt; i++) dp[i][0] = i; for (int j = 1; j&lt;20; j++) for (int i = 1; i + (1 &lt;&lt; j) - 1 &lt;= cnt; i++) &#123; int a = dp[i][j - 1], b = dp[i + (1 &lt;&lt; (j - 1))][j - 1]; dp[i][j] = deep[a] &lt; deep[b] ? a : b; //存下坐标 &#125;&#125;int RMQ(int l, int r) //找 l 和 r 的最近公共祖先的下坐标&#123; int k = 0; while (1 &lt;&lt; (k + 1) &lt;= r - l + 1) k++; int a = dp[l][k]; int b = dp[r - (1 &lt;&lt; k) + 1][k]; return deep[a] &lt; deep[b] ? a : b;&#125;int LCA(int u, int v)&#123; int x = first[u], y = first[v]; //第一次出现的位置 if (x &gt; y) swap(x, y); int res = RMQ(x, y); return ver[res]; //返回 u 和 v 的最近公共祖先&#125; Tarjan 离线算法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;#include &lt;stack&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;#include &lt;map&gt;using namespace std;#define mem(a, b) memset(a, b, sizeof(a))#define PI acos(-1)#define DEBUG(a) cout &lt;&lt; (a) &lt;&lt; endltypedef long long ll;int dir8[8][2] = &#123;&#123;1, 2&#125;, &#123;2, 1&#125;, &#123;-1, 2&#125;, &#123;2, -1&#125;, &#123;-2, 1&#125;, &#123;-2, -1&#125;, &#123;-1, -2&#125;, &#123;1, -2&#125;&#125;;int dir4[4][2] = &#123;1, 0, 0, 1, -1, 0, 0, -1&#125;;const int INF = 0x3f3f3f3fLL;const long long LLF = 0x3f3f3f3f3f3f3f3fLL;const int MAXn = 4e4 + 15;const int mod = 1e9 + 7;//priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; q;struct node&#123; int u, v, w, next;&#125; edge[2 * MAXn];//边struct Quiz&#123; int u, v, i, next; //求 u 和 v 的LCA，这是第 i 组提问&#125; quiz[2*205]; //提问int head_edge[MAXn];//边int head_quiz[MAXn]; //提问bool vis[MAXn]; //是否遍历过int dis[MAXn]; //到根节点的距离int fa[MAXn]; //父节点int lca[205]; //提问的结果，lca[i]=n 表示第 i 组提问的LCA是 n int A[205],B[205]; //存提问数据int n, m, tot1 = 0, tot2 = 0; void add_edge(int u, int v, int w)&#123; //链式前向星 edge[++tot1] = &#123;u, v, w, head_edge[u]&#125;; head_edge[u] = tot1;&#125;void add_quiz(int u,int v,int i)&#123; quiz[++tot2]=&#123;u,v,i,head_quiz[u]&#125;; head_quiz[u]=tot2;&#125;void init()&#123; //初始化 mem(dis, 0); mem(vis, 0); mem(head_edge, 0); mem(head_quiz,0); tot1 = tot2 = 0;&#125;int find(int x) //寻找祖先 + 路径压缩&#123; return fa[x]==x?x:fa[x]=find(fa[x]);&#125;void Tarjan(int x)&#123; vis[x]=1; //标记 fa[x]=x; //父节点更新为自己 for(int i=head_quiz[x];i!=0;i=quiz[i].next)&#123; //如果有 x，quiz[i].v 这组提问并且 quiz[i].v 被遍历过 if(vis[quiz[i].v]) lca[quiz[i].i]=find(quiz[i].v); //quiz[i].v 的祖先即提问的LCA &#125; for(int i=head_edge[x];i!=0;i=edge[i].next)&#123; //遍历树 if(!vis[edge[i].v])&#123; dis[edge[i].v]=dis[x]+edge[i].w; Tarjan(edge[i].v); fa[edge[i].v]=x; &#125; &#125;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Tarjan 算法求强连通分量","slug":"tarjan-算法求强连通分量","date":"2020-04-10T10:10:30.000Z","updated":"2022-04-13T13:31:48.690Z","comments":true,"path":"2020/04/10/tarjan-算法求强连通分量/","link":"","permalink":"https://tang7o.cn/2020/04/10/tarjan-%E7%AE%97%E6%B3%95%E6%B1%82%E5%BC%BA%E8%BF%9E%E9%80%9A%E5%88%86%E9%87%8F/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#include &lt;cstdio&gt;#include &lt;iostream&gt;#include &lt;cstdlib&gt;#include &lt;cmath&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;#include &lt;set&gt;#include &lt;map&gt;#include &lt;queue&gt;#include &lt;stack&gt;#include &lt;vector&gt;#include &lt;string&gt;using namespace std;#define mem(a, b) memset(a, b, sizeof(a))#define PI acos(-1)#define debug(a) cout &lt;&lt; (a) &lt;&lt; endltypedef long long ll;int dir8[8][2] = &#123;&#123;1, 0&#125;, &#123;0, 1&#125;, &#123;-1, 0&#125;, &#123;0, -1&#125;, &#123;1, 1&#125;, &#123;1, -1&#125;, &#123;-1, 1&#125;, &#123;-1, -1&#125;&#125;;int dir4[4][2] = &#123;1, 0, 0, 1, -1, 0, 0, -1&#125;;const int INF = 0x3f3f3f3fLL;const long long LLF = 0x3f3f3f3f3f3f3f3fLL;const int MAXn = 1e4 + 15;const int mod = 1e9 + 7;//priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; q;/************有向图****************/struct node &#123; int u, v, next;&#125; edge[MAXn];int head_edge[MAXn];bool in_Stack[MAXn]; //入栈标记bool visit[MAXn]; //遍历标记int DFN[MAXn]; //第几个被遍历（时间戳int LOW[MAXn]; //强连通分量中最小时间戳（根节点int Stack[MAXn]; //栈int tot_edge; int Index; int tot_point; //时间戳void add_edge(int u, int v)&#123; edge[++tot_edge] = &#123; u, v, head_edge[u] &#125;; head_edge[u] = tot_edge;&#125;void init()//初始化&#123; tot_edge = tot_point = Index = 0; mem(in_Stack, 0); mem(visit, 0); mem(Stack, 0); mem(head_edge, 0);&#125;void Tarjan(int x)&#123; DFN[x] = LOW[x] = ++tot_point; //更新时间戳 Stack[++Index] = x; //入栈 in_Stack[x] = visit[x] = 1; //标记 for (int i = head_edge[x]; i != 0; i = edge[i].next) &#123; //遍历图 if (!DFN[edge[i].v]) &#123; //如果没有遍历过 Tarjan(edge[i].v); //遍历 LOW[x] = min(LOW[edge[i].v], LOW[x]); //更新LOW数组 &#125; else if (in_Stack[edge[i].v]) &#123; //如果遍历过并且在栈里面，直接更新LOW数组 LOW[x] = min(LOW[edge[i].v], LOW[x]); &#125; &#125; if (DFN[x] == LOW[x]) &#123;//发现是整个强连通分量子树里的最小根 do&#123; printf(&quot;%d &quot;,Stack[Index]); visit[Stack[Index]]=0; Index--; &#125;while(x!=Stack[Index+1]);//出栈，并且输出 printf(&quot;\\n&quot;); &#125; return;&#125;int main()&#123; /* 相应操作 */ for (int i = 1; i &lt;= n; i++) if (!visit[i]) //如果这个点没遍历过，就遍历一遍，避免遗漏 Tarjan(i); /* 相应操作 */ return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"[USACO 4.2.2] The Perfect Stall 完美的牛栏","slug":"usaco-4-2-2-the-perfect-stall-完美的牛栏","date":"2020-04-10T10:09:52.000Z","updated":"2022-04-13T13:31:48.704Z","comments":true,"path":"2020/04/10/usaco-4-2-2-the-perfect-stall-完美的牛栏/","link":"","permalink":"https://tang7o.cn/2020/04/10/usaco-4-2-2-the-perfect-stall-%E5%AE%8C%E7%BE%8E%E7%9A%84%E7%89%9B%E6%A0%8F/","excerpt":"","text":"题目链接 匈牙利算法模板题123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;#include &lt;stack&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;#include &lt;map&gt; using namespace std;#define mem(a, b) memset(a, b, sizeof(a))#define PI acos(-1)#define DEBUG(a) cout &lt;&lt; (a) &lt;&lt; endltypedef long long ll;int dir8[8][2] = &#123;&#123;1, 0&#125;, &#123;0, 1&#125;, &#123;-1, 0&#125;, &#123;0, -1&#125;, &#123;-1, 1&#125;, &#123;-1, -1&#125;, &#123;1, -1&#125;, &#123;1, 1&#125;&#125;;int dir4[4][2] = &#123;1, 0, 0, 1, -1, 0, 0, -1&#125;;const int INF = 0x3f3f3f3fLL;const long long LLF = 0x3f3f3f3f3f3f3f3fLL;const int MAXn = 1e5 + 15;const int mod = 1e9 + 7;//priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; q;int cnt,n,m,Next[400];//Next[i]=a表示第i个牛栏中是第a头牛bool mapn[402][402],mark[400];//mapn[i][j]=true;表示第i头牛喜欢第j个牛栏 mark[i]=true;表示第i个牛栏用过了bool check(int x)&#123; for (int i=1;i&lt;=m;i++)//便利每一个牛栏 if (mapn[x][i]&amp;&amp;(!mark[i]))//如果第x头牛喜欢这个牛栏 并且这个牛栏是空的 &#123; mark[i]=true;//标记这个牛栏 if (Next[i]==0check(Next[i]))//如果这个牛栏没有牛或者可以腾出地方 &#123; Next[i]=x;//更新这个牛栏中是第x头牛 return true; &#125; &#125; return false;&#125;int main()&#123;//输入 scanf(&quot;%d%d&quot;,&amp;n,&amp;m); for (int i=1;i&lt;=n;i++) &#123; int a; scanf(&quot;%d&quot;,&amp;a); for (int j=1;j&lt;=a;j++) &#123; int b; scanf(&quot;%d&quot;,&amp;b); mapn[i][b]=true; &#125; &#125; for (int i=1;i&lt;=n;i++)//遍历每头牛 &#123; for (int j=1;j&lt;=m;j++)//清空标记数组 mark[j]=false; if (check(i)) cnt++; &#125; printf(&quot;%d\\n&quot;,cnt); return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"题目","slug":"ACM/题目","permalink":"https://tang7o.cn/categories/ACM/%E9%A2%98%E7%9B%AE/"}],"tags":[{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"}]},{"title":"欧拉函数线性筛","slug":"欧拉函数线性筛","date":"2020-04-10T10:00:47.000Z","updated":"2022-04-13T13:31:49.094Z","comments":true,"path":"2020/04/10/欧拉函数线性筛/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E6%AC%A7%E6%8B%89%E5%87%BD%E6%95%B0%E7%BA%BF%E6%80%A7%E7%AD%9B/","excerpt":"","text":"定义：欧拉函数是小于n的数中与n互质的数的数目。例如φ(8)=4，因为1,3,5,7均和8互质。 欧拉函数的通式为$φ(x)=x (1-\\left(\\frac{1}{p1}\\right))(1-\\left(\\frac{1}{p2}\\right))…(1-\\left(\\frac{1}{pk}\\right))$：,其中pi表示x的质因数。 特别声明，φ(1)=1。 注意：每种质因数只一个。比如$12=223$那么$φ（12）=12（1-\\left(\\frac{1}{2}\\right)）(1-\\left(\\frac{1}{3}\\right))=4$ 其中还有比较特殊的几个。 若p为质数，$n=p^k$ ，则$φ(n)=p^k-p^k-1$ 。 如果n是奇数，那么$φ(2n)=φ(n)$ 如果n是质数，那么，$φ(n)=n-1$ ,即所有小于n的数都与他互质。 $φ(ab)=φ(a)φ(b)$ 如果i%p==0，那么，$φ(ip)=φ(i)p$; 计算时$phi(x)=x(1-\\left(\\frac{1}{p1}\\right))…(1-\\left(\\frac{1}{pi}\\right))$中的x(1-1/pi)可以转化为x/pi*(pi-1)用来避免小数的产生，同时先除后乘可以避免溢出。 单个欧拉函数 1234567891011121314void euler(int n)&#123; for (int i=1;i&lt;=n;i++) phi[i]=i; for (int i=2;i&lt;=n;i++) &#123; if (phi[i]==i)//这代表i是质数 &#123; for (int j=i;j&lt;=n;j+=i) &#123; phi[j]=phi[j]/i*(i-1);//把i的倍数更新掉 &#125; &#125; &#125;&#125; 线性筛 思想：保证每个合数只会被他的最小之质因子筛去。 12345678910111213141516171819202122void euler(int n)&#123; phi[1]=1;//1要特判 for (int i=2;i&lt;=n;i++) &#123; if (flag[i]==0)//这代表i是质数 &#123; prime[++num]=i; phi[i]=i-1; &#125; for (int j=1;j&lt;=num&amp;&amp;prime[j]*i&lt;=n;j++)//经典的欧拉筛写法 &#123; flag[i*prime[j]]=1;//先把这个合数标记掉 if (i%prime[j]==0) &#123; phi[i*prime[j]]=phi[i]*prime[j];//若prime[j]是i的质因子，则根据计算公式，i已经包括i*prime[j]的所有质因子 break;//经典欧拉筛的核心语句，这样能保证每个数只会被自己最小的因子筛掉一次 &#125; else phi[i*prime[j]]=phi[i]*phi[prime[j]];//利用了欧拉函数是个积性函数的性质 &#125; &#125;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"组合游戏 - SG函数和SG定理","slug":"组合游戏-sg函数和sg定理","date":"2020-04-10T09:59:17.000Z","updated":"2022-04-13T13:31:49.194Z","comments":true,"path":"2020/04/10/组合游戏-sg函数和sg定理/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E7%BB%84%E5%90%88%E6%B8%B8%E6%88%8F-sg%E5%87%BD%E6%95%B0%E5%92%8Csg%E5%AE%9A%E7%90%86/","excerpt":"","text":"在介绍SG函数和SG定理之前我们先介绍介绍必胜点与必败点吧. 必胜点和必败点的概念： P点：必败点，换而言之，就是谁处于此位置，则在双方操作正确的情况下必败。 N点：必胜点，处于此情况下，双方操作均正确的情况下必胜。 必胜点和必败点的性质： 1、所有终结点是 必败点 P 。（我们以此为基本前提进行推理，换句话说，我们以此为假设） 2、从任何必胜点N 操作，至少有一种方式可以进入必败点 P。 3、无论如何操作，必败点P 都只能进入 必胜点 N。 我们研究必胜点和必败点的目的时间为题进行简化，有助于我们的分析。通常我们分析必胜点和必败点都是以终结点进行逆序分析。我们以hdu 1847 Good Luck in CET-4 Everybody!为例： 当 n = 0 时，显然为必败点，因为此时你已经无法进行操作了 当 n = 1 时，因为你一次就可以拿完所有牌，故此时为必胜点 当 n = 2 时，也是一次就可以拿完，故此时为必胜点 当 n = 3 时，要么就是剩一张要么剩两张，无论怎么取对方都将面对必胜点，故这一点为必败点。 以此类推，最后你就可以得到； n： 0 1 2 3 4 5 6 ... position： P N N P N N P … 你发现了什么没有，对，他们就是成有规律，使用了 P/N来分析，有没有觉得问题变简单了。 现在给你一个稍微复杂一点点的： hdu 2147 kiki’s game 现在我们就来介绍今天的主角吧。组合游戏的和通常是很复杂的，但是有一种新工具，可以使组合问题变得简单————SG函数和SG定理。 Sprague-Grundy定理（SG定理）： **游戏和的SG函数等于各个游戏SG函数的Nim和。**这样就可以将每一个子游戏分而治之，从而简化了问题。而Bouton定理就是Sprague-Grundy定理在Nim游戏中的直接应用，因为单堆的Nim游戏 SG函数满足 SG(x) = x。不知道Nim游戏的请移步：[这里](http://blog.csdn.net/luomingjun12315/article/details/45479073) SG函数： 首先定义mex(minimal excludant)运算，这是施加于一个集合的运算，表示最小的不属于这个集合的非负整数。例如mex&#123;0,1,2,4&#125;=3、mex&#123;2,3,5&#125;=0、mex&#123;&#125;=0。 对于任意状态 x ， 定义 SG(x) = mex(S),其中 S 是 x 后继状态的SG函数值的集合。如 x 有三个后继状态分别为 SG(a),SG(b),SG(c)，那么SG(x) = mex&#123;SG(a),SG(b),SG(c)&#125;。 这样 集合S 的终态必然是空集，所以SG函数的终态为 SG(x) = 0,当且仅当 x 为必败点P时。 【实例】取石子问题 有1堆n个的石子，每次只能取{ 1, 3, 4 }个石子，先取完石子者胜利，那么各个数的SG值为多少？ SG[0]=0，f[]={1,3,4}, x=1 时，可以取走1 - f{1}个石子，剩余{0}个，所以 SG[1] = mex{ SG[0] }= mex{0} = 1; x=2 时，可以取走2 - f{1}个石子，剩余{1}个，所以 SG[2] = mex{ SG[1] }= mex{1} = 0; x=3 时，可以取走3 - f{1,3}个石子，剩余{2,0}个，所以 SG[3] = mex{SG[2],SG[0]} = mex{0,0} =1; x=4 时，可以取走4- f{1,3,4}个石子，剩余{3,1,0}个，所以 SG[4] = mex{SG[3],SG[1],SG[0]} = mex{1,1,0} = 2; x=5 时，可以取走5 - f{1,3,4}个石子，剩余{4,2,1}个，所以SG[5] = mex{SG[4],SG[2],SG[1]} =mex{2,0,1} = 3; 以此类推….. x 0 1 2 3 4 5 6 7 8…. SG[x] 0 1 0 1 2 3 2 0 1…. 由上述实例我们就可以得到SG函数值求解步骤，那么计算1~n的SG函数值步骤如下： 1、使用 数组f 将 可改变当前状态 的方式记录下来。 2、然后我们使用 另一个数组 将当前状态x 的后继状态标记。 3、最后模拟mex运算，也就是我们在标记值中 搜索 未被标记值 的最小值，将其赋值给SG(x)。 4、我们不断的重复 2 - 3 的步骤，就完成了 计算1~n 的函数值。 代码实现如下： 1234567891011121314151617181920//f[N]:可改变当前状态的方式，N为方式的种类，f[N]要在getSG之前先预处理//SG[]:0~n的SG函数值//S[]:为x后继状态的集合int f[N],SG[MAXN],S[MAXN];void getSG(int n)&#123; int i,j; memset(SG,0,sizeof(SG)); //因为SG[0]始终等于0，所以i从1开始 for(i = 1; i &lt;= n; i++)&#123; //每一次都要将上一状态 的 后继集合 重置 memset(S,0,sizeof(S)); for(j = 0; f[j] &lt;= i &amp;&amp; j &lt;= N; j++) S[SG[i-f[j]]] = 1; //将后继状态的SG函数值进行标记 for(j = 0;; j++) if(!S[j])&#123; //查询当前后继状态SG值中最小的非零值 SG[i] = j; break; &#125; &#125;&#125; 现在我们来一个实战演练（题目链接）： 只要按照上面的思路，解决这个就是分分钟的问题。 代码如下： 123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;#include &lt;string.h&gt;#define MAXN 1000 + 10#define N 20int f[N],SG[MAXN],S[MAXN];void getSG(int n)&#123; int i,j; memset(SG,0,sizeof(SG)); for(i = 1; i &lt;= n; i++)&#123; memset(S,0,sizeof(S)); for(j = 0; f[j] &lt;= i &amp;&amp; j &lt; N; j++) S[SG[i-f[j]]] = 1; for(j = 0;;j++) if(!S[j])&#123; SG[i] = j; break; &#125; &#125;&#125;int main()&#123; int n,m,k; f[0] = f[1] = 1; for(int i = 2; i &lt;= 16; i++) f[i] = f[i-1] + f[i-2]; getSG(1000); while(scanf(&quot;%d%d%d&quot;,&amp;m,&amp;n,&amp;k),m||n||k)&#123; if(SG[n]^SG[m]^SG[k]) printf(&quot;Fibo\\n&quot;); else printf(&quot;Nacci\\n&quot;); &#125; return 0;&#125; 大家是不是还没有过瘾，那我就在给大家附上一些组合博弈的题目： POJ 2234 Matches GameHOJ 4388 Stone Game IIPOJ 2975 NimHOJ 1367 A Stone GamePOJ 2505 A multiplication gameZJU 3057 beans gamePOJ 1067 取石子游戏POJ 2484 A Funny GamePOJ 2425 A Chess GamePOJ 2960 S-NimPOJ 1704 Georgia and BobPOJ 1740 A New Stone GamePOJ 2068 NimPOJ 3480 JohnPOJ 2348 Euclid’s GameHOJ 2645 WNimPOJ 3710 Christmas GamePOJ 3533 Light Switching Game （如有错误，欢迎指正）","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"知识","slug":"知识","permalink":"https://tang7o.cn/tags/%E7%9F%A5%E8%AF%86/"}]},{"title":"逆元","slug":"逆元","date":"2020-04-10T09:56:22.000Z","updated":"2022-04-13T13:31:49.222Z","comments":true,"path":"2020/04/10/逆元/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E9%80%86%E5%85%83/","excerpt":"","text":"由于C++储存数据的范围是有限的，当数据超出储存范围时计算就会出错，为了避免错误，一般使用求余的方法。 $(a+b)\\%c$可以表示为$(a\\%c+b\\%c)\\%c$，乘法同理 减法也可以表示为$(a+c-b)\\%c$ 但是除法怎么办呢？ 想一下除法计算过程：$a/b=a* 1/b$ 那么自然会想到，把$(a/b)\\%c$变成$(a(1/b))$不就可以了吗。但是现实是残酷的，取余是建立在除数和被除数都算整数的基础上的，浮点数无法进行取余计算。那么我们可不可以在$1～c-1$中找到一个数x使得$(a/b)\\%c==(ax)\\%c$ 呢？即$b x=1(\\%c)$;答案是肯定的！这个x就叫做b的逆元，或者叫做数论倒数(和正常意义上的倒数不一样，但和正常意义上的倒数具有相同的作用)。有逆元的充要条件$a$在mod c意义下有逆元的充要条件：GCD(a,c)=1那么*逆元要怎么求呢？ EXGCD求a在mod c意义下的逆元，可以转化为求 ax+cy=1 ；就可以用EXGCD求逆元了。 12345void ex_gcd(LL a,LL b,LL &amp;x,LL &amp;y)&#123; if(!b)&#123;x=1;y=0;return;&#125; ex_gcd(b,a%b,y,x); y-=a/b*x; &#125; 费马小定理如果p为质数，则$a^{p−1}≡1\\%p$$∴a*a^{p−2}≡1\\%p$快速幂求$a^{p-2}$就可以啦。 1234567891011int q_pow(int a,int n,int m) &#123; int ans = 1; while(n) &#123; if (n&amp;1) &#123; ans = ans*a%m; &#125; a = a*a%m; n &gt;&gt;= 1; &#125; return ans; &#125; 欧拉定理将费马小定理中的p−2换为φ( p )−1即可p可以不是质数 递推用于O(n)预处理[1⋯n]的逆元构造$p=k i+r$$∴k i+r≡0\\%p $$∴k i=−r $$∴i−1=−k r−1 $其中$k=⌊pi⌋,r=p\\%i $$∴i−1=−⌊pi⌋⋅inv[p\\%i] $ 为了防止出现负数，通常的写法是这样的 1inv[i]=(mod-mod/i)*inv[mod%i]%mod; 参考博客： https://blog.csdn.net/Gh0stCai/article/details/79968462 https://blog.csdn.net/Adusts/article/details/80627966","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"知识","slug":"知识","permalink":"https://tang7o.cn/tags/%E7%9F%A5%E8%AF%86/"}]},{"title":"KMP算法模板（自用）","slug":"kmp算法模板（自用）","date":"2020-04-10T09:53:21.000Z","updated":"2022-04-13T13:31:48.577Z","comments":true,"path":"2020/04/10/kmp算法模板（自用）/","link":"","permalink":"https://tang7o.cn/2020/04/10/kmp%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF%EF%BC%88%E8%87%AA%E7%94%A8%EF%BC%89/","excerpt":"","text":"nex[i]存的是从字符串起点到下标位i的字符真前缀和真后缀相同的最大长度 123456789101112131415161718192021222324252627282930313233void Getnex(char * m)&#123; nex[0]=-1; int k=-1,j=0; int len=strlen(m); while(j&lt;len) &#123; if(k==-1m[k]==m[j]) &#123; k++;j++; nex[j]=k; &#125;else k=nex[k]; &#125;&#125;int kmp()//用kmp进行匹配&#123; int k=0,j=0; while(j&lt;h.size()) &#123; if(k==-1s[k]==h[j]) &#123; k++;j++; &#125;else&#123; k=nex[k]; cout&lt;&lt;k&lt;&lt;&quot; &quot;&lt;&lt;j&lt;&lt;endl; &#125; if(k == s.size()) return j-k; &#125; return -1;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"模板","slug":"ACM/模板","permalink":"https://tang7o.cn/categories/ACM/%E6%A8%A1%E6%9D%BF/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"模板","slug":"模板","permalink":"https://tang7o.cn/tags/%E6%A8%A1%E6%9D%BF/"}]},{"title":"Manacher算法模板(求解最长回文串)","slug":"manacher算法模板求解最长回文串","date":"2020-04-10T09:52:37.000Z","updated":"2022-04-13T13:31:48.603Z","comments":true,"path":"2020/04/10/manacher算法模板求解最长回文串/","link":"","permalink":"https://tang7o.cn/2020/04/10/manacher%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF%E6%B1%82%E8%A7%A3%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E4%B8%B2/","excerpt":"","text":"（原文有详解，若点击链接跳转失败，直接在浏览器输入 bestsort.cn 即可） 1234567891011121314151617181920212223242526272829int cnt[MAXn];char String[MAXn];void Manacher(char s[],int len) &#123;//原字符串和串长 int l = 0; String[l++] = &#x27;$&#x27;; // 0下标存储为其他字符,防止越界 String[l++] = &#x27;#&#x27;; for (int i = 0; i &lt; len; i++) &#123; String[l++] = s[i]; String[l++] = &#x27;#&#x27;; &#125; String[l] = 0; // 空字符 int MaxR = 0; int flag = 0; for (int i = 0; i &lt; l; i++) &#123; cnt[i] = MaxR &gt; i ? min(cnt[2 * flag - i], MaxR - i) : 1;//2*flag-i是i点关于flag的对称点 while (String[i + cnt[i]] == String[i - cnt[i]]) cnt[i]++; if (i + cnt[i] &gt; MaxR) &#123; MaxR = i + cnt[i]; flag = i; &#125; &#125;&#125;/** String: $ # a # b # a # a # b # a # 0* cnt: 1 1 2 1 4 1 2 7 2 1 4 1 2 1 * cnt 即每个点的回文半径*/","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"ac自动机模板（自用）","slug":"ac自动机模板（自用）","date":"2020-04-10T09:50:29.000Z","updated":"2022-04-13T13:31:48.473Z","comments":true,"path":"2020/04/10/ac自动机模板（自用）/","link":"","permalink":"https://tang7o.cn/2020/04/10/ac%E8%87%AA%E5%8A%A8%E6%9C%BA%E6%A8%A1%E6%9D%BF%EF%BC%88%E8%87%AA%E7%94%A8%EF%BC%89/","excerpt":"","text":"（原文有详解，若点击链接跳转失败，直接在浏览器输入 bestsort.cn 即可） 从多个字符串中查找是否有某个字符串 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;queue&gt;#include &lt;cstdlib&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;#include &lt;string&gt;#include &lt;cstring&gt;#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;typedef long long ll;const int maxn = 2*1e6+9;int trie[maxn][26]; //字典树int cntword[maxn]; //记录该单词出现次数int fail[maxn]; //失败时的回溯指针int cnt = 0;void insertWords(string s)&#123; int root = 0; for(int i=0;i&lt;s.size();i++)&#123; int next = s[i] - &#x27;a&#x27;; if(!trie[root][next]) trie[root][next] = ++cnt; root = trie[root][next]; &#125; cntword[root]++; //当前节点单词数+1&#125;void getFail()&#123; queue &lt;int&gt;q; for(int i=0;i&lt;26;i++)&#123; //将第二层所有出现了的字母扔进队列 if(trie[0][i])&#123; fail[trie[0][i]] = 0; q.push(trie[0][i]); &#125; &#125;//fail[now] -&gt;当前节点now的失败指针指向的地方////tire[now][i] -&gt; 下一个字母为i+&#x27;a&#x27;的节点的下标为tire[now][i] while(!q.empty())&#123; int now = q.front(); q.pop(); for(int i=0;i&lt;26;i++)&#123; //查询26个字母 if(trie[now][i])&#123; //如果有这个子节点为字母i+&#x27;a&#x27;,则//让这个节点的失败指针指向(((他父亲节点)的失败指针所指向的那个节点)的下一个节点) //有点绕,为了方便理解特意加了括号 fail[trie[now][i]] = trie[fail[now]][i]; q.push(trie[now][i]); &#125; else//否则就让当前节点的这个子节点，指向当前节点fail指针的这个子节点 trie[now][i] = trie[fail[now]][i]; &#125; &#125;&#125;int query(string s)&#123; int now = 0,ans = 0; for(int i=0;i&lt;s.size();i++)&#123; //遍历文本串 now = trie[now][s[i]-&#x27;a&#x27;]; //从s[i]点开始寻找 for(int j=now;j &amp;&amp; cntword[j]!=-1;j=fail[j])&#123; //一直向下寻找,直到匹配失败(失败指针指向根或者当前节点已找过). ans += cntword[j]; cntword[j] = -1; //将遍历国后的节点标记,防止重复计算 &#125; &#125; return ans;&#125;int main() &#123; int n; string s; cin &gt;&gt; n; for(int i=0;i&lt;n;i++)&#123; cin &gt;&gt; s ; insertWords(s); &#125; fail[0] = 0; getFail(); cin &gt;&gt; s ; cout &lt;&lt; query(s) &lt;&lt; endl; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"模板","slug":"ACM/模板","permalink":"https://tang7o.cn/categories/ACM/%E6%A8%A1%E6%9D%BF/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"模板","slug":"模板","permalink":"https://tang7o.cn/tags/%E6%A8%A1%E6%9D%BF/"}]},{"title":"RMQ算法详解（在线ST）","slug":"rmq算法详解（在线st）","date":"2020-04-10T09:47:29.000Z","updated":"2022-04-13T13:31:48.656Z","comments":true,"path":"2020/04/10/rmq算法详解（在线st）/","link":"","permalink":"https://tang7o.cn/2020/04/10/rmq%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88%E5%9C%A8%E7%BA%BFst%EF%BC%89/","excerpt":"","text":"1. 概述 RMQ（Range Minimum/Maximum Query），即区间最值查询，是指这样一个问题： 对于长度为n的数列A，回答若干询问RMQ（A,i,j）(i,j&lt;=n)，返回数列A中下标在i，j之间的最小/大值。这两个问题是在实际应用中经常遇到的问题，下面介绍一下解决这两种问题的比较高效的算法。当然，该问题也可以用线段树（也叫区间树）解决，算法复杂度为：O(N)~O(logN)，这里我们暂不介绍。2.RMQ算法 对于该问题，最容易想到的解决方案是遍历，复杂度是O(n)。但当数据量非常大且查询很频繁时，该算法无法在有效的时间内查询出正解。 本节介绍了一种比较高效的在线算法（ST算法）解决这个问题。所谓在线算法，是指用户每输入一个查询便马上处理一个查询。该算法一般用较长的时间做预处理，待信息充足以后便可以用较少的时间回答每个查询。ST（Sparse Table）算法是一个非常有名的在线处理RMQ问题的算法，它可以在O(nlogn)时间内进行预处理，然后在O(1)时间内回答每个查询。（一）首先是预处理，用动态规划（DP）解决。 设A[i]是要求区间最值的数列，F[i, j]表示从第i个数起连续2^j个数中的最大值。（DP的状态） 例如： A数列为：3 2 4 5 6 8 1 2 9 7 F[1，0]表示第1个数起，长度为2^0=1的最大值，其实就是3这个数。同理 F[1,1] = max(3,2) = 3, F[1，2]=max(3,2,4,5) = 5，F[1，3] = max(3,2,4,5,6,8,1,2) = 8; 并且我们可以容易的看出F[i,0]就等于A[i]。（DP的初始值） 这样，DP的状态、初值都已经有了，剩下的就是状态转移方程。 我们把F[i，j]平均分成两段（因为f[i，j]一定是偶数个数字），从 i 到$i + 2 ^{j - 1} - 1$为一段，$i + 2 ^ {j - 1}$到$i + 2 ^{ j} - 1$为一段(长度都为$2 ^ {j - 1}$。用上例说明，当i=1，j=3时就是3,2,4,5 和 6,8,1,2这两段。F[i，j]就是这两段各自最大值中的最大值。于是我们得到了状态转移方程F[i, j]=max（F[i，j-1], F[$i + 2^{j-1}$，j-1]）。 代码如下： 12345678910void RMQ(int num) //预处理-&gt;O(nlogn) &#123; for(int j = 1; j &lt; 20; ++j) for(int i = 1; i &lt;= num; ++i) if(i + (1 &lt;&lt; j) - 1 &lt;= num) &#123; maxsum[i][j] = max(maxsum[i][j - 1], maxsum[i + (1 &lt;&lt; (j - 1))][j - 1]); minsum[i][j] = min(minsum[i][j - 1], minsum[i + (1 &lt;&lt; (j - 1))][j - 1]); &#125; &#125; 这里我们需要注意的是循环的顺序，我们发现外层是j，内层所i，这是为什么呢？可以是i在外，j在内吗？ 答案是不可以。因为我们需要理解这个状态转移方程的意义。 状态转移方程的含义是：先更新所有长度为F[i,0]即1个元素，然后通过2个1个元素的最值，获得所有长度为F[i,1]即2个元素的最值，然后再通过2个2个元素的最值，获得所有长度为F[i,2]即4个元素的最值，以此类推更新所有长度的最值。 而如果是i在外，j在内的话，我们更新的顺序就是F[1,0],F[1,1],F[1,2],F[1,3],表示更新从1开始1个元素,2个元素，4个元素，8个元素（A[0],A[1],….A[7]）的最值，这里$F[1,3] = max(max(A[0],A[1],A[2],A[3]),max(A[4],A[5],A[6],A[7]))$的值，但是我们根本没有计算$max(A[0],A[1],A[2],A[3])和max(A[4],A[5],A[6],A[7])$，所以这样的方法肯定是错误的。 为了避免这样的错误，一定要好好理解这个状态转移方程所代表的含义。 （二）然后是查询。 假如我们需要查询的区间为(i,j)，那么我们需要找到覆盖这个闭区间(左边界取i，右边界取j)的最小幂（可以重复，比如查询5，6，7，8，9，我们可以查询5678和6789）。 因为这个区间的长度为$j - i + 1$,所以我们可以取$k=log2( j - i + 1)$，则有：RMQ(A, i, j)=max{F[i , k], F[ $j - 2 ^ k + 1$, k]}。 举例说明，要求区间[2，8]的最大值，$k = log2（8 - 2 + 1）= 2$，即求max(F[2, 2]，F[$8 - 2 ^ 2 + 1$, 2]) = max(F[2, 2]，F[5, 2])；","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"最小生成树（prime算法、kruskal算法） 最短路径算法（Floyd,bellmen-ford,dijkstra,Spfa)","slug":"最小生成树（prime算法、kruskal算法）-最短路径算法（floydbellmen-fo","date":"2020-04-10T09:40:59.000Z","updated":"2022-04-13T13:31:49.025Z","comments":true,"path":"2020/04/10/最小生成树（prime算法、kruskal算法）-最短路径算法（floydbellmen-fo/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%EF%BC%88prime%E7%AE%97%E6%B3%95%E3%80%81kruskal%E7%AE%97%E6%B3%95%EF%BC%89-%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%EF%BC%88floydbellmen-fo/","excerpt":"","text":"1 最小生成树生成树的概念：联通图G的一个子图如果是一棵包含G的所有顶点的树，则该子图称为G的生成树 生成树是联通图的极小连通子图。所谓极小是指：若在树中任意增加一条边，则 将出现一个回路；若去掉一条边，将会使之编程非连通图。生成树各边的权值总和称为生成素的权。权最小的生成树称为最小生成树，常用的算法有prime算法和kruskal算法。举例：几个村庄都不相通, 要修路, 怎么修, 这个花的钱最少, 这种最优选择就是最小生成树 1.1例题为了便于理解，所以有了这个例题 题目链接 Problem Description 省政府“畅通工程”的目标是使全省任何两个村庄间都可以实现公路交通（但不一定有直接的公路相连，只要能间接通过公路可达即可）。经过调查评估，得到的统计表中列出了有可能建设公路的若干条道路的成本。现请你编写程序，计算出全省畅通需要的最低成本。 Input 测试输入包含若干测试用例。每个测试用例的第1行给出评估的道路条数 N、村庄数目M ( &lt; 100 )；随后的 N行对应村庄间道路的成本，每行给出一对正整数，分别是两个村庄的编号，以及此两村庄间道路的成本（也是正整数）。为简单起见，村庄从1到M编号。当N为0时，全部输入结束，相应的结果不要输出。 Output 对每个测试用例，在1行里输出全省畅通需要的最低成本。若统计数据不足以保证畅通，则输出“?”。 Sample Input 3 31 2 11 3 22 3 41 32 3 20 100 Sample Output 3? 1.2 Prime算法Prime算法的基本思想 清空生成树，任取一个顶点加入生成树。 在那些一个端点在生成树里，另一个端点不在生成树里的边中，选取一条权最小的边，将它和另一个端点加进生成树。 重复步骤2，直到所有的顶点都进入了生成树为止，此时的生成树就是最小生成树。 结合上面的例题来介绍具体算法实现AC代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include #include #include #include #include #include #include #define mem(a, b) memset(a, b, sizeof(a))#define PI 3.1415926535using namespace std;typedef long long ll;const int INF = 0x3f3f3f3f; const long long LLINF = 0x3f3f3f3f3f3f3f3f;const int MAXn = 100;const int mod = 1;int map[MAXn][MAXn]; //存图 map[i][j]==p 表示从i到j的距离为pbool Is_Used[MAXn]; //Is-Used[i]=true 表示点i已经在最小生成树中int Low_Cost[MAXn]; //Low_Cost[i] 表示最小生成树中的所有点到i点的距离的最小值int main()&#123; int n, m; while (cin &gt;&gt; n &gt;&gt; m) &#123; if (n == 0) break; mem(map,INF); int i, a, b, c, ans = 0, ok = 1; for (i = 1; i &lt;= n; i++) &#123; scanf(&quot;%d%d%d&quot;, &amp;a, &amp;b, &amp;c); map[a][b]=map[b][a] =c; &#125; mem(Is_Used, 0); //将Is_Used数组清零 Is_Used[1] = true; // 将V1（第一个点）存入树中作为起点 for (i = 1; i &lt;= m; i++)//因为最小生成树中只有V1 所以Low_Cost[i]=map[1][i] Low_Cost[i] = map[1][i]; for (i = 2; i &lt;= m; i++) &#123;//遍历其他的点（不在最小生成树中的点 int Min = INF, New_Point = -1; for (int j = 1; j &lt;= m; j++) &#123;//找不在最小生成树中的点到最小生成树中的点的最小距离，存为新的点 if (!Is_Used[j] &amp;&amp; Min &gt; Low_Cost[j]) &#123; Min = Low_Cost[j]; New_Point = j; &#125; &#125; Is_Used[New_Point] = true;//将新的点入树 ans += Min; for (int j = 1; j &lt;= m; j++) &#123;//更新不在最小生成树中的点到最小生成树中的点的最小距离 if (!Is_Used[j]) Low_Cost[j] = min(Low_Cost[j], map[New_Point][j]); &#125; &#125; for (i = 1; i &lt;= m; i++) &#123;//判断是否所有点都已入树 if (!Is_Used[i]) &#123; ok = 0; break; &#125; &#125; if (ok) printf(&quot;%d\\n&quot;,ans); else printf(&quot;?\\n&quot;); &#125; return 0;&#125; 1.3 Kruskal算法Kruskal算法 ：构造一个只含n个顶点，而边集为空的子图，若将该子图中各个顶点看成是各棵树的根节点，则它是一个含有n棵树的森林 。之后，从网的边集中选取一条权值最小的边，若该边的两个顶点分属不同的树 ，则将其加入子图，也就是这两个顶点分别所在的 两棵树合成一棵树；反之，若该边的两个顶点已落在同一棵树上，则不可取，而应该取下一条权值最小的边再试之。依次类推，直至森林只有一棵树。kruskal算法能够在并查集的基础很快的实现。并查集参考： 并查集 结合上面的例题来介绍具体算法实现AC代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#include #include #include #include #include #include #include #define mem(a, b) memset(a, b, sizeof(a))#define PI 3.1415926535using namespace std;typedef long long ll;const int INF = 0x3f3f3f3f;const long long LLINF = 0x3f3f3f3f3f3f3f3f;const int MAXn = 105;const int mod = 1;struct egde&#123; //u到v的距离为w int u,v; int w;&#125;s[MAXn*MAXn];int pre[MAXn];//并查集数组bool cmp(egde a,egde b)&#123; return a.w&lt;b.w;&#125;int Find(int a)&#123; int root=a; int tem; while(root!=pre[root]) root=pre[root]; //找老大（祖先 while(a!=root) &#123; //路径压缩 tem=a; a=pre[a]; pre[a]=root; &#125; return root;&#125;void kruskal(int n,int m)&#123; int ans=0,i,ok=1; for(i=0;i&lt;n;i++) &#123; //从权最小的边开始加进图中 int x=Find(s[i].u); int y=Find(s[i].v); if(x!=y) &#123; if(x&gt;y) swap(x,y); pre[x]=y; ans+=s[i].w; &#125; &#125; for(i=1;i&lt;=m;i++) &#123;//判断是否所有点都已入树 if(Find(i)!=Find(1)) &#123; ok=0; break; &#125; &#125; if(ok) printf(&quot;%d\\n&quot;,ans); else printf(&quot;?\\n&quot;);&#125;int main()&#123; int n,m; while (~scanf(&quot;%d%d&quot;,&amp;n,&amp;m)) &#123; if (n == 0) break; mem(s,0); for(int i=0;i&lt;=MAXn;i++) pre[i]=i; //初始化 for(int i=0;i&lt;n;i++) &#123; scanf(&quot;%d%d%d&quot;,&amp;s[i].u,&amp;s[i].v,&amp;s[i].w); &#125; sort(s,s+n,cmp); //对边按权从小到大排序 kruskal(n,m); &#125; return 0;&#125; 2 最短路径最短路径问题旨在寻找图中两节点之间的最短路径 2.1 例题题目链接 Problem Description 在每年的校赛里，所有进入决赛的同学都会获得一件很漂亮的t-shirt。但是每当我们的工作人员把上百件的衣服从商店运回到赛场的时候，却是非常累的！所以现在他们想要寻找最短的从商店到赛场的路线，你可以帮助他们吗？ Input输入包括多组数据。每组数据第一行是两个整数N、M（N&lt;=100，M&lt;=10000），N表示成都的大街上有几个路口，标号为1的路口是商店所在地，标号为N的路口是赛场所在地，M则表示在成都有几条路。N=M=0表示输入结束。接下来M行，每行包括3个整数A，B，C（1&lt;=A,B&lt;=N,1&lt;=C&lt;=1000）,表示在路口A与路口B之间有一条路，我们的工作人员需要C分钟的时间走过这条路。输入保证至少存在1条商店到赛场的路线。 Output对于每组输入，输出一行，表示工作人员从商店走到赛场的最短时间 Sample Input2 1 1 2 3 3 3 1 2 5 2 3 5 3 1 2 0 0 Sample Output3 2 2.2 Floyd算法Floyd算法求多源、无负权边的最短路。用矩阵记录图。时效性较差，时间复杂度O(V^3)。 Floyd算法是解决任意两点间的最短路径的一种算法，可以正确处理有向图或负权的最短路径问题。Floyd-Warshall的原理是动态规划： 设Di,j,k为从i到j的只以(1…k)集合中的节点为中间节点的最短路径的长度。 若最短路径经过点k，则Di,j,k = Di,k,k-1 + Dk,j,k-1； 若最短路径不经过点k，则Di,j,k = Di,j,k-1。 因此，Di,j,k = min(Di,k,k-1 + Dk,j,k-1 , Di,j,k-1)。 123456789101112for(i=0;i&lt;=m;i++) for(j=0;j&lt;=n;j++) map[i][j]=INF;//初始化 for(k=1;k&lt;=n;k++)//动态规划的思想 for(i=1;i&lt;=n;i++) for(j=1;j&lt;=n;j++) &#123; if(i==j) continue; if(map[i][j]&gt;map[i][k]+map[k][j]) map[i][j]=map[i][k]+map[k][j]; &#125; 结合上面的例题来介绍具体算法实现 AC代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include #include #include #include #include #include #include #define mem(a, b) memset(a, b, sizeof(a))#define PI 3.1415926535using namespace std;typedef long long ll;const int INF = 0x3f3f3f3f;const long long LLF = 0x3f3f3f3f3f3f3f3f;const int MAXn = 105;const int mod = 1;int n, m;int w[MAXn][MAXn]; //a-&gt;b的距离void Floyd()&#123; int k, i, j; for (k = 1; k &lt;= n; k++) //中间点 for (i = 1; i &lt;= n; i++) for (j = 1; j &lt;= n; j++) w[i][j] = min(w[i][j], w[i][k] + w[k][j]);&#125;int main()&#123; while (~scanf(&quot;%d%d&quot;, &amp;n, &amp;m)) &#123; if (!n &amp;&amp; !m) break; int i, j, a, b, c; for (i = 0; i &lt;= n; i++) for (j = 0; j &lt;= n; j++) &#123; //初始化 w[i][j] = (i == j ? 0 : INF); &#125; for (i = 0; i &lt; m; i++) &#123; //输入 scanf(&quot;%d%d%d&quot;, &amp;a, &amp;b, &amp;c); w[a][b] = min(w[a][b], c); w[b][a] = w[a][b]; &#125; Floyd(); //Floyd算法求最短路径 printf(&quot;%d\\n&quot;, w[1][n]);//输出起到点n的最短路径 &#125; return 0;&#125; 2.3 Dijkstra算法Dijkstra算法求单源、无负权的最短路。时效性较好，时间复杂度为O（V* V+E）。 源点可达的话，O（V* lgV+E* lgV）=&gt;O（E* lgV）。 当是稀疏图的情况时，此时E=V* V/lgV，所以算法的时间复杂度可为O（V^2） 。若是斐波那契堆作优先队列的话，算法时间复杂度，则为O（V* lgV + E）。 算法流程：(a) 初始化：用起点v到该顶点w的直接边(弧)初始化最短路径，否则设为∞；(b) 从未求得最短路径的终点中选择路径长度最小的终点u：即求得v到u的最短路径；(c ) 修改最短路径：计算u的邻接点的最短路径，若(v,…,u)+(u,w)&lt;(v,…,w)，则以(v,…,u,w)代替。(d) 重复(b)-(c )，直到求得v到其余所有顶点的最短路径。特点：总是按照从小到大的顺序求得最短路径。 假设一共有N个节点，出发结点为s，需要一个一维数组vis[N]来记录前一个节点序号，一个一维数组dis[N]来记录从原点到当前节点最短路径（初始值为s到Vi的边的权值，没有则为+∞），一个二维数组map[N][N]来记录各点之间边的权重，按以上流程更新map[N]和dis[N]。 123456789101112131415161718192021222324252627void dijs(int v)//v为原点 &#123; int i,j,k; for(i=1;i&lt;=n;i++) dis[i]=map[v][i];//初始化 memset(vis,0,sizeof(vis)); vis[v]=1; for(i=2;i&lt;=n;i++) &#123; int min=INF; k=v; for(j=1;j&lt;=n;j++) &#123; if(!vis[j]&amp;&amp;min&gt;dis[j]) &#123; k=j; min=dis[j];//在dis中找出最小值 &#125; &#125; vis[k]=1;//使k为已生成终点 for(j=1;j&lt;=n;j++)//修改dis &#123; if(dis[j]&gt;dis[k]+map[k][j]) dis[j]=dis[k]+map[k][j]; &#125; &#125; &#125; 结合上面的例题来介绍具体算法实现AC代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include #include #include #include #include #include #include #define mem(a, b) memset(a, b, sizeof(a))#define PI 3.1415926535using namespace std;typedef long long ll;const int INF = 0x3f3f3f3f;const long long LLINF = 0x3f3f3f3f3f3f3f3f;const int MAXn = 105;const int mod = 1;int n, m;int w[MAXn][MAXn]; //a-&gt;b的距离bool v[MAXn]; //标记数组int d[MAXn]; //起点到点i的最小距离void Dijkstra(int s)//起点是s&#123; int i, j; for (i = 1; i &lt;= n; i++) d[i] = w[s][i]; //存储距离 mem(v, 0); //标记数组清零 v[s]=true; //标记 for (i = 1; i &lt; n; i++) //遍历n-1遍（其他的点 &#123; int m = -1, Min = INF; for (j = 1; j &lt;= n; j++) &#123; //寻找到当前点距离最近的点 if (!v[j] &amp;&amp; d[j] &lt; Min) Min = d[m = j]; &#125; v[m]=true; //将刚找到的点标记 for (j = 1; j &lt;= n; j++) &#123; //更新最小距离 d[j] = min(d[j], d[m] + w[m][j]); &#125; &#125;&#125;int main()&#123; while (~scanf(&quot;%d%d&quot;, &amp;n, &amp;m)) &#123; if (!n &amp;&amp; !m) break; int i, j, a, b, c; for (i = 0; i &lt;= n; i++) for (j = 0; j &lt;= n; j++) &#123; //初始化 w[i][j] = (i == j ? 0 : INF); &#125; for (i = 0; i &lt; m; i++) &#123; scanf(&quot;%d%d%d&quot;, &amp;a, &amp;b, &amp;c); w[a][b] = min(w[a][b], c); w[b][a] = w[a][b]; &#125; Dijkstra(1); //Dijkstra算法求最短路径 printf(&quot;%d\\n&quot;, d[n]);//输出起点到点n的最小距离 &#125; return 0;&#125; 2.4 Bellman-Ford算法适用条件&amp;范围： 单源最短路径(从源点s到其它所有顶点v); 有向图&amp;无向图(无向图可以看作(u,v),(v,u)同属于边集E的有向图); 边权可正可负(如有负权回路输出错误提示); 差分约束系统; Bellman－Ford算法可以大致分为三个部分 第一，初始化所有点。每一个点保存一个值，表示从原点到达这个点的距离，将原点的值设为0，其它的点的值设为无穷大（表示不可达）。 第二，进行循环，循环下标为从1到n－1（n等于图中点的个数）。在循环内部，遍历所有的边，进行松弛计算。 第三，遍历途中所有的边（edge（u，v）），判断是否存在这样情况: d（v） &gt; d (u) + w(u,v)，如果存在则返回false，表示途中存在从源点可达的权为负的回路。 之所以需要第三部分的原因，是因为，如果存在从源点可达的权为负的回路。则 应为无法收敛而导致不能求出最短路径。 1234567891011121314151617181920bool bellman() &#123; bool flag ; for(int i=0;i&lt;n-1;i++) &#123; flag=false; for(int j=0;j&lt;all;j++) //穷举每条边 if(dis[t[j].to]&gt;dis[t[j].from]+t[j].vis) //松弛判断 &#123; dis[t[j].to]=dis[t[j].from]+t[j].vis; //松弛操作 flag=true; &#125; if(!flag) break; &#125; for(int k=0;k&lt;all;k++) //对所有边进行一次遍历，判断是否有负回路 if(dis[t[k].to]&gt;dis[t[k].from]+t[k].vis) return true; return false; &#125; 2.5 SPFA算法SPFA算法采用一系列的松弛操作以得到从某一个节点出发到达图中其它所有节点的最短路径。所不同的是，SPFA算法通过维护一个队列，使得一个节点的当前最短路径被更新之后没有必要立刻去更新其他的节点，从而大大减少了重复的操作次数。SPFA算法可以用于存在负数边权的图SPFA算法是Bellman-Ford算法的一种优化，大大降低了时间复杂度。 结合上面的例题来介绍具体算法实现AC代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;#define mem(a, b) memset(a, b, sizeof(a))#define PI 3.1415926535using namespace std;typedef long long ll;const int INF = 0x3f3f3f3f;const long long LLF = 0x3f3f3f3f3f3f3f3f;const int MAXn = 105;const int mod = 1;int n, m;int w[MAXn][MAXn]; //a-&gt;b的距离bool v[MAXn]; //标记int d[MAXn]; //d[i] 起始位置到i的最小距离void Spfa(int s)//起始位置&#123; int i, j; mem(v, 0); for(i=0;i&lt;=n;i++) d[i]=INF; //初始化 d[s]=0; // 重要 queue&lt;int&gt; q; q.push(s); //入队 v[s]=true; //标记 while(!q.empty()) &#123; int now=q.front(); q.pop(); v[now]=false; //重要 for(i=1;i&lt;=n;i++) &#123; if(d[i]&gt;d[now]+w[now][i]) &#123; //更新最短距离 d[i]=d[now]+w[now][i]; if(v[i]==0) &#123; v[i]=true; q.push(i); &#125; &#125; &#125; &#125;&#125;int main()&#123; while (~scanf(&quot;%d%d&quot;, &amp;n, &amp;m)) &#123; if (!n &amp;&amp; !m) break; int i, j, a, b, c; for (i = 0; i &lt;= n; i++) for (j = 0; j &lt;= n; j++) &#123; //初始化 w[i][j] = (i == j ? 0 : INF); &#125; for (i = 0; i &lt; m; i++) &#123; //输入 scanf(&quot;%d%d%d&quot;, &amp;a, &amp;b, &amp;c); w[a][b] = min(w[a][b], c); w[b][a] = w[a][b]; &#125; Spfa(1);//Spfa算法求最短路径 printf(&quot;%d\\n&quot;, d[n]); //输出起到点n的最短路径 &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"},{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"MarkDown-改变字体颜色大小","slug":"markdown-改变字体颜色大小","date":"2020-04-10T09:32:49.000Z","updated":"2022-04-13T13:31:48.616Z","comments":true,"path":"2020/04/10/markdown-改变字体颜色大小/","link":"","permalink":"https://tang7o.cn/2020/04/10/markdown-%E6%94%B9%E5%8F%98%E5%AD%97%E4%BD%93%E9%A2%9C%E8%89%B2%E5%A4%A7%E5%B0%8F/","excerpt":"","text":"转自 testcs_dn(微wx笑) 博文 –&gt;传送门 123456&lt;font face=&quot;黑体&quot;&gt;我是黑体字&lt;/font&gt;&lt;font face=&quot;微软雅黑&quot;&gt;我是微软雅黑&lt;/font&gt;&lt;font face=&quot;STCAIYUN&quot;&gt;我是华文彩云&lt;/font&gt;&lt;font color=#0099ff size=7 face=&quot;黑体&quot;&gt;color=#0099ff size=72 face=&quot;黑体&quot;&lt;/font&gt;&lt;font color=#00ffff size=72&gt;color=#00ffff&lt;/font&gt;&lt;font color=gray size=72&gt;color=gray&lt;/font&gt; 呈现效果 我是黑体字 我是微软雅黑 我是华文彩云 color=#0099ff size=72 face=\"黑体\" color=#00ffff color=gray 转载过程中发现了一个问题…表格怎么上背景色←_←。查了查，可以用内嵌的 html 实现（之前画表格，我可都是规规矩矩按 帮助说明 的样式画的） –&gt;这篇文章里看到 代码123456789101112131415&lt;table&gt;&lt;tbody&gt; &lt;tr&gt; &lt;th&gt;方法说明&lt;/th&gt;&lt;th&gt;颜色名称&lt;/th&gt;&lt;th&gt;颜色&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;font color=&quot;Hotpink&quot;&gt;此处实现方法利用 CSDN-markdown 内嵌 html 语言的优势&lt;/font&gt;&lt;/td&gt; &lt;td&gt;&lt;font color=&quot;Hotpink&quot;&gt;Hotpink&lt;/font&gt;&lt;/td&gt; &lt;td bgcolor=&quot;Hotpink&quot;&gt;rgb(240, 248, 255)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;font color=&quot;Pink&quot;&gt;借助 table, tr, td 等表格标签的 bgcolor 属性实现背景色设置&lt;/font&gt;&lt;/td&gt; &lt;td&gt;&lt;font color=&quot;pink&quot;&gt;AntiqueWhite&lt;/font&gt;&lt;/td&gt; &lt;td bgcolor=&quot;Pink&quot;&gt;rgb(255, 192, 203)&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; 呈现效果 方法说明颜色名称颜色 此处实现方法利用 CSDN-markdown 内嵌 html 语言的优势Hotpinkrgb(240, 248, 255) 借助 table, tr, td 等表格标签的 bgcolor 属性实现背景色设置AntiqueWhitergb(255, 192, 203) 颜色名十六进制颜色值颜色AliceBlue#F0F8FFrgb(240, 248, 255)AntiqueWhite#FAEBD7rgb(250, 235, 215)Aqua#00FFFFrgb(0, 255, 255)Aquamarine#7FFFD4rgb(127, 255, 212)Azure#F0FFFFrgb(240, 255, 255)Beige#F5F5DCrgb(245, 245, 220)Bisque#FFE4C4rgb(255, 228, 196)Black#000000rgb(0, 0, 0)BlanchedAlmond#FFEBCDrgb(255, 235, 205)Blue#0000FFrgb(0, 0, 255)BlueViolet#8A2BE2rgb(138, 43, 226)Brown#A52A2Argb(165, 42, 42)BurlyWood#DEB887rgb(222, 184, 135)CadetBlue#5F9EA0rgb(95, 158, 160)Chartreuse#7FFF00rgb(127, 255, 0)Chocolate#D2691Ergb(210, 105, 30)Coral#FF7F50rgb(255, 127, 80)CornflowerBlue#6495EDrgb(100, 149, 237)Cornsilk#FFF8DCrgb(255, 248, 220)Crimson#DC143Crgb(220, 20, 60)Cyan#00FFFFrgb(0, 255, 255)DarkBlue#00008Brgb(0, 0, 139)DarkCyan#008B8Brgb(0, 139, 139)DarkGoldenRod#B8860Brgb(184, 134, 11)DarkGray#A9A9A9rgb(169, 169, 169)DarkGreen#006400rgb(0, 100, 0)DarkKhaki#BDB76Brgb(189, 183, 107)DarkMagenta#8B008Brgb(139, 0, 139)DarkOliveGreen#556B2Frgb(85, 107, 47)Darkorange#FF8C00rgb(255, 140, 0)DarkOrchid#9932CCrgb(153, 50, 204)DarkRed#8B0000rgb(139, 0, 0)DarkSalmon#E9967Argb(233, 150, 122)DarkSeaGreen#8FBC8Frgb(143, 188, 143)DarkSlateBlue#483D8Brgb(72, 61, 139)DarkSlateGray#2F4F4Frgb(47, 79, 79)DarkTurquoise#00CED1rgb(0, 206, 209)DarkViolet#9400D3rgb(148, 0, 211)DeepPink#FF1493rgb(255, 20, 147)DeepSkyBlue#00BFFFrgb(0, 191, 255)DimGray#696969rgb(105, 105, 105)DodgerBlue#1E90FFrgb(30, 144, 255)Feldspar#D19275rgb(209, 146, 117)FireBrick#B22222rgb(178, 34, 34)FloralWhite#FFFAF0rgb(255, 250, 240)ForestGreen#228B22rgb(34, 139, 34)Fuchsia#FF00FFrgb(255, 0, 255)Gainsboro#DCDCDCrgb(220, 220, 220)GhostWhite#F8F8FFrgb(248, 248, 255)Gold#FFD700rgb(255, 215, 0)GoldenRod#DAA520rgb(218, 165, 32)Gray#808080rgb(128, 128, 128)Green#008000rgb(0, 128, 0)GreenYellow#ADFF2Frgb(173, 255, 47)HoneyDew#F0FFF0rgb(240, 255, 240)HotPink#FF69B4rgb(255, 105, 180)IndianRed#CD5C5Crgb(205, 92, 92)Indigo#4B0082rgb(75, 0, 130)Ivory#FFFFF0rgb(255, 255, 240)Khaki#F0E68Crgb(240, 230, 140)Lavender#E6E6FArgb(230, 230, 250)LavenderBlush#FFF0F5rgb(255, 240, 245)LawnGreen#7CFC00rgb(124, 252, 0)LemonChiffon#FFFACDrgb(255, 250, 205)LightBlue#ADD8E6rgb(173, 216, 230)LightCoral#F08080rgb(240, 128, 128)LightCyan#E0FFFFrgb(224, 255, 255)LightGoldenRodYellow#FAFAD2rgb(250, 250, 210)LightGrey#D3D3D3rgb(211, 211, 211)LightGreen#90EE90rgb(144, 238, 144)LightPink#FFB6C1rgb(255, 182, 193)LightSalmon#FFA07Argb(255, 160, 122)LightSeaGreen#20B2AArgb(32, 178, 170)LightSkyBlue#87CEFArgb(135, 206, 250)LightSlateBlue#8470FFrgb(132, 112, 255)LightSlateGray#778899rgb(119, 136, 153)LightSteelBlue#B0C4DErgb(176, 196, 222)LightYellow#FFFFE0rgb(255, 255, 224)Lime#00FF00rgb(0, 255, 0)LimeGreen#32CD32rgb(50, 205, 50)Linen#FAF0E6rgb(250, 240, 230)Magenta#FF00FFrgb(255, 0, 255)Maroon#800000rgb(128, 0, 0)MediumAquaMarine#66CDAArgb(102, 205, 170)MediumBlue#0000CDrgb(0, 0, 205)MediumOrchid#BA55D3rgb(186, 85, 211)MediumPurple#9370D8rgb(147, 112, 216)MediumSeaGreen#3CB371rgb(60, 179, 113)MediumSlateBlue#7B68EErgb(123, 104, 238)MediumSpringGreen#00FA9Argb(0, 250, 154)MediumTurquoise#48D1CCrgb(72, 209, 204)MediumVioletRed#C71585rgb(199, 21, 133)MidnightBlue#191970rgb(25, 25, 112)MintCream#F5FFFArgb(245, 255, 250)MistyRose#FFE4E1rgb(255, 228, 225)Moccasin#FFE4B5rgb(255, 228, 181)NavajoWhite#FFDEADrgb(255, 222, 173)Navy#000080rgb(0, 0, 128)OldLace#FDF5E6rgb(253, 245, 230)Olive#808000rgb(128, 128, 0)OliveDrab#6B8E23rgb(107, 142, 35)Orange#FFA500rgb(255, 165, 0)OrangeRed#FF4500rgb(255, 69, 0)Orchid#DA70D6rgb(218, 112, 214)PaleGoldenRod#EEE8AArgb(238, 232, 170)PaleGreen#98FB98rgb(152, 251, 152)PaleTurquoise#AFEEEErgb(175, 238, 238)PaleVioletRed#D87093rgb(216, 112, 147)PapayaWhip#FFEFD5rgb(255, 239, 213)PeachPuff#FFDAB9rgb(255, 218, 185)Peru#CD853Frgb(205, 133, 63)Pink#FFC0CBrgb(255, 192, 203)Plum#DDA0DDrgb(221, 160, 221)PowderBlue#B0E0E6rgb(176, 224, 230)Purple#800080rgb(128, 0, 128)Red#FF0000rgb(255, 0, 0)RosyBrown#BC8F8Frgb(188, 143, 143)RoyalBlue#4169E1rgb(65, 105, 225)SaddleBrown#8B4513rgb(139, 69, 19)Salmon#FA8072rgb(250, 128, 114)SandyBrown#F4A460rgb(244, 164, 96)SeaGreen#2E8B57rgb(46, 139, 87)SeaShell#FFF5EErgb(255, 245, 238)Sienna#A0522Drgb(160, 82, 45)Silver#C0C0C0rgb(192, 192, 192)SkyBlue#87CEEBrgb(135, 206, 235)SlateBlue#6A5ACDrgb(106, 90, 205)SlateGray#708090rgb(112, 128, 144)Snow#FFFAFArgb(255, 250, 250)SpringGreen#00FF7Frgb(0, 255, 127)SteelBlue#4682B4rgb(70, 130, 180)Tan#D2B48Crgb(210, 180, 140)Teal#008080rgb(0, 128, 128)Thistle#D8BFD8rgb(216, 191, 216)Tomato#FF6347rgb(255, 99, 71)Turquoise#40E0D0rgb(64, 224, 208)Violet#EE82EErgb(238, 130, 238)VioletRed#D02090rgb(208, 32, 144)Wheat#F5DEB3rgb(245, 222, 179)White#FFFFFFrgb(255, 255, 255)WhiteSmoke#F5F5F5rgb(245, 245, 245)Yellow#FFFF00rgb(255, 255, 0)YellowGreen#9ACD32rgb(154, 205, 50)","categories":[{"name":"MarkDown","slug":"MarkDown","permalink":"https://tang7o.cn/categories/MarkDown/"}],"tags":[{"name":"MarkDwon","slug":"MarkDwon","permalink":"https://tang7o.cn/tags/MarkDwon/"}]},{"title":"2019-4-13 2050万人编程竞赛 1003----分宿舍","slug":"2019-4-13-2050万人编程竞赛-1003-分宿舍","date":"2020-04-10T09:32:40.000Z","updated":"2022-04-13T13:31:47.887Z","comments":true,"path":"2020/04/10/2019-4-13-2050万人编程竞赛-1003-分宿舍/","link":"","permalink":"https://tang7o.cn/2020/04/10/2019-4-13-2050%E4%B8%87%E4%BA%BA%E7%BC%96%E7%A8%8B%E7%AB%9E%E8%B5%9B-1003-%E5%88%86%E5%AE%BF%E8%88%8D/","excerpt":"","text":"Description“那天TA说TA要来，于是我就来啦。那天我说我要来，于是你就来啦。TA看到了什么？你又看到了什么？我看到你们在一起，我是真的很happy：）太阳在哪里啊？就在早上七八点。太阳在哪里啊？就在云的栖息地！”——2050主题曲 2050的线下活动吸引了很多心怀梦想的年轻人。 小伙们打算组团去参加。他们一共有 n+m+2k 个人，包括 n+k 个男生，m+k 个女生，其中 k 对男女生为异性情侣，现在他们要找房间住。房间有三种类型，双人间 a 元一间，三人间 b 元一间，这两种只能同性一起住。情侣间能住一对异性情侣，一间 c 元。除了情侣间以外，其他房间都可以不住满。 求最少花多少钱，能让小伙伴们都有地方住。 Input第一行一个整数 T (1≤T≤50) 表示数据组数。 接下来 T 组数据，每组数据一行 6 个整数 n,m,k,a,b,c，其中 0≤n,m,k≤103,0≤a,b,c≤109。 Output对于每组数据输出一行一个数，表示所有人住下来所需要的最小花费。 Sample Input 23 0 1 1 3 33 3 2 1 6 2 Sample Output 36 思路:先不考虑情侣房,开一个数组f[i]表示i个人住双人间或三人间的最少花费,枚举f[i] （0&lt;=i&lt;=N+M+2*K+10 ）,然后再考虑住情侣房的情况,枚举i （0&lt;=i&lt;=k）对情侣住情侣房,此时花费为: i *c+f[n+k-i]+f[m+k-i],取最小值输出即可。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;queue&gt; #include &lt;cmath&gt;#include &lt;cstdio&gt;#define mem(a, b) memset(a, b, sizeof(a))#define PI 3.1415926535using namespace std;typedef long long ll;const int MAXn = 4e3 + 10;ll f[MAXn];int main()&#123; int T; scanf(&quot;%d&quot;, &amp;T); while (T--) &#123; int i, m, n, k, a, b, c; scanf(&quot;%d%d%d%d%d%d&quot;, &amp;n, &amp;m, &amp;k, &amp;a, &amp;b, &amp;c); for ( i = 0; i &lt; MAXn; i++) &#123; f[i] = 0x3f3f3f3f3f3f3f3f; &#125; f[0]=0; for(i=2;i&lt;n+2*k+m+15;i++) &#123;//住双人间 f[i]=min(f[i],f[i-2]+a); &#125;//类似背包问题，物品体积为2 费用为a for(i=3;i&lt;m+2*k+n+15;i++) &#123;//三人间 f[i]=min(f[i],f[i-3]+b); &#125; for(i=m+n+2*k+14;i&gt;=0;i--) &#123;//考虑没住满的情况 f[i]=min(f[i],f[i+1]); &#125; ll ans=0x3f3f3f3f3f3f3f3f; for(i=0;i&lt;=k;i++) &#123; ans=min(ans,i*c+f[n+k-i]+f[m+k-i]);//枚举情侣房 &#125; printf(&quot;%lld\\n&quot;,ans); &#125;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"题目","slug":"ACM/题目","permalink":"https://tang7o.cn/categories/ACM/%E9%A2%98%E7%9B%AE/"}],"tags":[{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"}]},{"title":"new和malloc的区别","slug":"new和malloc的区别","date":"2020-04-10T09:31:02.000Z","updated":"2022-04-13T13:31:48.630Z","comments":true,"path":"2020/04/10/new和malloc的区别/","link":"","permalink":"https://tang7o.cn/2020/04/10/new%E5%92%8Cmalloc%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"1 . malloc()函数1.1 malloc的全称是memory allocation，中文叫动态内存分配。原型：extern void *malloc(unsigned int num_bytes);说明：分配长度为num_bytes字节的内存块。如果分配成功则返回指向被分配内存的指针，分配失败返回空指针NULL。当内存不再使用时，应使用free()函数将内存块释放。 1.2 void malloc(int size);说明：malloc 向系统申请分配指定size个字节的内存空间，返回类型是 void 类型。void* 表示未确定类型的指针。C,C++规定，void* 类型可以强制转换为任何其它类型的指针。 备注：void* 表示未确定类型的指针，更明确的说是指申请内存空间时还不知道用户是用这段空间来存储什么类型的数据（比如是char还是int或者…） 1.3 freevoid free(void *FirstByte)： 该函数是将之前用malloc分配的空间还给程序或者是操作系统，也就是释放了这块内存，让它重新得到自由。 1.4注意事项1）申请了内存空间后，必须检查是否分配成功。2）当不需要再使用申请的内存时，记得释放；释放后应该把指向这块内存的指针指向NULL，防止程序后面不小心使用了它。3）这两个函数应该是配对。如果申请后不释放就是内存泄露；如果无故释放那就是什么也没有做。释放只能一次，如果释放两次及两次以上会出现错误（释放空指针例外，释放空指针其实也等于啥也没做，所以释放空指针释放多少次都没有问题）。4）虽然malloc()函数的类型是(void *),任何类型的指针都可以转换成(void *),但是最好还是在前面进行强制类型转换，因为这样可以躲过一些编译器的检查。 1.5 malloc()到底从哪里得到了内存空间？答案是从堆里面获得空间。也就是说函数返回的指针是指向堆里面的一块内存。操作系统中有一个记录空闲内存地址的链表。当操作系统收到程序的申请时，就会遍历该链表，然后就寻找第一个空间大于所申请空间的堆结点，然后就将该结点从空闲结点链表中删除，并将该结点的空间分配给程序。 2 . new运算符2.1 C++中，用new和delete动态创建和释放数组或单个对象。 动态创建对象时，只需指定其数据类型，而不必为该对象命名，new表达式返回指向该新创建对象的指针，我们可以通过指针来访问此对象。int *pi=new int;这个new表达式在堆区中分配创建了一个整型对象，并返回此对象的地址，并用该地址初始化指针pi 。 2.2 动态创建对象的初始化 动态创建的对象可以用初始化变量的方式初始化。int *pi=new int(100); //指针pi所指向的对象初始化为100string *ps=new string(10,’9’);//*ps 为“9999999999” 如果不提供显示初始化，对于类类型，用该类的默认构造函数初始化；而内置类型的对象则无初始化。也可以对动态创建的对象做值初始化：int *pi=new int( );//初始化为0int *pi=new int;//pi 指向一个没有初始化的intstring *ps=new string( );//初始化为空字符串 （对于提供了默认构造函数的类类型，没有必要对其对象进行值初始化） 2.3 撤销动态创建的对象 delete表达式释放指针指向的地址空间。delete pi ;// 释放单个对象delete [ ]pi;//释放数组如果指针指向的不是new分配的内存地址，则使用delete是不合法的。 2.4 在delete之后，重设指针的值 delete p; //执行完该语句后，p变成了不确定的指针，在很多机器上，尽管p值没有明确定义，但仍然存放了它之前所指对象的地址，然后p所指向的内存已经被释放了，所以p不再有效。此时，该指针变成了悬垂指针（悬垂指针指向曾经存放对象的内存，但该对象已经不存在了）。悬垂指针往往导致程序错误，而且很难检测出来。一旦删除了指针所指的对象，立即将指针置为0，这样就非常清楚的指明指针不再指向任何对象。（零值指针：int *ip=0;） 2.5 区分零值指针和NULL指针 零值指针，是值是0的指针，可以是任何一种指针类型，可以是通用变体类型void也可以是char，int*等等。空指针，其实空指针只是一种编程概念，就如一个容器可能有空和非空两种基本状态，而在非空时可能里面存储了一个数值是0，因此空指针是人为认为的指针不提供任何地址讯息。参考：http://www.cnblogs.com/fly1988happy/archive/2012/04/16/2452021.html 2.6 new分配失败时，返回什么？ 1993年前，c++一直要求在内存分配失败时operator new要返回0，现在则是要求operator new抛出std::bad_alloc异常。很多c++程序是在编译器开始支持新规范前写的。c++标准委员会不想放弃那些已有的遵循返回0规范的代码，所以他们提供了另外形式的operator new(以及operator new[])以继续提供返回0功能。这些形式被称为“无抛出”，因为他们没用过一个throw，而是在使用new的入口点采用了nothrow对象:class widget { … }; widget *pw1 = new widget;// 分配失败抛出std::bad_alloc if (pw1 == 0) … // 这个检查一定失败 widget *pw2 = new (nothrow) widget; // 若分配失败返回0 if (pw2 == 0) … // 这个检查可能会成功 3 . malloc和new的区别3.1 new 返回指定类型的指针，并且可以自动计算所需要大小。比如： int p; p = new int; //返回类型为int 类型(整数型指针)，分配大小为 sizeof(int); 或： int* parr; parr = new int [100]; //返回类型为 int* 类型(整数型指针)，分配大小为 sizeof(int) * 100; 而 malloc 则必须要由我们计算字节数，并且在返回后强行转换为实际类型的指针。 int* p; p = (int *) malloc (sizeof(int)*128);//分配128个（可根据实际需要替换该数值）整型存储单元，并将这128个连续的整型存储单元的首地址存储到指针变量p中double *pd=(double *) malloc (sizeof(double)*12);//分配12个double型存储单元，并将首地址存储到指针变量pd中 3.2 malloc 只管分配内存，并不能对所得的内存进行初始化，所以得到的一片新内存中，其值将是随机的。除了分配及最后释放的方法不一样以外，通过malloc或new得到指针，在其它操作上保持一致。 4.有了malloc/free为什么还要new/delete？ malloc与free是C++/C语言的标准库函数，new/delete是C++的运算符。它们都可用于申请动态内存和释放内存。 对于非内部数据类型的对象而言，光用maloc/free无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于malloc/free是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于malloc/free。因此C++语言需要一个能完成动态内存分配和初始化工作的运算符new，以及一个能完成清理与释放内存工作的运算符delete。注意new/delete不是库函数。我们不要企图用malloc/free来完成动态对象的内存管理，应该用new/delete。由于内部数据类型的“对象”没有构造与析构的过程，对它们而言malloc/free和new/delete是等价的。 既然new/delete的功能完全覆盖了malloc/free，为什么C++不把malloc/free淘汰出局呢？这是因为C++程序经常要调用C函数，而C程序只能用malloc/free管理动态内存。如果用free释放“new创建的动态对象”，那么该对象因无法执行析构函数而可能导致程序出错。如果用delete释放“malloc申请的动态内存”，结果也会导致程序出错，但是该程序的可读性很差。所以new/delete必须配对使用，malloc/free也一样。","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"}],"tags":[{"name":"知识","slug":"知识","permalink":"https://tang7o.cn/tags/%E7%9F%A5%E8%AF%86/"},{"name":"C++","slug":"C","permalink":"https://tang7o.cn/tags/C/"}]},{"title":"ACM-ICPC Live Archive:6184 --- One-Dimensional Cellular Automaton（矩阵快速幂）","slug":"acm-icpc-live-archive6184-one-dimensional-cellular-automaton（矩阵快速幂）","date":"2020-04-10T09:28:20.000Z","updated":"2022-04-13T13:31:48.460Z","comments":true,"path":"2020/04/10/acm-icpc-live-archive6184-one-dimensional-cellular-automaton（矩阵快速幂）/","link":"","permalink":"https://tang7o.cn/2020/04/10/acm-icpc-live-archive6184-one-dimensional-cellular-automaton%EF%BC%88%E7%9F%A9%E9%98%B5%E5%BF%AB%E9%80%9F%E5%B9%82%EF%BC%89/","excerpt":"","text":"思路：如果将题目中原先的序列，（假设n为5）我们可以通过一个构造转换矩阵来实现对原先序列的一个转换，转换如下： \\begin{Bmatrix} S(0,T-1) \\\\ S(1,T-1) \\\\ S(2,T-1) \\\\ S(3,T-1) \\\\ S(4,T-1) \\\\ \\end{Bmatrix} * \\begin{Bmatrix} B & C & 0 & 0 & 0 \\\\ A & B & C & 0 & 0 \\\\ 0 & A & B & C & 0 \\\\ 0 & 0 & A & B & C \\\\ 0 & 0 & 0 & A & B \\\\ \\end{Bmatrix} = \\begin{Bmatrix} S(0,T) \\\\ S(1,T) \\\\ S(2,T) \\\\ S(3,T) \\\\ S(4,T) \\\\ \\end{Bmatrix}这样转化后就变成一个求某矩阵的T次幂，然后再做一次矩阵乘法就可以了，T很大，但是可以通过快速幂来实现。AC代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;#define mem(a, b) memset(a, b, sizeof(a))#define PI 3.1415926535using namespace std;typedef long long ll;const int MAXn = 55;struct matirix&#123; int a[MAXn][MAXn];&#125; r, o; //o为转换矩阵int sum[MAXn], n, m, a, b, c, t; //sum[MAXn]为初始矩阵matirix cheng(matirix a, matirix b)&#123;//矩阵相乘 int x, y, z; matirix t; mem(t.a, 0); for (x = 0; x &lt; n; x++) for (y = 0; y &lt; n; y++) &#123; for (z = 0; z &lt; n; z++) &#123; t.a[x][y] += (a.a[x][z] * b.a[z][y]) % m; t.a[x][y] %= m; &#125; &#125; return t;&#125;void sort_pow(int t)&#123;//矩阵快速幂 while (t) &#123; if (t &amp; 1) r = cheng(r, o); o = cheng(o, o); t &gt;&gt;= 1; &#125;&#125;void init()&#123; mem(r.a,0); //清零 mem(o.a,0); int i, j; scanf(&quot;%d%d%d%d%d&quot;, &amp;m, &amp;a, &amp;b, &amp;c, &amp;t); r.a[0][0] = r.a[n - 1][n - 1] = 1; //构建矩阵 o.a[0][0] = b; o.a[0][1] = c; o.a[n - 1][n - 2] = a; o.a[n - 1][n - 1] = b; for (i = 1; i &lt; n - 1; i++) &#123; o.a[i][i - 1] = a; o.a[i][i] = b; o.a[i][i + 1] = c; r.a[i][i] = 1; &#125; sort_pow(t); for (i = 0; i &lt; n; i++) scanf(&quot;%d&quot;, sum + i); for (i = 0; i &lt; n; i++) &#123; int ans = 0; for (j = 0; j &lt; n; j++) &#123; ans += sum[j] * r.a[i][j]; ans %= m; &#125; if (i != 0) printf(&quot; &quot;); printf(&quot;%d&quot;, ans); &#125; printf(&quot;\\n&quot;);&#125;int main()&#123; while (1) &#123; scanf(&quot;%d&quot;, &amp;n); if (n == 0) break; init(); &#125;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"题目","slug":"ACM/题目","permalink":"https://tang7o.cn/categories/ACM/%E9%A2%98%E7%9B%AE/"}],"tags":[{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"}]},{"title":"并查集","slug":"并查集","date":"2020-04-10T09:25:45.000Z","updated":"2022-04-13T13:31:48.896Z","comments":true,"path":"2020/04/10/并查集/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E5%B9%B6%E6%9F%A5%E9%9B%86/","excerpt":"","text":"故事读完，并查集就会了~ 江湖上散落着各式各样的大侠，有上千个之多。他们没有什么正当职业，整天背着剑在外面走来走去，碰到和自己不是一路人的，就免不了要打一架。但大侠们有一个优点就是讲义气，绝对不打自己的朋友。而且他们信奉“朋友的朋友就是我的朋友”，只要是能通过朋友关系串联起来的，不管拐了多少个弯，都认为是自己人。这样一来，江湖上就形成了一个一个的帮派，通过两两之间的朋友关系串联起来。而不在同一个帮派的人，无论如何都无法通过朋友关系连起来，于是就可以放心往死了打。但是两个原本互不相识的人，如何判断是否属于一个朋友圈呢？ 我们可以在每个朋友圈内推举出一个比较有名望的人，作为该圈子的代表人物。这样，每个圈子就可以这样命名“中国同胞队”美国同胞队”……两人只要互相对一下自己的队长是不是同一个人，就可以确定敌友关系了。 但是还有问题啊，大侠们只知道自己直接的朋友是谁，很多人压根就不认识队长要判断自己的队长是谁，只能漫无目的的通过朋友的朋友关系问下去：“你是不是队长？你是不是队长？”这样，想打一架得先问个几十年，饿都饿死了，受不了。这样一来，队长面子上也挂不住了，不仅效率太低，还有可能陷入无限循环中。于是队长下令，重新组队。队内所有人实行分等级制度，形成树状结构，我队长就是根节点，下面分别是二级队员、三级队员。每个人只要记住自己的上级是谁就行了。遇到判断敌友的时候，只要一层层向上问，直到最高层，就可以在短时间内确定队长是谁了。由于我们关心的只是两个人之间是否是一个帮派的，至于他们是如何通过朋友关系相关联的，以及每个圈子内部的结构是怎样的，甚至队长是谁，都不重要了。所以我们可以放任队长随意重新组队，只要不搞错敌友关系就好了。于是，门派产生了。 下面我们来看并查集的实现。 int pre[1000]; 这个数组，记录了每个大侠的上级是谁。大侠们从1或者0开始编号（依据题意而定），pre[15]=3就表示15号大侠的上级是3号大侠。如果一个人的上级就是他自己，那说明他就是掌门人了，查找到此为止。也有孤家寡人自成一派的，比如欧阳锋，那么他的上级就是他自己。每个人都只认自己的上级。比如胡青牛同学只知道自己的上级是杨左使。张无忌是谁？不认识！要想知道自己的掌门是谁，只能一级级查上去。 find这个函数就是找掌门用的，意义再清楚不过了（路径压缩算法先不论，后面再说）。 1234567891011121314151617int unionsearch(int root) //查找根结点&#123; int son, tmp; son = root; while (root != pre[root]) //我的上级不是掌门 root = pre[root]; while (son != root) //我就找他的上级，直到掌门出现 &#123; tmp = pre[son]; pre[son] = root; son = tmp; &#125; return root; //掌门驾到~~&#125; 再来看看join函数，就是在两个点之间连一条线，这样一来，原先它们所在的两个板块的所有点就都可以互通了。这在图上很好办，画条线就行了。但我们现在是用并查集来描述武林中的状况的，一共只有一个pre[]数组，该如何实现呢？ 还是举江湖的例子，假设现在武林中的形势如图所示。虚竹帅锅与周芷若MM是我非常喜欢的两个人物，他们的终极boss分别是玄慈方丈和灭绝师太，那明显就是两个阵营了。我不希望他们互相打架，就对他俩说：“你们两位拉拉勾，做好朋友吧。”他们看在我的面子上，同意了。这一同意可非同小可，整个少林和峨眉派的人就不能打架了。这么重大的变化，可如何实现呀，要改动多少地方？其实非常简单，我对玄慈方丈说：“大师，麻烦你把你的上级改为灭绝师太吧。这样一来，两派原先的所有人员的终极boss都是师太，那还打个球啊！反正我们关心的只是连通性，门派内部的结构不要紧的。”玄慈一听肯定火大了：“我靠，凭什么是我变成她手下呀，怎么不反过来？我抗议！”于是，两人相约一战，杀的是天昏地暗，风云为之变色啊，但是啊，这场战争终究会有胜负，胜者为王。弱者就被吞并了。反正谁加入谁效果是一样的，门派就由两个变成一个了。这段函数的意思明白了吧？ 12345678void join(int root1, int root2) //虚竹和周芷若做朋友&#123; int x, y; x = unionsearch(root1);//我老大是玄慈 y = unionsearch(root2);//我老大是灭绝 if(x != y) pre[x] = y; //打一仗，谁赢就当对方老大&#125; 再来看看路径压缩算法。建立门派的过程是用join函数两个人两个人地连接起来的，谁当谁的手下完全随机。最后的树状结构会变成什么样，我也无法预知，一字长蛇阵也有可能。这样查找的效率就会比较低下。最理想的情况就是所有人的直接上级都是掌门，一共就两级结构，只要找一次就找到掌门了。哪怕不能完全做到，也最好尽量接近。这样就产生了路径压缩算法。 设想这样一个场景：两个互不相识的大侠碰面了，想知道能不能干一场。 于是赶紧打电话问自己的上级：“你是不是掌门？” 上级说：“我不是呀，我的上级是谁谁谁，你问问他看看。” 一路问下去，原来两人的最终boss都是东厂曹公公。 “哎呀呀，原来是自己人，有礼有礼，在下三营六组白面葫芦娃!” “幸会幸会，在下九营十八组仙子狗尾巴花！” 两人高高兴兴地手拉手喝酒去了。 “等等等等，两位大侠请留步，还有事情没完成呢！”我叫住他俩。 “哦，对了，还要做路径压缩。”两人醒悟。 白面葫芦娃打电话给他的上级六组长：“组长啊，我查过了，其实偶们的掌门是曹公公。不如偶们一起结拜在曹公公手下吧，省得级别太低，以后查找掌门麻烦。” “唔，有道理。” 白面葫芦娃接着打电话给刚才拜访过的三营长……仙子狗尾巴花也做了同样的事情。 这样，查询中所有涉及到的人物都聚集在曹公公的直接领导下。每次查询都做了优化处理，所以整个门派树的层数都会维持在比较低的水平上。路径压缩的代码，看得懂很好，看不懂可以自己模拟一下，很简单的一个递归而已。总之它所实现的功能就是这么个意思。 于是，问题圆满解决。。。。。。。。。 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;cstring&gt;#include&lt;cmath&gt;#include&lt;algorithm&gt;using namespace std;int pre[1010]; //里面全是掌门 int unionsearch(int root)&#123; int son, tmp; son = root; while(root != pre[root]) //寻找掌门ing…… root = pre[root]; while(son != root) //路径压缩 &#123; tmp = pre[son]; pre[son] = root; son = tmp; &#125; return root; //掌门驾到~&#125; int main()&#123; int num, road, total, i, start, end, root1, root2; while(scanf(&quot;%d%d&quot;, &amp;num, &amp;road) &amp;&amp; num) &#123; total = num - 1; //共num-1个门派 for(i = 1; i &lt;= num; ++i) //每条路都是掌门 pre[i] = i; while(road--) &#123; scanf(&quot;%d%d&quot;, &amp;start, &amp;end); //他俩要结拜 root1 = unionsearch(start); root2 = unionsearch(end); if(root1 != root2) //掌门不同？踢馆！~ &#123; pre[root1] = root2; total--; //门派少一个，敌人（要建的路）就少一个 &#125; &#125; printf(&quot;%d\\n&quot;, total);//天下局势：还剩几个门派 &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"二叉树的简单讲解","slug":"二叉树的简单讲解","date":"2020-04-10T09:24:08.000Z","updated":"2022-04-13T13:31:48.779Z","comments":true,"path":"2020/04/10/二叉树的简单讲解/","link":"","permalink":"https://tang7o.cn/2020/04/10/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E7%AE%80%E5%8D%95%E8%AE%B2%E8%A7%A3/","excerpt":"","text":"&lt; div id=”article_content” class=”article_content clearfix”&gt; 二叉树是一种特殊的树，在二叉树中每个节点最多有两个子节点，一般称为左子节点和右子节点（或左孩子和右孩子），并且二叉树的子树有左右之分，其次序不能任意颠倒。 树的术语： Name Function 路径 顺着连接点的边从一个节点走向另一个节点，所经过的节点的顺序排列就称为路径。 根 树顶端的节点就称为根，一棵树只有一个根，如果要把一个节点和边的集合定义为树，那么从根到其他任何一个节点都必须有一条路径。 父节点 每个节点（除了根）都恰好有一条边向上连接到另一个节点，上面的节点就称为下面节点的“父节点”。 子节点 每个节点都可能有一条或多条边向下连接其他节点，下面的这些节点就称为它的“子节点”。 叶节点 没有子节点的节点称为“叶子节点”或简称“叶节点”。树只能有一个根，但是可以有很多叶节点 子树 每个节点都可以作为子树的根，它和它所有的子节点，子节点的子节点等都含在子树中。 访问 当程序控制流程到达某个节点的时候，就称为“访问”这个节点，通常是为了在这个节点处执行某种操作，例如查看节点某个数据字段的值或者显示节点。 遍历 遍历树意味着要遵循某种特定的顺序访问树中的所有节点。 层 一个节点的层数是指从根开始到这个节点有多少“代”。 关键字 可以看到，对象中通常会有一个数据域被指定为关键字值。这个值通常用于查询或者其他操作。 二叉树 如果树中的每个节点最多只能有两个子节点，这样的树就称为“二叉树”。 满二叉树：在一棵二叉树中，如果所有分支结点都有左孩子和右孩子结点，并且叶子结点都集中在二叉树的最下层，这样的树叫做满二叉树如：根据满二叉树的定义，得到其特点为： 叶子只能出现在最下一层。 非叶子结点度一定是2. 在同样深度的二叉树中，满二叉树的结点个数最多，叶子数最多。 完全二叉树：若二叉树中最多只有最下面两层的结点的度数可以小于2，并且最下面一层的叶子结点都是依次排列在该层最左边的位置上，则称为完全二叉树。如：满二叉树与完全二叉树的区别：满二叉树是完全二叉树的特例，因为满二叉树已经满了，而完全并不代表满。所以形态你也应该想象出来了吧，满指的是出了叶子节点外每个节点都有两个孩子，而完全的含义则是最后一层没有满，并没有满。 结合完全二叉树定义得到其特点： 叶子结点只能出现在最下一层和次下层（满二叉树继承而来） 最下层叶子结点一定集中在左 部连续位置。 倒数第二层，如有叶子节点，一定出现在右部连续位置。 同样结点树的二叉树，完全二叉树的深度最小（满二叉树也是对的）。 一般二叉树的性质： 左节点下标是其父节点的二倍，右节点的下标是其父节点的二倍加一（左节点加一）。 第n层的节点个数最多为2n-1。 前n层的节点个数最多为2n-1。 对于任何一棵非空的二叉树,如果叶节点个数为n0，度数为2的节点个数为n2，则有: n0 = n2 + 1。4的证明：在一棵二叉树中，除了叶子结点（度为0）之外，就剩下度为2(n2)和1(n1)的结点了。则树的结点总数为T = n0+n1+n2;在二叉树中结点总数为T，而连线数为T-1.所以有：n0+n1+n2-1 = 2*n2 +n1;最后得到n0 = n2+1; 完全二叉树的性质： 具有n个结点的完全二叉树的深度为log2n+1.证明： 满二叉树是完全二叉树，对于深度为k的满二叉树中结点数量是2k-1 = n，完全二叉树结点数量肯定最多2k-1,同时完全二叉树倒数第二层肯定是满的（倒数第一层有结点，那么倒是第二层序号和满二叉树相同），所以完全二叉树的结点数最少大于少一层的满二叉树，为2k-1-1。根据上面推断得出： 2k-1-1&lt; n=","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"zyb的面试","slug":"zyb的面试","date":"2020-04-10T09:17:47.000Z","updated":"2022-04-13T13:31:48.750Z","comments":true,"path":"2020/04/10/zyb的面试/","link":"","permalink":"https://tang7o.cn/2020/04/10/zyb%E7%9A%84%E9%9D%A2%E8%AF%95/","excerpt":"","text":"Description今天zyb参加一场面试,面试官听说zyb是ACMer之后立马抛出了一道算法题给zyb: 有一个序列,是1到n的一种排列,排列的顺序是字典序小的在前,那么第k个数字是什么? 例如n=15,k=7, 排列顺序为1, 10, 11, 12, 13, 14, 15, 2, 3, 4, 5, 6, 7, 8, 9;那么第7个数字就是15. 那么,如果你处在zyb的场景下,你能解决这个问题吗? InputT组样例(T&lt;=100) 两个整数n和k(1&lt;=n&lt;=1e6,1&lt;=k&lt;=n),n和k代表的含义如上文 Output输出1-n之中字典序第k小的数字 Sample Input1 15 7 Sample Output15 思路：完全十叉树12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;#define mem(a,b) memset(a,b,sizeof(a))using namespace std;typedef long long ll;const int MAXn=10005;//const int mod=1000000007;int cal(int n,int k)&#123; int cur=1; k=k-1; while(k&gt;0)&#123; int step=0,first=cur,last=cur+1; while(first&lt;=n)&#123; step+=min(n+1,last)-first; first*=10; last*=10; &#125; if(step&lt;=k)&#123; cur++; k-=step; &#125; else&#123; cur*=10; k-=1; &#125; &#125; return cur;&#125;int main()&#123; int t; cin&gt;&gt;t; while(t--)&#123; int n,k; cin&gt;&gt;n&gt;&gt;k; cout&lt;&lt;cal(n,k)&lt;&lt;endl; &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"题目","slug":"ACM/题目","permalink":"https://tang7o.cn/categories/ACM/%E9%A2%98%E7%9B%AE/"}],"tags":[{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"}]},{"title":"非常可乐（BFS）","slug":"非常可乐（bfs）","date":"2020-04-09T11:27:43.000Z","updated":"2022-04-13T13:31:49.264Z","comments":true,"path":"2020/04/09/非常可乐（bfs）/","link":"","permalink":"https://tang7o.cn/2020/04/09/%E9%9D%9E%E5%B8%B8%E5%8F%AF%E4%B9%90%EF%BC%88bfs%EF%BC%89/","excerpt":"","text":"Description大家一定觉的运动以后喝可乐是一件很惬意的事情，但是seeyou却不这么认为。因为每次当seeyou买了可乐以后，阿牛就要求和seeyou一起分享这一瓶可乐，而且一定要喝的和seeyou一样多。但seeyou的手中只有两个杯子，它们的容量分别是N 毫升和M 毫升 可乐的体积为S （S&lt;101）毫升 (正好装满一瓶) ，它们三个之间可以相互倒可乐 (都是没有刻度的，且 S==N+M，101＞S＞0，N＞0，M＞0) 。聪明的ACMER你们说他们能平分吗？如果能请输出倒可乐的最少的次数，如果不能输出”NO”。 Input三个整数 : S 可乐的体积 , N 和 M是两个杯子的容量，以”0 0 0”结束。 Output如果能平分的话请输出最少要倒的次数，否则输出”NO”。 Sample Input7 4 3 4 1 3 0 0 0 Sample OutputNO 3 思路：BFS就好了，起点（0，0，s），六个方向 s-&gt;a,s-&gt;b,a-&gt;s,a-&gt;b,b-&gt;s,b-&gt;a;终点（s/2,s/2,0）；只要列一下这六个方向就行了AC代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;#define mem(a,b) memset(a,b,sizeof(a))using namespace std;const int Max=101;struct node&#123; int s,a,b,t;&#125;;int s,a,b,vi[Max][Max][Max];int BFS()&#123; queue&lt;node&gt;p; node n1; memset(vi,0,sizeof(vi)); n1.s=s,n1.a=0,n1.b=0,n1.t=0; p.push(n1); vi[n1.s][n1.a][n1.b]=1; while(!p.empty()) &#123; node u=p.front(),v; if(u.s==s/2&amp;&amp;u.a==s/2) return u.t; if(u.s&amp;&amp;u.a!=a) &#123; //ss-&gt;a 从可乐瓶往a杯里面倒 int c=a-u.a; if(u.s&gt;=c) &#123; v.s=u.s-c; v.a=a; &#125; else &#123; v.s=0; v.a=u.a+u.s; &#125; v.b=u.b; v.t=u.t+1; if(!vi[v.s][v.a][v.b]) &#123; p.push(v); vi[v.s][v.a][v.b]=1; &#125; &#125; if(u.s&amp;&amp;u.b!=b) &#123; //ss-&gt;b int c=b-u.b; if(u.s&gt;=c) &#123; v.s=u.s-c; v.b=b; &#125; else &#123; v.s=0; v.b=u.b+u.s; &#125; v.a=u.a; v.t=u.t+1; if(!vi[v.s][v.a][v.b]) &#123; p.push(v); vi[v.s][v.a][v.b]=1; &#125; &#125; if(u.a&amp;&amp;u.b!=b) &#123; //a-&gt;b int c=b-u.b; if(u.a&gt;=c) &#123; v.a=u.a-c; v.b=b; &#125; else &#123; v.a=0; v.b=u.b+u.a; &#125; v.s=u.s; v.t=u.t+1; if(!vi[v.s][v.a][v.b]) &#123; p.push(v); vi[v.s][v.a][v.b]=1; &#125; &#125; if(u.a&amp;&amp;u.s!=s) &#123; //a-&gt;s int c=s-u.s; if(u.a&gt;=c) &#123; v.a=u.a-c; v.s=s; &#125; else &#123; v.a=0; v.s=u.s+u.a; &#125; v.b=u.b; v.t=u.t+1; if(!vi[v.s][v.a][v.b]) &#123; p.push(v); vi[v.s][v.a][v.b]=1; &#125; &#125; if(u.b&amp;&amp;u.s!=s) &#123; //b-&gt;s int c=s-u.s; if(u.b&gt;=c) &#123; v.b=u.b-c; v.s=s; &#125; else &#123; v.b=0; v.s=u.s+u.b; &#125; v.a=u.a; v.t=u.t+1; if(!vi[v.s][v.a][v.b]) &#123; p.push(v); vi[v.s][v.a][v.b]=1; &#125; &#125; if(u.b&amp;&amp;u.a!=a) &#123; //b-&gt;a int c=a-u.a; if(u.b&gt;=c) &#123; v.b=u.b-c; v.a=a; &#125; else &#123; v.b=0; v.a=u.a+u.b; &#125; v.s=u.s; v.t=u.t+1; if(!vi[v.s][v.a][v.b]) &#123; p.push(v); vi[v.s][v.a][v.b]=1; &#125; &#125; p.pop(); &#125; return 0;&#125;int main()&#123; while(~scanf(&quot;%d%d%d&quot;,&amp;s,&amp;a,&amp;b)) //s可乐体积 a，b杯子 &#123; if(!s&amp;&amp;!a&amp;&amp;!b) break; if(s%2) &#123; printf(&quot;NO\\n&quot;); continue; &#125; if(a&lt;b) swap(a,b); int ans=BFS(); if(ans) printf(&quot;%d\\n&quot;,ans); else printf(&quot;NO\\n&quot;); &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"题目","slug":"ACM/题目","permalink":"https://tang7o.cn/categories/ACM/%E9%A2%98%E7%9B%AE/"}],"tags":[{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"}]},{"title":"棋盘问题 （DFS）","slug":"棋盘问题-（dfs）","date":"2020-04-09T10:34:22.000Z","updated":"2022-04-13T13:31:49.078Z","comments":true,"path":"2020/04/09/棋盘问题-（dfs）/","link":"","permalink":"https://tang7o.cn/2020/04/09/%E6%A3%8B%E7%9B%98%E9%97%AE%E9%A2%98-%EF%BC%88dfs%EF%BC%89/","excerpt":"","text":"Description在一个给定形状的棋盘（形状可能是不规则的）上面摆放棋子，棋子没有区别。要求摆放时任意的两个棋子不能放在棋盘中的同一行或者同一列，请编程求解对于给定形状和大小的棋盘，摆放k个棋子的所有可行的摆放方案C。 Input输入含有多组测试数据。 每组数据的第一行是两个正整数，n k，用一个空格隔开，表示了将在一个n*n的矩阵内描述棋盘，以及摆放棋子的数目。 n &lt;= 8 , k &lt;= n 当为-1 -1时表示输入结束。 随后的n行描述了棋盘的形状：每行有n个字符，其中 # 表示棋盘区域， . 表示空白区域（数据保证不出现多余的空白行或者空白列）。 Output对于每一组数据，给出一行输出，输出摆放的方案数目C （数据保证C&lt;2^31）。 Sample Input2 1 #. .# 4 4 …# …#. .#… #… -1 -1 Sample Output2 1 思路：用DFS，DFS只有一个形参，那就是列数（当然行数也可以）因为题目说了，每一行每一列只能放一个棋子；AC代码如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;#define mem(a,b) memset(a,b,sizeof(a))using namespace std;const int maxn=8;int ans,x,n,k; //ans表示方案数目 x表示已经放了几个棋子了char qipan[maxn][maxn],v[maxn]; //v用来标记第n行（因为一行就能放一个棋子void dfs(int h) //h表示第几列&#123; int i; if(x==k) //如果已经发放了k个棋子 方案数+1； &#123; ans++; return ; &#125; if(h&gt;=n) //如果列数超界 退出循环 return ; for(i=0; i&lt;n; i++) &#123; if(qipan[i][h]==&#x27;#&#x27;&amp;&amp;v[i]) &#123; v[i]=0; x++; dfs(h+1); x--; v[i]=1; &#125; &#125; dfs(h+1); &#125;int main()&#123; int i,j; while(cin&gt;&gt;n&gt;&gt;k) &#123; if(n==-1&amp;&amp;k==-1) break; mem(qipan,0); mem(v,1); ans=0; x=0; for(i=0; i&lt;n; i++) for(j=0; j&lt;n; j++) cin&gt;&gt;qipan[i][j]; dfs(0); cout&lt;&lt;ans&lt;&lt;endl; &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"题目","slug":"ACM/题目","permalink":"https://tang7o.cn/categories/ACM/%E9%A2%98%E7%9B%AE/"}],"tags":[{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"},{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Prime Path （BFS+打表）","slug":"prime-path-（bfs打表）","date":"2020-04-09T10:28:13.000Z","updated":"2022-04-13T13:31:48.644Z","comments":true,"path":"2020/04/09/prime-path-（bfs打表）/","link":"","permalink":"https://tang7o.cn/2020/04/09/prime-path-%EF%BC%88bfs%E6%89%93%E8%A1%A8%EF%BC%89/","excerpt":"","text":"DescriptionThe ministers of the cabinet were quite upset by the message from the Chief of Security stating that they would all have to change the four-digit room numbers on their offices. — It is a matter of security to change such things every now and then, to keep the enemy in the dark. — But look, I have chosen my number 1033 for good reasons. I am the Prime minister, you know! — I know, so therefore your new number 8179 is also a prime. You will just have to paste four new digits over the four old ones on your office door. — No, it’s not that simple. Suppose that I change the first digit to an 8, then the number will read 8033 which is not a prime! — I see, being the prime minister you cannot stand having a non-prime number on your door even for a few seconds. — Correct! So I must invent a scheme for going from 1033 to 8179 by a path of prime numbers where only one digit is changed from one prime to the next prime. Now, the minister of finance, who had been eavesdropping, intervened. — No unnecessary expenditure, please! I happen to know that the price of a digit is one pound. — Hmm, in that case I need a computer program to minimize the cost. You don’t know some very cheap software gurus, do you? — In fact, I do. You see, there is this programming contest going on… Help the prime minister to find the cheapest prime path between any two given four-digit primes! The first digit must be nonzero, of course. Here is a solution in the case above. 1033 1733 3733 3739 3779 8779 8179 The cost of this solution is 6 pounds. Note that the digit 1 which got pasted over in step 2 can not be reused in the last step – a new 1 must be purchased. InputOne line with a positive number: the number of test cases (at most 100). Then for each test case, one line with two numbers separated by a blank. Both numbers are four-digit primes (without leading zeros). OutputOne line for each case, either with a number stating the minimal cost or containing the word Impossible. Sample Input3 1033 8179 1373 8017 1033 1033 Sample Output6 7 0 题目大意：让你将第一个数变成第二个数，每次只能改变一个位数字，改完后的数字必须是素数，找最少次数，如果不能变成另一个数输出“Impossible”，否则输出次数思路：用BFS， 枚举每一位上的数字，如果符合要求就入列，直到变换为另一个数字，或者退出循环；———————————————— 代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;#define mem(a,b) memset(a,b,sizeof(a))using namespace std;typedef long long ll;const int MAXn=10005;//const int mod=1000000007;typedef struct node&#123; int n,t;&#125; node;int ss[MAXn],a,b,v[MAXn];//ss用来存素数 v用来标记void BFS(int n)&#123; int i; node n1; n1.n=n; n1.t=0; queue&lt;node&gt;q; while(!q.empty()) q.pop(); //清空队列 v[n]=0; q.push(n1); while(!q.empty()) &#123; node n2=q.front(); q.pop(); if(n2.n==b) &#123; //变换成功就输出次数（因为是用的BFS，所以次数保证最少） cout&lt;&lt;n2.t&lt;&lt;endl; return ; &#125; for(i=1; i&lt;=9; i++) //千位 &#123; n=n2.n%1000+i*1000; if(!ss[n]&amp;&amp;v[n]) &#123; //符合要求就存入队列并标记这个数字 n1.n=n; n1.t=n2.t+1; v[n]=0; q.push(n1); &#125; &#125; for(i=0; i&lt;=9; i++) //百位 &#123; n=n2.n/1000*1000+i*100+n2.n%100; if(!ss[n]&amp;&amp;v[n]) &#123; n1.n=n; n1.t=n2.t+1; v[n]=0; q.push(n1); &#125; &#125; for(i=0; i&lt;=9; i++) //十位 &#123; n=n2.n/100*100+i*10+n2.n%10; if(!ss[n]&amp;&amp;v[n]) &#123; n1.n=n; n1.t=n2.t+1; v[n]=0; q.push(n1); &#125; &#125; for(i=1; i&lt;=9; i+=2) //个位 &#123; n=n2.n/10*10+i; if(!ss[n]&amp;&amp;v[n]) &#123; n1.n=n; n1.t=n2.t+1; v[n]=0; q.push(n1); &#125; &#125; &#125; cout&lt;&lt;&quot;Impossible&quot;&lt;&lt;endl;//如果找不到，输出Impossible&#125;int main()&#123; mem(ss,1); ss[2]=ss[3]=0; for (int i=5; i&lt;10000; i++) &#123;//这是一种较为快捷的素数打表方法，原理：除了2和3，其他素数不是6的倍数加一就是6的倍数减一 if ((i+1)%6==0(i-1)%6==0) &#123; int j; for (j=2; j&lt;(int)(sqrt(i)+1); j++) &#123; if (i%j==0) break; &#125; if (j==(int)(sqrt(i)+1)) ss[i]=0; &#125; &#125; int T; cin&gt;&gt;T; while(T--) &#123; cin&gt;&gt;a&gt;&gt;b; mem(v,1); BFS(a); &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"题目","slug":"ACM/题目","permalink":"https://tang7o.cn/categories/ACM/%E9%A2%98%E7%9B%AE/"}],"tags":[{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"}]},{"title":"广度/深度优先搜索","slug":"广度-深度优先搜索","date":"2020-04-09T10:23:27.000Z","updated":"2022-04-13T13:31:48.909Z","comments":true,"path":"2020/04/09/广度-深度优先搜索/","link":"","permalink":"https://tang7o.cn/2020/04/09/%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/","excerpt":"","text":"1.前言广度优先搜索（也称宽度优先搜索，缩写BFS，以下采用广度来描述）是连通图的一种遍历策略。因为它的思想是从一个顶点V0开始，辐射状地优先遍历其周围较广的区域，故得名。 一般可以用它做什么呢？一个 广度/宽度优先搜索(BFS) 算法导论里边会给出不少严格的证明，我想尽量写得通俗一点，因此采用一些直观的讲法来伪装成证明，关键的point能够帮你get到就好。 2.图的概念刚刚说的广度优先搜索是连通图的一种遍历策略，那就有必要将图先简单解释一下。 图2-1连通图示例图 如图2-1所示，这就是我们所说的连通图，这里展示的是一个无向图，连通即每2个点都有至少一条路径相连，例如V0到V4的路径就是V0-&gt;V1-&gt;V4。 一般我们把顶点用V缩写，把边用E缩写。 3.广度优先搜索3.1.算法的基本思路常常我们有这样一个问题，从一个起点开始要到一个终点，我们要找寻一条最短的路径，从图2-1举例，如果我们要求V0到V6的一条最短路（假设走一个节点按一步来算）【注意：此处你可以选择不看这段文字直接看图3-1】，我们明显看出这条路径就是V0-&gt;V2-&gt;V6，而不是V0-&gt;V3-&gt;V5-&gt;V6。先想想你自己刚刚是怎么找到这条路径的：首先看跟V0直接连接的节点V1、V2、V3，发现没有V6，进而再看刚刚V1、V2、V3的直接连接节点分别是：{V0、V4}、{V0、V1、V6}、{V0、V1、V5}（这里画删除线的意思是那些顶点在我们刚刚的搜索过程中已经找过了，我们不需要重新回头再看他们了）。这时候我们从V2的连通节点集中找到了V6，那说明我们找到了这条V0到V6的最短路径：V0-&gt;V2-&gt;V6，虽然你再进一步搜索V5的连接节点集合后会找到另一条路径V0-&gt;V3-&gt;V5-&gt;V6，但显然他不是最短路径。 你会看到这里有点像辐射形状的搜索方式，从一个节点，向其旁边节点传递病毒，就这样一层一层的传递辐射下去，知道目标节点被辐射中了，此时就已经找到了从起点到终点的路径。 我们采用示例图来说明这个过程，在搜索的过程中，初始所有节点是白色（代表了所有点都还没开始搜索），把起点V0标志成灰色（表示即将辐射V0），下一步搜索的时候，我们把所有的灰色节点访问一次，然后将其变成黑色（表示已经被辐射过了），进而再将他们所能到达的节点标志成灰色（因为那些节点是下一步搜索的目标点了），但是这里有个判断，就像刚刚的例子，当访问到V1节点的时候，它的下一个节点应该是V0和V4，但是V0已经在前面被染成黑色了，所以不会将它染灰色。这样持续下去，直到目标节点V6被染灰色，说明了下一步就到终点了，没必要再搜索（染色）其他节点了，此时可以结束搜索了，整个搜索就结束了。然后根据搜索过程，反过来把最短路径找出来，图3-1中把最终路径上的节点标志成绿色。 整个过程的实例图如图3-1所示。 初始全部都是白色（未访问） 即将搜索起点V0（灰色） 已搜索V0，即将搜索V1、V2、V3 ……终点V6被染灰色，终止 找到最短路径 图3-1寻找V0到V6的过程 3.2.广度优先搜索流程图 图3-2广度优先搜索的流程图 在写具体代码之前有必要先举个实例，详见第4节。 4.实例第一节就讲过广度优先搜索适用于迷宫类问题，这里先给出POJ3984《迷宫问题》。 《迷宫问题》 定义一个二维数组：intmaze[5][5]={0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,1,1,1,0,0,0,0,1,0,};它表示一个迷宫，其中的1表示墙壁，0表示可以走的路，只能横着走或竖着走，不能斜着走，要求编程序找出从左上角到右下角的最短路线。 题目保证了输入是一定有解的。 也许你会问，这个跟广度优先搜索的图怎么对应起来？BFS的第一步就是要识别图的节点跟边！ 4.1.识别出节点跟边节点就是某种状态，边就是节点与节点间的某种规则。 对应于《迷宫问题》，你可以这么认为，节点就是迷宫路上的每一个格子（非墙），走迷宫的时候，格子间的关系是什么呢？按照题目意思，我们只能横竖走，因此我们可以这样看，格子与它横竖方向上的格子是有连通关系的，只要这个格子跟另一个格子是连通的，那么两个格子节点间就有一条边。 如果说本题再修改成斜方向也可以走的话，那么就是格子跟周围8个格子都可以连通，于是一个节点就会有8条边（除了边界的节点）。 4.2.解题思路对应于题目的输入数组： 0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,1,1,1,0,0,0,0,1,0, 我们把节点定义为(x,y)，(x,y)表示数组maze的项maze[x][y]。 于是起点就是(0,0)，终点是(4,4)。按照刚刚的思路，我们大概手工梳理一遍： 初始条件： 起点Vs为(0,0) 终点Vd为(4,4) 灰色节点集合Q={} 初始化所有节点为白色节点 开始我们的广度搜索！ 手工执行步骤【PS：你可以直接看图4-1】: 1.起始节点Vs变成灰色，加入队列Q，Q={(0,0)} 2.取出队列Q的头一个节点Vn，Vn={0,0}，Q={} 3.把Vn={0,0}染成黑色，取出Vn所有相邻的白色节点{(1,0)} 4.不包含终点(4,4)，染成灰色，加入队列Q，Q={(1,0)} 5.取出队列Q的头一个节点Vn，Vn={1,0}，Q={} 6.把Vn={1,0}染成黑色，取出Vn所有相邻的白色节点{(2,0)} 7.不包含终点(4,4)，染成灰色，加入队列Q，Q={(2,0)} 8.取出队列Q的头一个节点Vn，Vn={2,0}，Q={} 9.把Vn={2,0}染成黑色，取出Vn所有相邻的白色节点{(2,1),(3,0)} 10.不包含终点(4,4)，染成灰色，加入队列Q，Q={(2,1),(3,0)} 11.取出队列Q的头一个节点Vn，Vn={2,1}，Q={(3,0)} 把Vn={2,1}染成黑色，取出Vn所有相邻的白色节点{(2,2)} 13.不包含终点(4,4)，染成灰色，加入队列Q，Q={(3,0),(2,2)} 14.持续下去，知道Vn的所有相邻的白色节点中包含了(4,4)…… 15.此时获得了答案 起始你很容易模仿上边过程走到终点，那为什么它就是最短的呢？ 怎么保证呢？ 我们来看看广度搜索的过程中节点的顺序情况： 图4-1迷宫问题的搜索树 你是否观察到了，广度搜索的顺序是什么样子的？ 图中标号即为我们搜索过程中的顺序，我们观察到，这个搜索顺序是按照上图的层次关系来的，例如节点(0,0)在第1层，节点(1,0)在第2层，节点(2,0)在第3层，节点(2,1)和节点(3,0)在第3层。 我们的搜索顺序就是第一层-&gt;第二层-&gt;第三层-&gt;第N层这样子。 我们假设终点在第N层，因此我们搜索到的路径长度肯定是N，而且这个N一定是所求最短的。 我们用简单的反证法来证明：假设终点在第N层上边出现过，例如第M层，M&lt;n，那么我们在搜索的过程中，肯定是先搜索到第m层的，此时搜索到第m层的时候发现终点出现过了，那么最短路径应该是m，而不是n了。 所以根据广度优先搜索的话，搜索到终点时，该路径一定是最短的。 4.3.代码我给出以下代码用于解决上述题目(仅仅只是核心代码)： 12345678910111213141516171819202122232425262728293031323334353637383940bool BFS(Node&amp; Vs, Node&amp; Vd)&#123; queue&lt;node&gt; Q; Node Vn, Vw; inti; //用于标记颜色当visit[i][j]==true时，说明节点访问过，也就是黑色 bool visit[MAXL][MAXL]; //四个方向 intdir[][2] = &#123; &#123;0,1&#125;, &#123;1,0&#125;, &#123;0, -1&#125;, &#123;-1,0&#125; &#125;; //初始状态将起点放进队列Q Q.push(Vs); visit[Vs.x][Vs.y] = true;//设置节点已经访问过了！ while(!Q.empty())&#123;//队列不为空，继续搜索！ //取出队列的头Vn Vn = Q.front(); Q.pop(); for(i = 0; i &lt; 4; ++i)&#123; Vw = Node(Vn.x+dir[i][0], Vn.y+dir[i][1]);//计算相邻节点 if(Vw == Vd)&#123;//找到终点了！ //把路径记录，这里没给出解法 returntrue;//返回 &#125; if(isValid(Vw) &amp;&amp; !visit[Vw.x][Vw.y])&#123; //Vw是一个合法的节点并且为白色节点 Q.push(Vw);//加入队列Q visit[Vw.x][Vw.y] = true;//设置节点颜色 &#125; &#125; &#125; returnfalse;//无解 &#125; 5.核心代码12345678910111213141516171819202122232425bool BFS(Node&amp; Vs, Node&amp; Vd)&#123; queue&lt;node&gt; Q; Node Vn, Vw; inti; //初始状态将起点放进队列Q Q.push(Vs); hash(Vw) = true;//设置节点已经访问过了！ while(!Q.empty())&#123;//队列不为空，继续搜索！ //取出队列的头Vn Vn = Q.front(); //从队列中移除 Q.pop(); while(Vw = Vn通过某规则能够到达的节点)&#123; if(Vw == Vd)&#123;//找到终点了！ //把路径记录，这里没给出解法 returntrue;//返回 &#125; if(isValid(Vw) &amp;&amp; !visit[Vw])&#123; //Vw是一个合法的节点并且为白色节点 Q.push(Vw);","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"广度优先搜索和深度优先搜索","slug":"广度优先搜索和深度优先搜索","date":"2020-04-09T10:22:12.000Z","updated":"2022-04-13T13:31:48.926Z","comments":true,"path":"2020/04/09/广度优先搜索和深度优先搜索/","link":"","permalink":"https://tang7o.cn/2020/04/09/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E5%92%8C%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/","excerpt":"","text":"BFS和DFS算法解析【算法入门】1.前言和树的遍历类似，图的遍历也是从图中某点出发，然后按照某种方法对图中所有顶点进行访问，且仅访问一次。 但是图的遍历相对树而言要更为复杂。因为图中的任意顶点都可能与其他顶点相邻，所以在图的遍历中必须记录已被访问的顶点，避免重复访问。 根据搜索路径的不同，我们可以将遍历图的方法分为两种：广度优先搜索和深度优先搜索。 2.图的基本概念2.1.无向图和无向图顶点对(u，v)是无序的，即（u，v）和（v，u）是同一条边。常用一对圆括号表示。 图2-1-1 无向图示例 顶点对是有序的，它是指从顶点u到顶点 v的一条有向边。其中u是有向边的始点，v是有向边的终点。常用一对尖括号表示。 图2-1-2 有向图示例 2.2.权和网图的每条边上可能存在具有某种含义的数值，称该数值为该边上的权。而这种带权的图被称为网。 2.3.连通图与非连通图连通图：在无向图G中，从顶点v到顶点v’有路径，则称v和v’是联通的。若图中任意两顶点v、v’∈V，v和v’之间均联通，则称G是连通图。上述两图均为连通图。 非连通图：若无向图G中，存在v和v’之间不连通，则称G是非连通图。 图2-3 非连通图示例 3.广度优先搜索 3.1.算法的基本思路广度优先搜索类似于树的层次遍历过程。它需要借助一个队列来实现。如图2-1-1所示，要想遍历从v0到v6的每一个顶点，我们可以设v0为第一层，v1、v2、v3为第二层，v4、v5为第三层，v6为第四层，再逐个遍历每一层的每个顶点。 具体过程如下： 1.准备工作：创建一个visited数组，用来记录已被访问过的顶点；创建一个队列，用来存放每一层的顶点；初始化图G。 2.从图中的v0开始访问，将的visited[v0]数组的值设置为true，同时将v0入队。 3.只要队列不空，则重复如下操作： (1)队头顶点u出队。 (2)依次检查u的所有邻接顶点w，若visited[w]的值为false，则访问w，并将visited[w]置为true，同时将w入队。 3.2.算法的实现过程白色表示未被访问，灰色表示即将访问，黑色表示已访问。 visited数组：0表示未访问，1表示以访问。 队列：队头出元素，队尾进元素。 1.初始时全部顶点均未被访问，visited数组初始化为0，队列中没有元素。 图3-2-1 2.即将访问顶点v0。图3-2-23.访问顶点v0，并置visited[0]的值为1，同时将v0入队。图3-2-3 4.将v0出队，访问v0的邻接点v2。判断visited[2]，因为visited[2]的值为0，访问v2。 图3-2-4 5.将visited[2]置为1，并将v2入队。 图3-2-5 6.访问v0邻接点v1。判断visited[1],因为visited[1]的值为0，访问v1。 图3-2-6 7.将visited[1]置为0，并将v1入队。 图3-2-7 8.判断visited[3],因为它的值为0，访问v3。将visited[3]置为0，并将v3入队。 图3-2-8 9.v0的全部邻接点均已被访问完毕。将队头元素v2出队，开始访问v2的所有邻接点。 开始访问v2邻接点v0，判断visited[0]，因为其值为1，不进行访问。 继续访问v2邻接点v4，判断visited[4]，因为其值为0，访问v4，如下图： 图3-2-9 10.将visited[4]置为1，并将v4入队。 图3-2-10 11.v2的全部邻接点均已被访问完毕。将队头元素v1出队，开始访问v1的所有邻接点。 开始访问v1邻接点v0，因为visited[0]值为1，不进行访问。 继续访问v1邻接点v4，因为visited[4]的值为1，不进行访问。 继续访问v1邻接点v5，因为visited[5]值为0，访问v5，如下图： 图3-2-11 12.将visited[5]置为1，并将v5入队。 图3-2-12 13.v1的全部邻接点均已被访问完毕，将队头元素v3出队，开始访问v3的所有邻接点。 开始访问v3邻接点v0，因为visited[0]值为1，不进行访问。 继续访问v3邻接点v5，因为visited[5]值为1，不进行访问。 图3-2-13 14.v3的全部邻接点均已被访问完毕，将队头元素v4出队，开始访问v4的所有邻接点。 开始访问v4的邻接点v2，因为visited[2]的值为1，不进行访问。 继续访问v4的邻接点v6，因为visited[6]的值为0，访问v6，如下图： 图3-2-14 15.将visited[6]值为1，并将v6入队。 图3-2-15 16.v4的全部邻接点均已被访问完毕，将队头元素v5出队，开始访问v5的所有邻接点。 开始访问v5邻接点v3，因为visited[3]的值为1，不进行访问。 继续访问v5邻接点v6，因为visited[6]的值为1，不进行访问。 图3-2-16 17.v5的全部邻接点均已被访问完毕，将队头元素v6出队，开始访问v6的所有邻接点。 开始访问v6邻接点v4，因为visited[4]的值为1，不进行访问。 继续访问v6邻接点v5，因为visited[5]的值文1，不进行访问。 图3-2-17 18.队列为空，退出循环，全部顶点均访问完毕。 图3-2-18 3.3具体代码的实现3.3.1用邻接矩阵表示图的广度优先搜索12345/*一些量的定义*/queue&lt;char&gt; q; //定义一个队列，使用库函数queue#define MVNum 100 //表示最大顶点个数bool visited[MVNum]; //定义一个visited数组，记录已被访问的顶点 1234567/*邻接矩阵存储表示*/typedef struct AMGraph&#123; char vexs[MVNum]; //顶点表 int arcs[MVNum][MVNum]; //邻接矩阵 int vexnum, arcnum; //当前的顶点数和边数&#125;AMGraph; 123456789/*找到顶点v的对应下标*/int LocateVex(AMGraph &amp;G, char v)&#123; int i; for (i = 0; i &lt; G.vexnum; i++) if (G.vexs[i] == v) return i;&#125; 1234567891011121314151617181920212223/*采用邻接矩阵表示法，创建无向图G*/int CreateUDG_1(AMGraph &amp;G)&#123; int i, j, k; char v1, v2; scanf(&quot;%d%d&quot;, &amp;G.vexnum, &amp;G.arcnum); //输入总顶点数，总边数 getchar(); //获取&#x27;\\n’，防止其对之后的字符输入造成影响 for (i = 0; i &lt; G.vexnum; i++) scanf(&quot;%c&quot;, &amp;G.vexs[i]); //依次输入点的信息 for (i = 0; i &lt; G.vexnum; i++) for (j = 0; j &lt; G.vexnum; j++) G.arcs[i][j] = 0; //初始化邻接矩阵边，0表示顶点i和j之间无边 for (k = 0; k &lt; G.arcnum; k++) &#123; getchar(); scanf(&quot;%c%c&quot;, &amp;v1, &amp;v2); //输入一条边依附的顶点 i = LocateVex(G, v1); //找到顶点i的下标 j = LocateVex(G, v2); //找到顶点j的下标 G.arcs[i][j] = G.arcs[j][i] = 1; //1表示顶点i和j之间有边，无向图不区分方向 &#125; return 1;&#125; 12345678910111213141516171819202122232425262728/*采用邻接矩阵表示图的广度优先遍历*/void BFS_AM(AMGraph &amp;G,char v0)&#123;/*从v0元素开始访问图*/ int u,i,v,w; v = LocateVex(G,v0); //找到v0对应的下标 printf(&quot;%c &quot;, v0); //打印v0 visited[v] = 1; //顶点v0已被访问 q.push(v0); //将v0入队 while (!q.empty()) &#123; u = q.front(); //将队头元素u出队，开始访问u的所有邻接点 v = LocateVex(G, u); //得到顶点u的对应下标 q.pop(); //将顶点u出队 for (i = 0; i &lt; G.vexnum; i++) &#123; w = G.vexs[i]; if (G.arcs[v][i] &amp;&amp; !visited[i])//顶点u和w间有边，且顶点w未被访问 &#123; printf(&quot;%c &quot;, w); //打印顶点w q.push(w); //将顶点w入队 visited[i] = 1; //顶点w已被访问 &#125; &#125; &#125;&#125; 3.3.2用邻接表表示图的广度优先搜索123456789/*找到顶点对应的下标*/int LocateVex(ALGraph &amp;G, char v)&#123; int i; for (i = 0; i &lt; G.vexnum; i++) if (v == G.vertices[i].data) return i;&#125; 1234567891011121314151617181920/*邻接表存储表示*/typedef struct ArcNode //边结点&#123; int adjvex; //该边所指向的顶点的位置 ArcNode *nextarc; //指向下一条边的指针 int info; //和边相关的信息，如权值&#125;ArcNode; typedef struct VexNode //表头结点&#123; char data; ArcNode *firstarc; //指向第一条依附该顶点的边的指针&#125;VexNode,AdjList[MVNum]; //AbjList表示一个表头结点表 typedef struct ALGraph&#123; AdjList vertices; int vexnum, arcnum;&#125;ALGraph; 1234567891011121314151617181920212223242526272829/*采用邻接表表示法，创建无向图G*/int CreateUDG_2(ALGraph &amp;G)&#123; int i, j, k; char v1, v2; scanf(&quot;%d%d&quot;, &amp;G.vexnum, &amp;G.arcnum); //输入总顶点数，总边数 getchar(); for (i = 0; i &lt; G.vexnum; i++) //输入各顶点，构造表头结点表 &#123; scanf(&quot;%c&quot;, &amp;G.vertices[i].data); //输入顶点值 G.vertices[i].firstarc = NULL; //初始化每个表头结点的指针域为NULL &#125; for (k = 0; k &lt; G.arcnum; k++) //输入各边，构造邻接表 &#123; getchar(); scanf(&quot;%c%c&quot;, &amp;v1, &amp;v2); //输入一条边依附的两个顶点 i = LocateVex(G, v1); //找到顶点i的下标 j = LocateVex(G, v2); //找到顶点j的下标 ArcNode *p1 = new ArcNode; //创建一个边结点*p1 p1-&gt;adjvex = j; //其邻接点域为j p1-&gt;nextarc = G.vertices[i].firstarc; G.vertices[i].firstarc = p1; // 将新结点*p插入到顶点v1的边表头部 ArcNode *p2 = new ArcNode; //生成另一个对称的新的表结点*p2 p2-&gt;adjvex = i; p2-&gt;nextarc = G.vertices[j].firstarc; G.vertices[j].firstarc = p1; &#125; return 1;&#125; 1234567891011121314151617181920212223242526/*采用邻接表表示图的广度优先遍历*/void BFS_AL(ALGraph &amp;G, char v0)&#123; int u,w,v; ArcNode *p; printf(&quot;%c &quot;, v0); //打印顶点v0 v = LocateVex(G, v0); //找到v0对应的下标 visited[v] = 1; //顶点v0已被访问 q.push(v0); //将顶点v0入队 while (!q.empty()) &#123; u = q.front(); //将顶点元素u出队，开始访问u的所有邻接点 v = LocateVex(G, u); //得到顶点u的对应下标 q.pop(); //将顶点u出队 for (p = G.vertices[v].firstarc; p; p = p-&gt;nextarc) //遍历顶点u的邻接点 &#123; w = p-&gt;adjvex; if (!visited[w]) //顶点p未被访问 &#123; printf(&quot;%c &quot;, G.vertices[w].data); //打印顶点p visited[w] = 1; //顶点p已被访问 q.push(G.vertices[w].data); //将顶点p入队 &#125; &#125; &#125;&#125; 3.4.非联通图的广度优先遍历的实现方法123456789/*广度优先搜索非连通图*/void BFSTraverse(AMGraph G)&#123; int v; for (v = 0; v &lt; G.vexnum; v++) visited[v] = 0; //将visited数组初始化 for (v = 0; v &lt; G.vexnum; v++) if (!visited[v]) BFS_AM(G, G.vexs[v]); //对尚未访问的顶点调用BFS&#125; 4.深度优先搜索 4.1算法的基本思路深度优先搜索类似于树的先序遍历，具体过程如下：准备工作：创建一个visited数组，用于记录所有被访问过的顶点。1.从图中v0出发，访问v0。 2.找出v0的第一个未被访问的邻接点，访问该顶点。以该顶点为新顶点，重复此步骤，直至刚访问过的顶点没有未被访问的邻接点为止。 3.返回前一个访问过的仍有未被访问邻接点的顶点，继续访问该顶点的下一个未被访问领接点。 4.重复2,3步骤，直至所有顶点均被访问，搜索结束。 4.2算法的实现过程1.初始时所有顶点均未被访问，visited数组为空。 图4-2-12.即将访问v0。 图4-2-23.访问v0，并将visited[0]的值置为1。 图4-2-34.访问v0的邻接点v2，判断visited[2]，因其值为0，访问v2。 图4-2-45.将visited[2]置为1。 图4-2-56.访问v2的邻接点v0，判断visited[0]，其值为1，不访问。 继续访问v2的邻接点v4，判断visited[4]，其值为0，访问v4。 图4-2-67.将visited[4]置为1。 图4-2-7 8.访问v4的邻接点v1，判断visited[1]，其值为0，访问v1。图4-2-89.将visited[1]置为1。 图4-2-910.访问v1的邻接点v0，判断visited[0]，其值为1，不访问。 继续访问v1的邻接点v4，判断visited[4]，其值为1，不访问。 继续访问v1的邻接点v5，判读visited[5]，其值为0，访问v5。 图4-2-1011.将visited[5]置为1。 图4-2-1112.访问v5的邻接点v1，判断visited[1]，其值为1，不访问。 继续访问v5的邻接点v3，判断visited[3]，其值为0，访问v3。 图4-2-1213.将visited[1]置为1。 图4-2-1314.访问v3的邻接点v0，判断visited[0]，其值为1，不访问。 继续访问v3的邻接点v5，判断visited[5]，其值为1，不访问。 v3所有邻接点均已被访问，回溯到其上一个顶点v5，遍历v5所有邻接点。 访问v5的邻接点v6，判断visited[6]，其值为0，访问v6。 图4-2-1415.将visited[6]置为1。 图4-2-1516.访问v6的邻接点v4，判断visited[4]，其值为1，不访问。 访问v6的邻接点v5，判断visited[5]，其值为1，不访问。 v6所有邻接点均已被访问，回溯到其上一个顶点v5，遍历v5剩余邻接点。图4-2-1617.v5所有邻接点均已被访问，回溯到其上一个顶点v1。 v1所有邻接点均已被访问，回溯到其上一个顶点v4，遍历v4剩余邻接点v6。 v4所有邻接点均已被访问，回溯到其上一个顶点v2。v2所有邻接点均已被访问，回溯到其上一个顶点v1，遍历v1剩余邻接点v3。v1所有邻接点均已被访问，搜索结束。图4-2-17 4.3具体代码实现4.3.1用邻接矩阵表示图的深度优先搜索邻接矩阵的创建在上述已描述过，这里不再赘述 12345678910void DFS_AM(AMGraph &amp;G, int v)&#123; int w; printf(&quot;%c &quot;, G.vexs[v]); visited[v] = 1; for (w = 0; w &lt; G.vexnum; w++) if (G.arcs[v][w]&amp;&amp;!visited[w]) //递归调用 DFS_AM(G,w);&#125; 4.3.2用邻接表表示图的深度优先搜素邻接表的创建在上述已描述过，这里不再赘述。 123456789101112131415void DFS_AL(ALGraph &amp;G, int v)&#123; int w; printf(&quot;%c &quot;, G.vertices[v].data); visited[v] = 1; ArcNode *p = new ArcNode; p = G.vertices[v].firstarc; while (p) &#123; w = p-&gt;adjvex; if (!visited[w]) DFS_AL(G, w); p = p-&gt;nextarc; &#125;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Hello 2019 B. Petr and a Combination Lock(二进制枚举 || dfs)","slug":"hello-2019-b-petr-and-a-combination-lock二进制枚举-dfs","date":"2020-04-09T10:20:52.000Z","updated":"2022-04-13T13:31:48.549Z","comments":true,"path":"2020/04/09/hello-2019-b-petr-and-a-combination-lock二进制枚举-dfs/","link":"","permalink":"https://tang7o.cn/2020/04/09/hello-2019-b-petr-and-a-combination-lock%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%9E%9A%E4%B8%BE-dfs/","excerpt":"","text":"题目链接: 题意：给你n个数字，让这n个数字相加减，如果是360的倍数或者是0就输出YES，否则输出NO。 思路：二进制枚举每一种状态，或者直接暴力搜索。 二进制枚举123456789101112131415161718192021#include&lt;bits/stdc++.h&gt;using namespace std;const int maxn=4005,inf=1e8;int a[maxn], n;int main()&#123; cin &gt;&gt; n; for(int i = 0; i &lt; n; i++) cin &gt;&gt; a[i]; for(int i = 1; i &lt; (1 &lt;&lt; n); i++) &#123; int sum = 0; for(int j = 0; j &lt; n; j++) &#123; if(i &amp; (1 &lt;&lt; j)) sum += a[j]; else sum -= a[j]; &#125; if( !sum !(sum % 360)) return puts(&quot;YES&quot;),0; &#125; puts(&quot;NO&quot;);&#125; DFS12345678910111213141516171819202122232425#include&lt;bits/stdc++.h&gt;using namespace std;const int maxn=4005,inf=1e8;int a[maxn], n;bool flag;void dfs(int x, int sum)&#123; if(x == n) &#123; if(!(sum % 360)) flag = true; return; &#125; dfs(x + 1, sum + a[x]); dfs(x + 1, sum - a[x]);&#125;int main()&#123; cin &gt;&gt; n; for(int i = 0; i &lt; n; i++) cin &gt;&gt; a[i]; flag = false; dfs(0,0); if(flag) puts(&quot;YES&quot;); else puts(&quot;NO&quot;); return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"题目","slug":"ACM/题目","permalink":"https://tang7o.cn/categories/ACM/%E9%A2%98%E7%9B%AE/"}],"tags":[{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"}]},{"title":"双向队列的简单讲解","slug":"双向队列的简单讲解","date":"2020-04-09T10:18:37.000Z","updated":"2022-04-13T13:31:48.880Z","comments":true,"path":"2020/04/09/双向队列的简单讲解/","link":"","permalink":"https://tang7o.cn/2020/04/09/%E5%8F%8C%E5%90%91%E9%98%9F%E5%88%97%E7%9A%84%E7%AE%80%E5%8D%95%E8%AE%B2%E8%A7%A3/","excerpt":"","text":"双向队列，顾名思义就是队列二边都可以操作的队列。 双向队列和向量很相似，但是它允许在容器头部快速插入和删除（就像在尾部一样）。双向都可以进行相应的操作。1234567891011121314151617181920212223Constructors 创建一个新双向队列Operators 比较和赋值双向队列assign() 设置双向队列的值at() 返回指定的元素back() 返回最后一个元素begin() 返回指向第一个元素的迭代器clear() 删除所有元素empty() 返回真如果双向队列为空end() 返回指向尾部的迭代器erase() 删除一个元素front() 返回第一个元素get\\_allocator() 返回双向队列的配置器insert() 插入一个元素到双向队列中max\\_size() 返回双向队列能容纳的最大元素个数pop\\_back() 删除尾部的元素pop\\_front() 删除头部的元素push\\_back() 在尾部加入一个元素push\\_front() 在头部加入一个元素rbegin() 返回指向尾部的逆向迭代器rend() 返回指向头部的逆向迭代器resize() 改变双向队列的大小size() 返回双向队列中元素的个数swap() 和另一个双向队列交换元素 看个例题 双向队列Description​ 想想双向链表……双向队列的定义差不多，也就是说一个队列的队尾同时也是队首；两头都可以做出队，入队的操作。 现在给你一系列的操作，请输出最后队列的状态； 命令格式： LIN X X表示一个整数，命令代表左边进队操作； RIN X 表示右边进队操作； ROUT LOUT 表示出队操作； Input第一行包含一个整数M(M&lt;=10000)，表示有M个操作； 以下M行每行包含一条命令； 命令可能不合法，对于不合法的命令，请在输出中处理； Output输出的第一行包含队列进行了M次操作后的状态，从左往右输出，每两个之间用空格隔开； 以下若干行处理不合法的命令（如果存在）； 对于不合法的命令，请输出一行X ERROR 其中X表示是第几条命令； Sample Input1234567898 LIN 5 RIN 6 LIN 3 LOUT ROUT ROUT ROUT LIN 3 Sample Output123 7 ERROR AC代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;queue&gt;#include &lt;deque&gt;#include &lt;algorithm&gt;using namespace std;#define MAX 10010int main()&#123; deque&lt;int&gt;q; //创建双向队列 while(!q.empty())//清空双向队列 q.pop_front(); int n,a,i,m[MAX]= &#123;0&#125;; scanf(&quot;%d&quot;,&amp;n); for(i=1; i&lt;=n; i++) &#123; char s[10]; scanf(&quot; %s&quot;,s); if(!strcmp(s,&quot;LIN&quot;)) &#123; scanf(&quot;%d&quot;,&amp;a); q.push_front(a); //在队列头（左边）存入数据 &#125; else if(!strcmp(s,&quot;RIN&quot;)) &#123; scanf(&quot;%d&quot;,&amp;a); q.push_back(a);//在队列尾（右边）存入数据 &#125; else if(!strcmp(s,&quot;LOUT&quot;)) &#123; if(!q.empty()) q.pop_front(); //如果队列非空删除队列头（最左边）的数据 else m[i]++; &#125; else if(!strcmp(s,&quot;ROUT&quot;)) &#123; if(q.empty()) m[i]++; else q.pop_back(); &#125; &#125; printf(&quot;%d&quot;,q.front()); q.pop_front(); while(!q.empty()) &#123; printf(&quot; %d&quot;,q.front());//输出队列中的数据 q.pop_front(); &#125; printf(&quot;\\n&quot;); for(i=1; i&lt;=n; i++) if(m[i]) printf(&quot;%d ERROR\\n&quot;,i); return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"优先队列简单讲解","slug":"优先队列简单讲解","date":"2020-04-09T10:14:13.000Z","updated":"2022-04-13T13:31:48.811Z","comments":true,"path":"2020/04/09/优先队列简单讲解/","link":"","permalink":"https://tang7o.cn/2020/04/09/%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97%E7%AE%80%E5%8D%95%E8%AE%B2%E8%A7%A3/","excerpt":"","text":"优先队列就是会自动排序的队列； 头文件`#include ； 声明格式为：priority_queue ans;//声明一个名为ans的整形的优先队列` 基本操作有： 12345empty( ) //判断一个队列是否为空 pop( ) //删除队顶元素 top( ) //返回优先队列的队顶元素 push( ) //加入一个元素 size( ) //返回优先队列中的元素个数 默认的优先队列优先级高的排在前面，既优先级高的先出队列。 例如int型的优先队列数值大的排在前面、先出队列。 默认优先队列使用方法（优先级高先出队列）：1priority_queue&lt;int&gt; q1; //默认从大到小排序，整数中元素大的优先级高 1234567891011121314151617181920212223242526#include&lt;cstdio&gt;#include&lt;queue&gt;using namespace std;int main()&#123; priority_queue&lt;int&gt; q1;//默认从大到小排序 if(!q1.empty()) q1.top(); //清空优先队列 int n; scanf(&quot;%d&quot;,&amp;n); int t; for(int i=1;i&lt;=n;i++) &#123; scanf(&quot;%d&quot;,&amp;t); q1.push(t); &#125; while(!q1.empty()) &#123; printf(&quot;%d &quot;,q1.top()); q1.pop(); &#125; return 0;&#125; 执行结果如下： 从大到小排序（优先级低的先出）；12priority_queue&lt;int,vector&lt;int&gt;,greater&lt;int&gt; &gt;q1; 1234567891011121314151617181920212223242526#include&lt;cstdio&gt;#include&lt;queue&gt;using namespace std;int main()&#123; priority_queue&lt;int,vector&lt;int&gt;,greater&lt;int&gt; &gt;q1;//从大到小排序，注意后面两个“&gt;”不要写在一起，“&gt;&gt;”是右移运算符 if(!q1.empty()) q1.top(); //清空优先队列 int n; scanf(&quot;%d&quot;,&amp;n); int t; for(int i=1;i&lt;=n;i++) &#123; scanf(&quot;%d&quot;,&amp;t); q1.push(t); &#125; while(!q1.empty()) &#123; printf(&quot;%d &quot;,q1.top()); q1.pop(); &#125; return 0;&#125; 执行结果如下： 自定义排序：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include&lt;cstdio&gt;#include&lt;queue&gt;using namespace std;int tmp[100];struct cmp1&#123; bool operator()(int x,int y) &#123; return x&gt;y;//小的优先级高 ,从小到大排 &#125;&#125;;struct cmp2&#123; bool operator()(const int x,const int y) &#123; return tmp[x]&gt;tmp[y]; &#125;&#125;;struct node&#123; int x,y; friend bool operator&lt;(node a,node b) &#123; return a.x&gt;b.x;//按x从小到大排 &#125;&#125;;priority_queue&lt;int&gt;q1;priority_queue&lt;int,vector&lt;int&gt;,cmp1&gt;q2;priority_queue&lt;int,vector&lt;int&gt;,cmp2&gt;q3;priority_queue&lt;node&gt;q4;int main()&#123; int i,n; node a; while(~scanf(&quot;%d&quot;,&amp;n)) &#123; for(i=0;i&lt;n;i++) &#123; scanf(&quot;%d %d&quot;,&amp;a.y,&amp;a.x); q4.push(a); &#125; printf(&quot;\\n&quot;); while(!q4.empty()) &#123; printf(&quot;%d %d\\n&quot;,q4.top().y,q4.top().x); q4.pop(); &#125; printf(&quot;\\n&quot;); int t; for(i=0;i&lt;n;i++) &#123; scanf(&quot;%d&quot;,&amp;t); q2.push(t); &#125; while(!q2.empty()) &#123; printf(&quot;%d\\n&quot;,q2.top()); q2.pop(); &#125; printf(&quot;\\n&quot;); &#125; return 0;&#125; 执行结果如下： 下面举个栗子： 题目链接 Stall ReservationsDescriptionOh those picky N (1 &lt;= N &lt;= 50,000) cows! They are so picky that each one will only be milked over some precise time interval A…B (1 &lt;= A &lt;= B &lt;= 1,000,000), which includes both times A and B. Obviously, FJ must create a reservation system to determine which stall each cow can be assigned for her milking time. Of course, no cow will share such a private moment with other cows. Help FJ by determining: The minimum number of stalls required in the barn so that each cow can have her private milking period An assignment of cows to these stalls over time Many answers are correct for each test dataset; a program will grade your answer. InputLine 1: A single integer, N Lines 2…N+1: Line i+1 describes cow i’s milking interval with two space-separated integers. OutputLine 1: The minimum number of stalls the barn must have. Lines 2…N+1: Line i+1 describes the stall to which cow i will be assigned for her milking period. Sample Input5 1 10 2 4 3 6 5 8 4 7 Sample Output4 1 2 3 2 4 题意： 思路 AC代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;cstdio&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;using namespace std;const int Maxn=5e4+5;typedef struct node&#123; int b,e,stall,id; friend bool operator&lt; (node n1,node n2) &#123; return n1.e &gt; n2.e; &#125;&#125; cow;cow s[Maxn];bool cmp1(cow x,cow y)&#123; return x.b &lt; y.b;&#125;bool cmp2(cow x,cow y)&#123; return x.id &lt; y.id;&#125;int main()&#123; int N; while(~scanf(&quot;%d&quot;,&amp;N)) &#123; for(int i = 0; i &lt; N; i++) &#123; scanf(&quot;%d%d&quot;,&amp;s[i].b,&amp;s[i].e); s[i].id = i; &#125; sort(s,s+N,cmp1); priority_queue&lt;cow&gt; que; s[0].stall = 1; que.push(s[0]); int cnt = 1; for(int i = 1; i &lt; N; i++) &#123; cow temp = que.top(); if(s[i].b &lt;= temp.e) &#123; cnt++; s[i].stall = cnt; que.push(s[i]); &#125; else &#123; s[i].stall = temp.stall; que.pop(); que.push(s[i]); &#125; &#125; sort(s,s+N,cmp2); printf(&quot;%d\\n&quot;,cnt); for(int i = 0; i &lt; N; i++) printf(&quot;%d\\n&quot;,s[i].stall); &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"栈的简单讲解","slug":"栈的简单讲解","date":"2020-04-09T10:06:15.000Z","updated":"2022-04-13T13:31:49.065Z","comments":true,"path":"2020/04/09/栈的简单讲解/","link":"","permalink":"https://tang7o.cn/2020/04/09/%E6%A0%88%E7%9A%84%E7%AE%80%E5%8D%95%E8%AE%B2%E8%A7%A3/","excerpt":"","text":"栈stack的特征：后进先出 可以把栈想象成一个木桶，后放进去的东西先拿出来； C++队列queue类成员函数如下: push(): 向栈内压入一个成员； pop(): 从栈顶弹出一个成员； empty(): 如果栈为空返回true，否则返回false； top(): 返回栈顶，但不删除成员； size(): 返回栈内元素的大小； 下面看个例题: 括号配对问题Description现在有一种只包括左右小括号（“（”和“）”）和空格（” “）的字符串序列，请你判断括号是否匹配，如果匹配就输出Yes，不匹配输出No。 Input输入数据第一行输入一个T（0≤T≤100），表示测试数据的组数。 接下来有T行测试数据，每行有一个符合题意的字符串，字符串长度不超过500。 Output每组测试数据，先输出一个”Case %d：“，%d表示第几组测试数据。接着，如果字符串括号匹配，输出Yes，否则，输出No。具体输出格式参考下面输出样例。 Sample Input2 ( ()) )( Sample OutputCase 1:Yes Case 2:No 思路：遇到 ‘(’ 就存到栈里，遇到 ‘)’ 就检测栈是否为空，若为空输出No，否则删掉栈最上面的成员 ，字符串读完后如果栈内还有数据，即栈里还有 ‘(’ ，输出No，若栈为空，输出Yes AC代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;cstdio&gt;#include&lt;algorithm&gt;#include&lt;stack&gt;using namespace std;int main()&#123; stack&lt;char&gt;p; char s[505]; int n,i,x=0;; scanf(&quot;%d&quot;,&amp;n); getchar(); while(n--) &#123; x++; while(!p.empty()) p.pop(); gets(s); printf(&quot;Case %d:&quot;,x); for(i=0; s[i]!=0; i++) &#123; if(s[i]==&#x27;(&#x27;) p.push(s[i]); if(s[i]==&#x27;)&#x27;) &#123; if(p.empty()) &#123; break; &#125; p.pop(); &#125; &#125; if(s[i]==0&amp;&amp;p.empty()) &#123; printf(&quot;Yes\\n&quot;); &#125; else printf(&quot;No\\n&quot;); &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"队列的简单讲解","slug":"队列的简单讲解","date":"2020-04-09T10:02:18.000Z","updated":"2022-04-13T13:31:49.249Z","comments":true,"path":"2020/04/09/队列的简单讲解/","link":"","permalink":"https://tang7o.cn/2020/04/09/%E9%98%9F%E5%88%97%E7%9A%84%E7%AE%80%E5%8D%95%E8%AE%B2%E8%A7%A3/","excerpt":"","text":"队列queue的特征：先进先出可以简单将队列看成一个通道，从通道的一头进从另外一头出。 头文件： #include&lt;queue&gt; C++队列queue类成员函数如下: back()返回最后一个元素 empty()如果队列空则返回真 front()返回第一个元素 pop()删除第一个元素 push()在末尾加入一个元素 size()返回队列中元素的个数 下面看个简单的例题 约瑟夫环Description题目：n个数字（1,2,3…,n）形成一个圆圈，从数字1开始，每次从这个圆圈中删除第m个数字（第一个为当前数字本身，第二个为当前数字的下一个数字）。 当一个数字删除后，从被删除数字的下一个继续删除第m个数字。 求出在这个圆圈中剩下的最后一个数字。 Inputn=9 m=5 OutputThe last one is 8 Sample Input9 5 Sample Output8 思路：把所有数字存入队列，把队列中的第一个数据存入队列并删除第一个数据，第m个数据不存入队列就OK了 AC代码如下： 123456789101112131415161718192021222324252627282930313233343536#include &lt;cstdio&gt;#include &lt;stack&gt;#include &lt;queue&gt;#include &lt;algorithm&gt;using namespace std;int main()&#123; queue&lt;int&gt;p; //开辟队列 int n,m,x=0,i; while(!p.empty()) //清空队列 p.pop(); scanf(&quot;%d%d&quot;,&amp;n,&amp;m); for(i=1; i&lt;=n; i++) &#123; p.push(i); //把数据存入队列 &#125; i=0; while(1) &#123; x++; if(x!=5) //如果不是你要删掉的那个数据 就存到队列最后 p.push(p.front()); else x=0; //删除一个数据后要重新计数 p.pop(); //删除队列中第一个数据 if(p.size()==1) &#123; //如果还剩一个数据 输出该数据 printf(&quot;%d\\n&quot;,p.front()); break; &#125; &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"会场安排问题 （贪心算法）","slug":"会场安排问题 （贪心算法）","date":"2020-04-09T09:56:25.000Z","updated":"2022-04-13T13:31:48.825Z","comments":true,"path":"2020/04/09/会场安排问题 （贪心算法）/","link":"","permalink":"https://tang7o.cn/2020/04/09/%E4%BC%9A%E5%9C%BA%E5%AE%89%E6%8E%92%E9%97%AE%E9%A2%98%20%EF%BC%88%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%EF%BC%89/","excerpt":"","text":"题目如下Description假设要在足够多的会场里安排一批活动，并希望使用尽可能少的会场。设计一个有效的贪心算法进行安排。（这个问题实际上是著名的图着色问题。若将每一个活动作为图的一个顶点，不相容活动间用边相连。使相邻顶点着有不同颜色的最小着色数，相应于要找的最小会场数。） 对于给定的k个待安排的活动，计算使用最少会场的时间表。 Input输入数据的第一行有1 个正整数k（k≤10000），表示有k个待安排的活动。接下来的k行中，每行有2个正整数，分别表示k个待安排的活动开始时间和结束时间。时间以0 点开始的分钟计。 Output输出一个整数，表示最少会场数。 Sample Input5 1 23 12 28 25 35 27 80 36 50 Sample Output3 本来一开始是用的优先队列和快排，AC之后又发现了一个更快的方法（其实就是偷看的 优先队列AC代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;cstdio&gt;#include &lt;stack&gt;#include &lt;queue&gt;#include &lt;cmath&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;using namespace std;typedef long long ll;const int Maxn=1e4+5;typedef struct node&#123; int Ti_s,Ti_e; bool operator &lt;(const struct node &amp;a)const &#123; if(Ti_e==a.Ti_e) return Ti_s&gt;a.Ti_s; return Ti_e&gt;a.Ti_e; &#125;&#125; JM;bool cmp(JM a,JM b)&#123; return a.Ti_s&lt;b.Ti_s;&#125;int main()&#123; int n; scanf(&quot;%d&quot;,&amp;n); priority_queue&lt;JM&gt; q; JM jm[Maxn]; int i,ans=n; for(i=0; i&lt;n; i++) scanf(&quot;%d%d&quot;,&amp;jm[i].Ti_s,&amp;jm[i].Ti_e); sort(jm,jm+n,cmp); q.push(jm[0]); for(i=1; i&lt;n; i++) &#123; JM p; p=q.top(); if(jm[i].Ti_s&gt;=p.Ti_e) &#123; q.pop(); ans--; q.push(jm[i]); &#125; else &#123; q.push(jm[i]); &#125; &#125; printf(&quot;%d\\n&quot;,ans);&#125; 另一种方法（不得不说这种方法是真的厉害 1234567891011121314151617181920212223242526272829303132333435#include &lt;cstdio&gt;#include &lt;stack&gt;#include &lt;queue&gt;#include &lt;cmath&gt;#include &lt;cctype&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;#define mem(a,b) memset(a,b,sizeof (a))using namespace std;typedef long long ll;const int Maxn=1e4+5;int main()&#123; int n,a[Maxn],b[Maxn],i,ans=0,j=0; scanf(&quot;%d&quot;,&amp;n); for(i=0;i&lt;n;i++) &#123; scanf(&quot;%d %d&quot;,a+i,b+i); &#125; sort(a,a+n); sort(b,b+n); for(i=0;i&lt;n;i++) &#123; if(a[i]&lt;b[j]) ans++; else j++; &#125; printf(&quot;%d\\n&quot;,ans);&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"题目","slug":"ACM/题目","permalink":"https://tang7o.cn/categories/ACM/%E9%A2%98%E7%9B%AE/"}],"tags":[{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"}]},{"title":"GCD EXGCD","slug":"gcd","date":"2020-04-09T09:47:16.000Z","updated":"2022-04-13T13:31:48.521Z","comments":true,"path":"2020/04/09/gcd/","link":"","permalink":"https://tang7o.cn/2020/04/09/gcd/","excerpt":"","text":"GCD原理：a=b*q+r1; (a,b)==(b1,r1) ）( (a，b)为a，b的最小公约数） 代码如下： 1234567int gcd(int a,int b)&#123; if(b==0) return a; gcd(b,a%b);&#125; EXGCD1234void exgcd(ll a,ll b,ll &amp;x,ll &amp;y)&#123; if(b==0)&#123;x=1;y=0;&#125; else &#123;exgcd(b,a%b,y,x);y-=(a/b)*x;&#125;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"模板","slug":"模板","permalink":"https://tang7o.cn/tags/%E6%A8%A1%E6%9D%BF/"}]},{"title":"快速乘与快速幂","slug":"快速乘与快速幂","date":"2020-04-09T09:44:10.000Z","updated":"2022-04-13T13:31:48.940Z","comments":true,"path":"2020/04/09/快速乘与快速幂/","link":"","permalink":"https://tang7o.cn/2020/04/09/%E5%BF%AB%E9%80%9F%E4%B9%98%E4%B8%8E%E5%BF%AB%E9%80%9F%E5%B9%82/","excerpt":"","text":"快速乘：(a*b)%c原理：将b转化为二进制的形式 用b每一位的权重乘a再相加举个例子：$20 10=20(1010)_2=(202^31) + (202^20) + (202^11) + (202^00)=160+40=200$代码如下：123456789101112int fast_mul(int a,int b,int c)&#123; int ans=0; while(b) &#123; if(b%2) ans=ans%c+a%c; a=(a%c+a%c)%c; b/=2; &#125; return ans;&#125; 快速幂：(a^b)%c原理：将b转化为二进制的形式 用a^(b每一位的权重的和)举个例子： 11的二进制是1011, 11 = 2³×1 + 2²×0 + 2¹×1 + 2º×1，我们将a¹¹转化为算 $a^ {11}=a^ {(2^ 0+2^ 1+2^ 3)}=a^ {2^ 0}a^ {2^ 1}a^ {2^3}$代码如下： 123456789101112int fast_pow(int a,int b,int c)&#123; int ans=1; while(b) &#123; if(b%2) ans=(ans%c*a%c)%c; a=(a%c*a%c)%c; b/=2; &#125; return ans;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"素数打表","slug":"素数打表","date":"2020-04-08T08:47:52.000Z","updated":"2022-04-13T13:31:49.153Z","comments":true,"path":"2020/04/08/素数打表/","link":"","permalink":"https://tang7o.cn/2020/04/08/%E7%B4%A0%E6%95%B0%E6%89%93%E8%A1%A8/","excerpt":"","text":"哈希打表1234567891011121314#include&lt;stdio.h&gt;int main()&#123; int s[10000]=&#123;0&#125;,a,b,i,j; for(i=2;i&lt;10000;i++) //素数从2开始 if(s[i]==0) for(j=i*i;j&lt;10000;j+=i) s[j]=1; //将素数的倍数(即非素数）都标记为1 scanf(&quot;%d%d&quot;,&amp;a,&amp;b); for(i=a;i&lt;=b;i++) if(s[i]==0) printf(&quot;%d &quot;,i); return 0;&#125; 网上看到的一种方法除2，3以外，所有的素数要么是6的倍数加1，要么减1； 123456789101112131415prime[2]=prime[3]=1;for (int i=5; i&lt;10000; i++)&#123; if ((i+1)%6==0||(i-1)%6==0) &#123; int j; for (j=2; j&lt;(int)(sqrt(i)+1); j++) &#123; if (i%j==0) break; &#125; if (j==(int)(sqrt(i)+1)) prime[i]=1; &#125;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"操作系统复习资料","slug":"操作系统复习资料","date":"2019-08-17T09:04:37.000Z","updated":"2022-04-13T13:31:48.982Z","comments":true,"path":"2019/08/17/操作系统复习资料/","link":"","permalink":"https://tang7o.cn/2019/08/17/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%A4%8D%E4%B9%A0%E8%B5%84%E6%96%99/","excerpt":"","text":"本文章转载于：Gleaming、Reserendipity 基本定义 并发：是指两个或多个事件在同一时间间隔内发生。 并行：是指两个或多个事件在同一时刻发生。 并发条件：读集与写集是空集、写集和写集是空集。 并发执行特征：失去了封闭性和可再现性。 共享性：是指计算机系统中的各种硬、软件资源都可以为多个用户同时使用。 虚拟性：一方面指把物理上的一个实体变成逻辑上的多个对应物，另一方面指虚拟出来的对应物只不过是用户主观上的一种错觉。 管态：操作系统的管理程序在执行 CPU 所处的状态，又称为系统态。 目态：用户程序在执行 CPU 所处的状态，又称为用户态。 进程特性：动态性、并发性、独立性、异步性、结构特性。 进程与程序的区别： 从定义上看，进程是程序处理数据的过程，而程序是一组指令的有序集合； 进程具有动态性、并发性、独立性和异步性等，而程序不具有这些特性； 从进程结构特性来看，他包含程序（以及数据和 PCB ）； 进程和程序并非一一对应； 进程的三种状态：就绪，执行，阻塞。 临界区：进程中访问临界资源的那段程序代码成为临界区或临界段。 临界区的使用原则：空则让进，忙则等待，等则有限，等则让权。 上锁和开锁的原语 上锁原语：LOCK(W) L1:如果 W=1 那么转向L1； 否则 W=1 返回 开锁原语：UNLOCK(W) W=0; 返回 信号量基本物理含义：当信号量值大于零时表示系统中某类资源的数目；当信号量值小于零时，其绝对值为系统中因请求该类资源而被阻塞的进程数目。 信号量的值的意义： 正数：资源数； 负数：等待资源进程数； 同步、互斥的区别：进程互斥是让各个进程竞争共享资源，资源的使用是各自独立的，相互之间无必然联系；进程同步时并发进程对共享资源的使用必须按照某种逻辑顺序来进行。 死锁定于：两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象。 产生死锁的必要条件： 互斥条件 占有并请求条件。 不可剥夺条件 循环等待条件。 物理地址：内存单元的地址编号，又称绝对地址或实地址。 逻辑地址：用户程序中使用的地址，又称相对地址或虚地址。 静态重定位：在程序执行过程之前由装入程序完成的重定位过程。 动态重定位：在程序执行过程中，由硬件地址变换机构实现重定位的过程。 虚拟内存：一种利用虚拟储存器来逻辑扩充物理内存的技术。 快表：一组相关联寄存器，具有并行能力。用来存在当前最长访问的那些页面的页表目内容。 二级页表：为节约内存，氛围二级页表结构。第一级用１ｋ个表相，每项４个字节，占４KB内存；第二级再用１０位，这样二级表组合起来即可达到１MB个表项。 中断：是指计算机在执行期间，系统内发生了某一急需处理的事件，使得CPU暂时终止当前正在执行的程序而转去执行相应的事件处理程序，待处理完毕后再返回到刚才暂停程序的被中断处继续执行。 I/O通道：是指专门用于负责输入/输出工作的处理机，是大型机必备的为CPU减负的设备。 缓冲技术：在CPU和外设之间设立缓冲区，用以暂存CPU和外设之间交换的数据，从而缓和CPU和外设速度不匹配所产生的矛盾。 I/O控制方式：程序直接控制方式、中断控制方式、DMA控制方式、通道控制方式。 文件物理结构：从系统角度看到的文件信息的组织形式。 算法银行家算法假定系统中有五个进程{P0、P1、P2、P3、P4}和三类资源{A、B、C}，各种资源的数量分别是10、5、7，在T0时刻的资源分配情况如下图所示： 1）判断在T0时刻的安全性。 MAX：进程所需的资源 Allocation：系统已经分配给进程的资源数 Need：进程还需要的资源数 Need = MAX - Allocation Available：系统剩余的资源数 Available =Total - Allocation Work：当前系统所剩资源 work+allocation：计算机处理完当前进程后所剩资源 所以在T0时刻有安全序列{P1，P3，P4，P2，P0}，所以T0时刻是安全的。 2）P1请求资源：P1发出请求向量Request（1，0，2），系统按照银行家算法进行检查。 判断步骤： 先判断请求是否小于等于所需：Request（1，0，2）&lt;= Need(1，2，2) 判断请求的是否小于等于系统还剩的：Request（1，0，2）&lt;=Allocation（3，3，2） 根据请求资源量进行分配（更改表） 列表计算 更改表： 结果： 所以P1可以请求成功。 页面置换算法缺页：当前物理页面中不存在的页面 缺页次数：出现缺页的次数 缺页率：缺页次数/总页数 先进先出算法 FIFO 置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。 按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。但是该算法会淘汰经常访问的页面，不适应进程实际运行的规律，目前已经很少使用。 P 2 3 2 1 5 2 4 5 3 2 5 2 0 2 2 2 2 5 5 5 5 3 3 3 3 1 3 3 3 3 2 2 2 2 2 5 5 2 1 1 1 4 4 4 4 4 2 F=9 Y Y Y Y Y Y Y Y Y 缺页率：9/12*100%=75% 最佳置换算法 OPT 被淘汰的页面将是在未来最长的时间内不再被访问的页面 缺页中断率最低，但是该算法需要依据以后各业的使用情况，而当一个进程还未运行完成是，很难估计哪一个页面是以后不再使用或在最长时间以后才会用到的页面。所以该算法是不能实现的。 P: 2 3 2 1 5 2 4 5 3 2 5 2 M=3 2 2 2 2 2 2 4 4 4 4 4 4 3 3 3 3 3 3 3 3 2 2 2 1 5 5 5 5 5 5 5 5 F=6 Y Y Y Y Y Y 缺页率：6/12*100%=50% 最近最少使用算法LRU 置换最近一段时间以来最长时间未访问过的页面 P 2 3 2 1 5 2 4 5 3 2 5 2 0 2 2 2 2 2 2 2 2 3 3 3 3 1 3 3 3 5 5 5 5 5 5 5 5 2 1 1 1 4 4 4 2 2 2 F=7 Y Y Y Y Y Y Y 缺页率：7/12*100%=58.3% 计算物理地址在采用页式存储管理的系统中，某进程的逻辑地址空间为4页（每页2048字节），已知该进程的页面映像表（页表）如下： 页号 块号 0 2 1 4 2 6 3 8 计算有效逻辑地址4865所对应的物理地址。 地址转换：绝对地址=块号×块长+块内地址 求页号： d = 4865%2048=2……769 对页表：找到块号 6 算地址：物理地址=6*2048+769=13057 磁盘调度一个磁盘驱动器有150个柱面，考虑一个磁盘序列，它按照到达时间顺序分别是35、52、37、17、80、120、135、104，如果读写磁头最初位于柱面90，请使用FCFS、SSTF、SCAN、CSCAN算法求总寻道长度和平均寻道长度。 先来先服务算法 FCFS磁头移动顺序： ​ 90 -&gt; 35 -&gt; 52 -&gt; 37 -&gt; 17 -&gt; 80 -&gt; 120 -&gt; 135 -&gt; 104 总寻道长度 = (90-35) + (52-35) + (52-37) + (37-17) + (80-17) + (120-80) + (135-120) + (135-104) = 256 平均寻道长度 = 总长/移动次数 = 256/8 = 32; 最短寻道时间优先 SSTF先把磁盘序列的时间按照从小到大的顺序排列，磁头从开始柱面移动到距离开始柱面最近的柱面，然后从这个柱面移动到到离这个柱面最近的柱面，以此类推，直到访问所有的柱面。 17 35 37 52 80 90 104 120 135 17 35 37 52 80 90 104 120 135 17 35 37 52 80 90 104 120 135 17 35 37 52 80 90 104 120 135 17 35 37 52 80 90 104 120 135 17 35 37 52 80 90 104 120 135 17 35 37 52 80 90 104 120 135 17 35 37 52 80 90 104 120 135 17 35 37 52 80 90 104 120 135 磁头移动顺序： ​ 90 -&gt; 80 -&gt; 104 -&gt; 120 -&gt; 135 -&gt; 52 -&gt; 37 -&gt; 35 -&gt; 17 扫描算法 SCAN17 35 37 52 80 90 104 120 135 磁头从初始柱面向左（右）扫描，一直到头，然后向右（左）扫描。 磁头移动顺序： 向左：90 -&gt; 80 -&gt; 52 -&gt; 37 -&gt; 35 -&gt; 17 -&gt; 104 -&gt; 120 -&gt; 135 向右：90 -&gt; 104 -&gt; 120 -&gt; 135 -&gt; 80 -&gt; 52 -&gt; 37 -&gt; 35 -&gt; 17 循环扫描算法 C-SCAN17 35 37 52 80 90 104 120 135 磁头移动顺序： 向左：90 -&gt; 80 -&gt; 52 -&gt; 37 -&gt; 35 -&gt; 17 -&gt; 135 -&gt; 120 -&gt; 104 向右：90 -&gt; 104 -&gt; 120 -&gt; 135 -&gt; 17 -&gt; 35 -&gt; 37 -&gt; 52 -&gt; 80 向左（右）到头，然后因为是圆形有150个柱面，所以直接转了一圈，计算总寻道长度的时候注意 进程调度从P1到P4有四个进程，每个进程的到达时间和运行时间如下表所示： 进程 到达时间 执行时间 P1 0 8 P2 1 4 P3 2 9 P4 3 5 求FCFS和SJF的平均等待时间、平均周转时间和平均带权周转时间。 先来先服务算法 FCFS按照进程到达的先后次序 ： ​ P1 -&gt; P2 -&gt; P3 -&gt; P4 进程 到达时间 执行时间 开始时间 结束时间 等待时间 周转时间 带权周转时间 P1 0 8 0 8 0 8 1 P2 1 4 8 12 7 11 2.75 P3 2 9 12 21 10 19 2.11 P4 3 5 21 26 18 23 4.6 等待时间 = 开始时间 - 到达时间 周转时间 = 结束时间 - 到达时间 带权周转时间 = 周转时间/执行时间 平均等待时间 = 等待时间/进程数 平均周转时间 = 周转时间/进程数 平均带权周转时间 = 带权周转时间/进程数 短作业优先调度算法 SJF按照进程的长短，进程越短越优先 非抢占 P1 -&gt; P2 -&gt; P4 -&gt; P3 进程 到达时间 执行时间 开始时间 结束时间 等待时间 周转时间 带权周转时间 P1 0 8 0 8 0 8 1 P2 1 4 8 12 7 11 2.75 P4 3 5 12 17 9 14 2.8 P3 2 9 17 26 15 24 2.66 抢占 P1 -&gt; P2 -&gt; P4 -&gt; P1 -&gt; P3 进程 到达时间 执行时间 开始时间 结束时间 等待时间 周转时间 带权周转时间 P1 0 8/7 0/10 1/17 P2 1 4 1 5 P3 2 9 17 26 P4 3 5 5 10","categories":[],"tags":[]}],"categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/categories/MySQL/"},{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"},{"name":"HTTPS","slug":"网络/HTTPS","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/HTTPS/"},{"name":"OS","slug":"OS","permalink":"https://tang7o.cn/categories/OS/"},{"name":"HTTP","slug":"网络/HTTP","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/HTTP/"},{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/categories/Redis/"},{"name":"TCP","slug":"网络/TCP","permalink":"https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/TCP/"},{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://tang7o.cn/categories/Java/%E5%B9%B6%E5%8F%91/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://tang7o.cn/categories/Java/JVM/"},{"name":"Linux","slug":"Linux","permalink":"https://tang7o.cn/categories/Linux/"},{"name":"ACM","slug":"ACM","permalink":"https://tang7o.cn/categories/ACM/"},{"name":"模板","slug":"ACM/模板","permalink":"https://tang7o.cn/categories/ACM/%E6%A8%A1%E6%9D%BF/"},{"name":"算法","slug":"ACM/算法","permalink":"https://tang7o.cn/categories/ACM/%E7%AE%97%E6%B3%95/"},{"name":"题目","slug":"ACM/题目","permalink":"https://tang7o.cn/categories/ACM/%E9%A2%98%E7%9B%AE/"},{"name":"MarkDown","slug":"MarkDown","permalink":"https://tang7o.cn/categories/MarkDown/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tang7o.cn/tags/MySQL/"},{"name":"网络","slug":"网络","permalink":"https://tang7o.cn/tags/%E7%BD%91%E7%BB%9C/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://tang7o.cn/tags/HTTPS/"},{"name":"OS","slug":"OS","permalink":"https://tang7o.cn/tags/OS/"},{"name":"HTTP","slug":"HTTP","permalink":"https://tang7o.cn/tags/HTTP/"},{"name":"Redis","slug":"Redis","permalink":"https://tang7o.cn/tags/Redis/"},{"name":"分布式","slug":"分布式","permalink":"https://tang7o.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"TCP","slug":"TCP","permalink":"https://tang7o.cn/tags/TCP/"},{"name":"Java","slug":"Java","permalink":"https://tang7o.cn/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://tang7o.cn/tags/%E5%B9%B6%E5%8F%91/"},{"name":"final","slug":"final","permalink":"https://tang7o.cn/tags/final/"},{"name":"JWT","slug":"JWT","permalink":"https://tang7o.cn/tags/JWT/"},{"name":"Roaring Bitmap","slug":"Roaring-Bitmap","permalink":"https://tang7o.cn/tags/Roaring-Bitmap/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://tang7o.cn/tags/Elasticsearch/"},{"name":"Kafka","slug":"Kafka","permalink":"https://tang7o.cn/tags/Kafka/"},{"name":"JVM","slug":"JVM","permalink":"https://tang7o.cn/tags/JVM/"},{"name":"Linux","slug":"Linux","permalink":"https://tang7o.cn/tags/Linux/"},{"name":"算法","slug":"算法","permalink":"https://tang7o.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"模板","slug":"模板","permalink":"https://tang7o.cn/tags/%E6%A8%A1%E6%9D%BF/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://tang7o.cn/tags/SpringBoot/"},{"name":"环境配置","slug":"环境配置","permalink":"https://tang7o.cn/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"题目","slug":"题目","permalink":"https://tang7o.cn/tags/%E9%A2%98%E7%9B%AE/"},{"name":"知识","slug":"知识","permalink":"https://tang7o.cn/tags/%E7%9F%A5%E8%AF%86/"},{"name":"MarkDwon","slug":"MarkDwon","permalink":"https://tang7o.cn/tags/MarkDwon/"},{"name":"C++","slug":"C","permalink":"https://tang7o.cn/tags/C/"}]}