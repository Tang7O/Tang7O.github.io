<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tang7O&#39;S BLOG</title>
  
  
  <link href="https://tang7o.cn/atom.xml" rel="self"/>
  
  <link href="https://tang7o.cn/"/>
  <updated>2022-05-13T11:50:51.788Z</updated>
  <id>https://tang7o.cn/</id>
  
  <author>
    <name>Tang7O</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>HTTP/2特性</title>
    <link href="https://tang7o.cn/2022/05/13/HTTP-2%E7%89%B9%E6%80%A7/"/>
    <id>https://tang7o.cn/2022/05/13/HTTP-2%E7%89%B9%E6%80%A7/</id>
    <published>2022-05-13T07:39:06.000Z</published>
    <updated>2022-05-13T11:50:51.788Z</updated>
    
    <content type="html"><![CDATA[<h3 id="二进制分帧"><a href="#二进制分帧" class="headerlink" title="二进制分帧"></a>二进制分帧</h3><ul><li><p>帧：HTTP/2 数据通信的最小单位消息：指 HTTP/2 中逻辑上的 HTTP 消息。例如请求和响应等，消息由一个或多个帧组成。</p></li><li><p>流：存在于连接中的一个虚拟通道。流可以承载双向消息，每个流都有一个唯一的整数ID。</p></li></ul><p>HTTP/2 采用二进制格式传输数据，而非 HTTP/1.x 的文本格式，二进制协议解析起来更加高效。HTTP/1 的请求和响应报文都是由起始行、首部、正文（可选）组成，各个部分之间以文本换行符分割。HTTP/2 将请求和响应报文分割为更小的帧，并且采用二进制编码。</p><p><strong>HTTP/2 中，同域名下的所有通信的都在单个连接上完成，该连接可以承载任意数量的双向数据流。</strong>每个数据流都以消息的形式发送，而消息又由一个或者多个帧组成。多个帧之间可以乱序发送，根据帧首部的流标识可以重新组装。</p><h3 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h3><p>多路复用代替原来的序列和阻塞机制。所有请求都是通过一个TCP连接完成。HTTP/1.x 中，如果想要并发多个请求，必须使用多个 TCP 连接，且浏览器为了控制资源，还有每个域名 6-8 个TCP链接的请求限制。</p><p>在 HTTP/2 中，有了二进制分帧之后，HTTP/2 不再依赖 TCP 链接去实现多流并行了，在 HTTP/2 中：</p><ul><li>同域名下的所有通信都在单个连接上完成。</li><li>单个连接可以承载任意数量的双向数据流。</li><li>数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，可以根据帧首部的流标识重新组装。</li></ul><p>这一特性，使性能得到了极大的提升：</p><ul><li><strong>同域名只需要占用一个 TCP 连接，</strong>消除了多个 TCP 连接带来的延时和内存消耗。</li><li>单个连接上可以并行交错的请求和响应，之间互不干扰。</li><li>在 HTTP/2 中，每个请求都可以带一个 31bit 的优先值，0 表示最高优先级，数值越大优先级越低。有了这个优先值，客户端和服务器就可以在处理不同的流时采取不同的策略，以最优的方式发送流、消息和帧。</li></ul><h3 id="服务器推送"><a href="#服务器推送" class="headerlink" title="服务器推送"></a>服务器推送</h3><p>服务端可以在发送页面 HTML 的时候主动推送其他资源，而不用等浏览器解析到响应资源发起请求在响应。例如服务端可以主动把 JS 和 CSS 文件推送给客户端，而不需要客户端解析 HTML 时再发送这些请求。</p><p>服务端可以主动推送，客户端也有权选择是否接收。如果服务端推送的资源已经被浏览器缓存过，浏览器可以通过发送 <code>RST_STREAM</code> 帧来拒收。主动推送也遵守同源策略，服务器不会随便推送第三方给客户端。</p><h3 id="头部压缩"><a href="#头部压缩" class="headerlink" title="头部压缩"></a>头部压缩</h3><p>HTTP/1.1 请求的大小变得越来越大，有时甚至会大于 TCP 窗口的初始大小，因为他们需要等待带着 ACK 的响应回来以后才能继续被发送。HTTP/2 对消息头采用 HPACK 进行压缩传输，能够节省消息头占用的网络的流量。而 HTTP/1.x 每次请求，都会携带大量冗余头信息，浪费了很多带宽资源。</p><p>HTTP每一次通信都会携带一组头部，用于描述这次通信的的资源、浏览器属性、cookie等。为了减少这块的资源消耗并提升性能，<strong>HTTP/2 对这些首部采取了压缩策略</strong>：</p><ul><li>HTTP/2 在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键－值对，对于相同的数据，不再通过每次请求和响应发送；</li><li>首部表在 HTTP/2 的连接存续期内始终存在，由客户端和服务器共同渐进地更新;</li><li>每个新的首部键－值对要么被追加到当前表的末尾，要么替换表中之前的值。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>HTTP/2的通过支持请求与响应的多路复用来减少延迟，通过压缩HTTP首部字段将协议开销降至最低，同时增加对请求优先级和服务器端推送的支持。</p><p>转载于<a href="https://zhuanlan.zhihu.com/p/26559480">一文读懂 HTTP/2 特性</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;二进制分帧&quot;&gt;&lt;a href=&quot;#二进制分帧&quot; class=&quot;headerlink&quot; title=&quot;二进制分帧&quot;&gt;&lt;/a&gt;二进制分帧&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;帧：HTTP/2 数据通信的最小单位消息：指 HTTP/2 中逻辑上的 HTTP 消息。例如请求和</summary>
      
    
    
    
    <category term="网络" scheme="https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP" scheme="https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/HTTP/"/>
    
    
    <category term="HTTP" scheme="https://tang7o.cn/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>Get和Post的区别</title>
    <link href="https://tang7o.cn/2022/05/13/Get%E5%92%8CPost%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://tang7o.cn/2022/05/13/Get%E5%92%8CPost%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2022-05-13T07:36:35.000Z</published>
    <updated>2022-05-13T07:38:24.171Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>GET有缓存 POST没有</p></li><li><p>GET url传参(有长度限制)， POST 请求头传参</p></li><li><p>GET只产生一个TCP数据包，POST两个：</p><ul><li><p>对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；</p></li><li><p>而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。</p></li></ul><p><strong>并不是所有浏览器POST都发送两次，火狐就发送一次</strong></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;GET有缓存 POST没有&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;GET url传参(有长度限制)， POST 请求头传参&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;GET只产生一个TCP数据包，POST两个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;对于GET方式的请求，浏</summary>
      
    
    
    
    <category term="网络" scheme="https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP" scheme="https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/HTTP/"/>
    
    
    <category term="HTTP" scheme="https://tang7o.cn/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>MySQL order by limit同时使用的问题</title>
    <link href="https://tang7o.cn/2022/04/23/MySQL-orderby-limit%E5%90%8C%E6%97%B6%E4%BD%BF%E7%94%A8/"/>
    <id>https://tang7o.cn/2022/04/23/MySQL-orderby-limit%E5%90%8C%E6%97%B6%E4%BD%BF%E7%94%A8/</id>
    <published>2022-04-23T02:30:49.000Z</published>
    <updated>2022-04-23T02:52:47.582Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html">MySQL文档原文</a></p><p>有一定英语阅读能力的读者，可以直接去读文档。</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如果<code>order by</code>排序属性的值不唯一，<code>order by</code>与<code>limit</code>同时使用可能会出现查询结果不同的现象。例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM ratings ORDER BY category;</span><br><span class="line">+----+----------+--------+</span><br><span class="line">| id | category | rating |</span><br><span class="line">+----+----------+--------+</span><br><span class="line">|  1 |        1 |    4.5 |</span><br><span class="line">|  5 |        1 |    3.2 |</span><br><span class="line">|  3 |        2 |    3.7 |</span><br><span class="line">|  4 |        2 |    3.5 |</span><br><span class="line">|  6 |        2 |    3.5 |</span><br><span class="line">|  2 |        3 |    5.0 |</span><br><span class="line">|  7 |        3 |    2.7 |</span><br><span class="line">+----+----------+--------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM ratings ORDER BY category LIMIT 5;</span><br><span class="line">+----+----------+--------+</span><br><span class="line">| id | category | rating |</span><br><span class="line">+----+----------+--------+</span><br><span class="line">|  1 |        1 |    4.5 |</span><br><span class="line">|  5 |        1 |    3.2 |</span><br><span class="line">|  4 |        2 |    3.5 |</span><br><span class="line">|  3 |        2 |    3.7 |</span><br><span class="line">|  6 |        2 |    3.5 |</span><br><span class="line">+----+----------+--------+</span><br></pre></td></tr></table></figure><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>文档原文如下：</p><blockquote><p>If you combine <code>LIMIT *</code>row_count<code>*</code> with <code>ORDER BY</code>, MySQL stops sorting as soon as it has found the first <em><code>row_count</code></em> rows of the sorted result, rather than sorting the entire result. If ordering is done by using an index, this is very fast. If a filesort must be done, all rows that match the query without the <code>LIMIT</code> clause are selected, and most or all of them are sorted, before the first <em><code>row_count</code></em> are found. After the initial rows have been found, MySQL does not sort any remainder of the result set.</p><p>One manifestation of this behavior is that an <code>ORDER BY</code> query with and without <code>LIMIT</code> may return rows in different order, as described later in this section.</p></blockquote><p>如果你将LIMIT <strong>row_count</strong>子句与ORDER BY子句组合在一起使用的话，MySQL会在找到排序结果的第一个<strong>row_count</strong>行后立即停止排序，而不是对整个结果进行排序。如果使用索引来完成排序，这将非常快。如果必须执行文件排序，则在找到第一个<strong>row_count</strong>行之前，选择所有与查询匹配但不包括LIMIT子句的行，并对其中大部分或所有行进行排序。一旦找到第一个<strong>row_count</strong>之后，MySQL不会对结果集的任何剩余部分进行排序。</p><p>这种行为的一种表现形式是，一个ORDER BY查询带或者不带LIMIT可能返回行的顺序是不一样的。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>在<code>order by</code>子句中包含其他列以使顺序具有确定性。</p><p>例如，假如id的值是唯一的，你可以通过下面的方式解决此问题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM ratings ORDER BY category, id;</span><br><span class="line">+----+----------+--------+</span><br><span class="line">| id | category | rating |</span><br><span class="line">+----+----------+--------+</span><br><span class="line">|  1 |        1 |    4.5 |</span><br><span class="line">|  5 |        1 |    3.2 |</span><br><span class="line">|  3 |        2 |    3.7 |</span><br><span class="line">|  4 |        2 |    3.5 |</span><br><span class="line">|  6 |        2 |    3.5 |</span><br><span class="line">|  2 |        3 |    5.0 |</span><br><span class="line">|  7 |        3 |    2.7 |</span><br><span class="line">+----+----------+--------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM ratings ORDER BY category, id LIMIT 5;</span><br><span class="line">+----+----------+--------+</span><br><span class="line">| id | category | rating |</span><br><span class="line">+----+----------+--------+</span><br><span class="line">|  1 |        1 |    4.5 |</span><br><span class="line">|  5 |        1 |    3.2 |</span><br><span class="line">|  3 |        2 |    3.7 |</span><br><span class="line">|  4 |        2 |    3.5 |</span><br><span class="line">|  6 |        2 |    3.5 |</span><br><span class="line">+----+----------+--------+</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">order by 和 order by limit 查询结果不一致？同一条 order by limit 语句查询结果不同？为什么会出现这种现象？这种现象如何解决？</summary>
    
    
    
    <category term="MySQL" scheme="https://tang7o.cn/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://tang7o.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>HTTPS解析</title>
    <link href="https://tang7o.cn/2022/04/22/HTTPS%E8%A7%A3%E6%9E%90/"/>
    <id>https://tang7o.cn/2022/04/22/HTTPS%E8%A7%A3%E6%9E%90/</id>
    <published>2022-04-22T08:49:56.000Z</published>
    <updated>2022-04-22T13:51:12.145Z</updated>
    
    <content type="html"><![CDATA[<h2 id="HTTPS是什么"><a href="#HTTPS是什么" class="headerlink" title="HTTPS是什么"></a>HTTPS是什么</h2><h3 id="为什么需要HTTPS"><a href="#为什么需要HTTPS" class="headerlink" title="为什么需要HTTPS"></a>为什么需要HTTPS</h3><p>由于HTTP存在一些缺陷：</p><ul><li>通信使用明文，内容可能被窃听</li><li>不验证通信方的身份，可能遭到伪装</li><li>无法验证报文的完整性，报文可能被篡改</li></ul><p>为了解决这些问题HTTPS诞生了。</p><h3 id="HTTPS的实质"><a href="#HTTPS的实质" class="headerlink" title="HTTPS的实质"></a>HTTPS的实质</h3><p>HTTP协议加上<strong>加密</strong>、<strong>认证机制</strong>和<strong>完整性验证</strong>就是HTTPS。</p><p>HTTPS并非一种新的协议。只是HTTP通信接口部分用SSL或TLS协议代替而已。所谓的HTTPS其实就是HTTP+SSL/TLS。</p><p><strong>TLS以SSL为原型开发的协议，有时会统称该协议为SSL。</strong></p><h2 id="HTTPS的加密原理"><a href="#HTTPS的加密原理" class="headerlink" title="HTTPS的加密原理"></a>HTTPS的加密原理</h2><p>HTTPS加密过程中使用了<strong>非对称加密</strong>和<strong>对称加密</strong>结合的方式。</p><p><a href="https://www.tang7o.cn/2021/09/28/https%E5%8A%A0%E5%AF%86%E8%BF%87%E7%A8%8B/">HTTPS加密过程</a></p><p><strong>为什么不只用对称加密？</strong></p><blockquote><p>采用单钥密码系统的加密方式，同一个密钥可以同时做信息的加密和解密，这种加密的方法称为对称加密，也称为单密钥加密。</p></blockquote><p><strong>缺点：</strong>以对称加密算法加密，必须将密钥发送给对方。这时候，假如通信被监听，密钥被攻击人获取，这个时候加密就是去了意义。</p><p>如何解决这个问题？使用两把密钥（非对称加密）。</p><p><strong>为什么不只用非对称加密？</strong></p><blockquote><p>与对称加密算法相反，非对称加密算法需要两个密钥来进行加密和解密，这两个密钥是配对的，分别是公开密钥（公钥）和私有密钥（私钥）。</p></blockquote><p>一般情况下，公钥是公开的，私钥是服务器私有的。<strong>公钥加密后的密文只能通过对应的私钥来解密，而私钥加密的密文却可以通过对应的公钥来解密。</strong></p><p><strong>缺点：</strong>加密比对称加密复杂，效率低。</p><h2 id="如何保证公钥的正确性"><a href="#如何保证公钥的正确性" class="headerlink" title="如何保证公钥的正确性"></a>如何保证公钥的正确性</h2><p>与服务器进行通信时，如何才能保证你收到的公钥服务器发行的公钥，而不是被攻击者替换掉的呢？</p><p>为了解决这个问题，可以使用数字证书认证机构（CA）颁发证书。</p><p>CA业务流程：</p><ul><li>CA会向申请者颁发一个证书，证书的内容有：签发者、证书用途、域名、证书到期时间、使用的HASH算法、签名使用的算法等。</li><li>将证书的内容做一次HASH，得到HASH值。</li><li>用<strong>CA的私钥</strong>对这个HASH值和使用的HASH算法加密，这样就完成了数字签名。</li><li>将数字签名附加在证书的末尾。</li></ul><p>客户端检验证书流程：</p><ul><li>用<strong>CA私钥对应的公钥</strong>，解密数字证书末尾的签名，得到HASH值和HASH算法。</li><li>用得到的HASH算法，对证书内容进行HASH运算。如果得到的HASH值与解密得到的HASH值相同，那么检验通过，否则失败。</li></ul><p>上面提到的C公钥怎么来的呢？</p><p>CA除了给申请者颁发证书，它本身也有自己的证书。CA自身的证书（一般由它自己颁发）在我们系统安装好的时候，就被微软（或其他操作系统的开发机构）安装再操作系统中了。而CA的公钥包含在其中。这样CA就可以通过自身的是要对发布的数字证书进行签名，而客户端就能用相应的公钥来解密。</p><h2 id="HTTPS通信的过程"><a href="#HTTPS通信的过程" class="headerlink" title="HTTPS通信的过程"></a>HTTPS通信的过程</h2><p><img src="1.jpg" class="lazyload" data-srcset="1.jpg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><ol><li>客户端发送Client Hello报文开始SLL通信。报文中包括客户端支持的SSL版本、加密组件（Cipher Suite）列表以及一个随机数A。</li><li>服务器可以进行SSL通信时，发送Server Hello报文作为应答。和客户端一样，在报文中包括SSL版本、加密组件列表（从客户端接收到的加密组件筛选出来的）以及一个随机数B。</li><li>之后服务器发送Certificate报文。报文中包含公钥证书。</li><li>最后服务器发送Server Hello Done报文通知客户端，最初阶段的SSL握手协商部分结束。</li><li>SSL第一次握手结束后，客户端会对服务器发过来的证书进行验证，如果验证成功，解密出证书的公钥。接着客户端以Client Key Exchange报文作为回应。报文中包含通信加密使用的一种被称为<code>Pre-master secret</code>的随机密码串，报文使用解密出的公钥进行加密。</li><li>客户端继续发送Change Cipher Spec报文。用于告知服务端，客户端已经切换到之前协商好的加密套件（Cipher Suite）的状态，准备使用之前协商好的加密套件加密数据并传输了。</li><li>客户端发送Finished报文。该报文包含连接至今全部报文的整体校验值（也就是HASH值），用来供服务器校验。</li><li>服务器接收到客户端的请求之后，使用私钥解密报文，把<code>Pre-master secret</code>取出来。接着，服务器同样发送Change Cipher Spec报文。</li><li>服务器同样发送Finished报文，用来供客户端校验。</li><li>服务器和客户端的Finished报文交换完毕之后，SSL连接就算建立完成。当然，通信会受到SSL的保护。从此处开始进行应用层协议的通信，即发送HTTP请求。</li><li>应用层协议通信，即返回HTTP响应。</li><li>最后由客户端断开连接。断开连接时，发送close_notify报文。上图做了一些省略，这步之后再发送TCP FIN报文来关闭与TCP的通信。</li></ol><h3 id="Finish报文的作用？"><a href="#Finish报文的作用？" class="headerlink" title="Finish报文的作用？"></a>Finish报文的作用？</h3><p>上面已经提及，Finish报文是对至今全部报文的整体校验值（也就是HASH值）。当客户端把这个值通过得到的公钥进行加密的时候，服务器得到之后对其进行解密，然后再对全部报文进行一个HASH求值。如果这个值跟解密得到的值相等的话，那么说明客户端是可信赖的。<br>同样的，服务器发送这样的一个整体校验值，用来客户端验证服务器是否是真正要进行通信的那一个。<br>综上，这个Finish报文就是用来校验双方的身份的。</p><h3 id="三个随机数的作用？"><a href="#三个随机数的作用？" class="headerlink" title="三个随机数的作用？"></a>三个随机数的作用？</h3><p>对于<strong>客户端</strong>：<br>当其生成了<code>Pre-master secret</code>之后，会结合原来的A、B随机数，用DH算法计算出一个<code>master secret</code>，紧接着根据这个<code>master secret</code>推导出<code>hash secret</code>和<code>session secret</code>。</p><p>对于<strong>服务端</strong>：<br>当其解密获得了<code>Pre-master secret</code>之后，会结合原来的A、B随机数，用DH算法计算出一个<code>master secret</code>，紧接着根据这个<code>master secret</code>推导出<code>hash secret</code>和<code>session secret</code>。</p><blockquote><p>在客户端和服务端的<code>master secret</code>是依据三个随机数推导出来的，它是不会在网络上传输的，只有双方知道，不会有第三者知道。同时，客户端推导出来的<code>session secret</code>和<code>hash secret</code>与服务端也是完全一样的。</p></blockquote><p>那么现在双方如果开始使用对称算法加密来进行通讯，使用哪个作为共享的密钥呢？过程是这样子的：</p><p>双方使用对称加密算法进行加密，用<code>hash secret</code>对HTTP报文做一次运算生成一个<code>MAC</code>，附在HTTP报文的后面，然后用<code>session-secret</code>加密所有数据（<code>HTTP+MAC</code>），然后发送。</p><p>接收方则先用<code>session-secret</code>解密数据，然后得到<code>HTTP+MAC</code>，再用相同的算法计算出自己的<code>MAC</code>，如果两个<code>MAC</code>相等，证明数据没有被篡改。</p><blockquote><p>MAC(Message Authentication Code)称为报文摘要，能够查知报文是否遭到篡改，从而保护报文的完整性。</p></blockquote><h3 id="为什么使用三个随机数？"><a href="#为什么使用三个随机数？" class="headerlink" title="为什么使用三个随机数？"></a>为什么使用三个随机数？</h3><p>客户端和服务器都需要生成随机数，以此来保证每次生成的秘钥都不相同。</p><p>使用三个随机数，是因为 SSL 的协议默认不信任每个主机都能产生完全随机的数，如果只使用一个伪随机的数来生成秘钥，就很容易被破解。</p><p>通过使用三个随机数的方式，增加了自由度，一个伪随机可能被破解，但是三个伪随机就很接近于随机了，因此可以使用这种方法来保持生成秘钥的随机性和安全性。</p><h3 id="黑客拦截服务器证书并篡改，会出现什么情况？"><a href="#黑客拦截服务器证书并篡改，会出现什么情况？" class="headerlink" title="黑客拦截服务器证书并篡改，会出现什么情况？"></a>黑客拦截服务器证书并篡改，会出现什么情况？</h3><ol><li>如果黑客只是单纯的篡改，由于有数字签名，客户端会很容易判断出报文被篡改过。</li><li>黑客不仅修改了证书内柔，还替换了数字签名，由于黑客不知道CA的私钥，于是客户端用CA公钥解密时，得不到正确的信息，也很容易判断出报文是否被修改。</li><li>黑客从相同的CA申请了一个数字证书。由于这个数字证书是真实存在的，所以客户端可以成功的用CA公钥进行解密。但是，由于数字证书绑定了<strong>域名</strong>，因此客户端很容易发现证书域名与访问域名的不一致，便会发出警告。警告如下图：</li></ol><p><img src="2.jpg" class="lazyload" data-srcset="2.jpg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><h2 id="一定要用HTTPS吗"><a href="#一定要用HTTPS吗" class="headerlink" title="一定要用HTTPS吗"></a>一定要用HTTPS吗</h2><p>当然不是，虽然HTTPS比HTTP要安全许多，但是由于加入了诸多的验证机制，导致它处理速度变慢。原因如下：</p><ul><li>客户端和服务器<strong>协商的次数变多</strong>，整体处理通信量会不可避免的增加。</li><li>客户端和服务器需要进行<strong>额外的加密和解密的运算处理</strong>。会消耗更多的资源。</li></ul><p>同时，使用HTTPS需要购买CA证书，需要额外的开销。</p><p>因此，大部分的Web网址都采用了一个折中的方法。对一些需要隐藏、私密的信息进行加密，而普通的信息不进行机密处理，以节省资源。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;HTTPS是什么&quot;&gt;&lt;a href=&quot;#HTTPS是什么&quot; class=&quot;headerlink&quot; title=&quot;HTTPS是什么&quot;&gt;&lt;/a&gt;HTTPS是什么&lt;/h2&gt;&lt;h3 id=&quot;为什么需要HTTPS&quot;&gt;&lt;a href=&quot;#为什么需要HTTPS&quot; class=&quot;</summary>
      
    
    
    
    <category term="网络" scheme="https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTPS" scheme="https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/HTTPS/"/>
    
    
    <category term="网络" scheme="https://tang7o.cn/tags/%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTPS" scheme="https://tang7o.cn/tags/HTTPS/"/>
    
  </entry>
  
  <entry>
    <title>浏览器输入url后发生了什么</title>
    <link href="https://tang7o.cn/2022/04/22/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5url%E5%8F%91%E7%94%9F%E7%9A%84%E4%BA%8B/"/>
    <id>https://tang7o.cn/2022/04/22/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5url%E5%8F%91%E7%94%9F%E7%9A%84%E4%BA%8B/</id>
    <published>2022-04-22T06:29:58.000Z</published>
    <updated>2022-04-22T07:59:17.341Z</updated>
    
    <content type="html"><![CDATA[<h3 id="大致流程"><a href="#大致流程" class="headerlink" title="大致流程"></a>大致流程</h3><ol><li>合成URL</li><li>DNS域名解析</li><li>建立TCP连接</li><li>发送HTTP请求，处理请求，返回响应结果</li><li>关闭TCP连接</li><li>浏览器渲染</li></ol><h3 id="合成URL"><a href="#合成URL" class="headerlink" title="合成URL"></a>合成URL</h3><p>浏览器根据用户输入信息判断是搜索还是网址，如果是搜索内容，就将搜索内容+默认搜索引擎合成新的URL；如果用户输入内容符合URL规则，浏览器就会根据URL协议生成合法的URL。</p><h3 id="DNS域名解析"><a href="#DNS域名解析" class="headerlink" title="DNS域名解析"></a>DNS域名解析</h3><p>DNS的域名解析，在客户端和浏览器、本地DNS之间的查询是递归查询；在本地DNS服务器和根DNS服务器及其子服务器之间是迭代查询。</p><p>递归：</p><p><img src="1.jpeg" class="lazyload" data-srcset="1.jpeg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>在客户端输入URL后，从历览器缓存查找-&gt;本地hosts文件查找-&gt;本地DNS解析器缓存查找-&gt;本地DNS服务器查找，这个步骤中任意一步查到了都会直接返回结果。</p><p>如果本地DNS服务器也查不到，则根据本地DNS服务器设置的转发器进行查询。若未用转发模式，则迭代查找过程如下图：</p><p><img src="2.jpeg" class="lazyload" data-srcset="2.jpeg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><h3 id="建立TCP连接"><a href="#建立TCP连接" class="headerlink" title="建立TCP连接"></a>建立TCP连接</h3><p>首先判断是不是HTTPS（HTTP+SSL/TLS）协议，若是，服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密的数据。</p><p><a href="https://www.tang7o.cn/2021/06/09/TCP/">三次握手，建立TCP连接</a></p><p><a href="https://www.tang7o.cn/2021/09/28/https%E5%8A%A0%E5%AF%86%E8%BF%87%E7%A8%8B/">HTTPS加密过程</a></p><h3 id="发送HTTP请求，服务器处理请求，返回响应结果"><a href="#发送HTTP请求，服务器处理请求，返回响应结果" class="headerlink" title="发送HTTP请求，服务器处理请求，返回响应结果"></a>发送HTTP请求，服务器处理请求，返回响应结果</h3><p>TCP建立连接后，浏览器就可以利用HTTP/HTTPS协议向服务器发送请求。服务器接受到请求，处理请求返回响应。</p><h3 id="关闭TCP连接"><a href="#关闭TCP连接" class="headerlink" title="关闭TCP连接"></a>关闭TCP连接</h3><p><a href="https://www.tang7o.cn/2021/06/09/TCP/">四次挥手，关闭TCP连接</a></p><h3 id="浏览器渲染"><a href="#浏览器渲染" class="headerlink" title="浏览器渲染"></a>浏览器渲染</h3><p>浏览器根据服务器返回的响应，渲染并显示界面。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;大致流程&quot;&gt;&lt;a href=&quot;#大致流程&quot; class=&quot;headerlink&quot; title=&quot;大致流程&quot;&gt;&lt;/a&gt;大致流程&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;合成URL&lt;/li&gt;
&lt;li&gt;DNS域名解析&lt;/li&gt;
&lt;li&gt;建立TCP连接&lt;/li&gt;
&lt;li&gt;发送HTTP请</summary>
      
    
    
    
    <category term="网络" scheme="https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="网络" scheme="https://tang7o.cn/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>next-key lock</title>
    <link href="https://tang7o.cn/2022/03/24/next-key/"/>
    <id>https://tang7o.cn/2022/03/24/next-key/</id>
    <published>2022-03-24T01:19:20.000Z</published>
    <updated>2022-04-24T05:40:44.475Z</updated>
    
    <content type="html"><![CDATA[<p>对记录加锁时，<strong>加锁的基本单位是 next-key lock</strong>，它是由记录锁和间隙锁组合而成的，<strong>next-key lock 是前开后闭区间，而间隙锁是前开后开区间</strong>。</p><p>但是，next-key lock 会在一些场景下会退化成记录锁或者间隙锁。</p><p>那到底是什么场景呢？我们以下表来举例说明：</p><p><img src="1.png" class="lazyload" data-srcset="1.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>其中，id 是主键索引（唯一索引），b 是普通索引（非唯一索引），a 是普通列。</p><p><strong>注意：本文 MySQL 版本为 8.0.26，不同版本的加锁规则可能不同。</strong></p><h2 id="唯一索引"><a href="#唯一索引" class="headerlink" title="唯一索引"></a>唯一索引</h2><h3 id="唯一索引等值查询"><a href="#唯一索引等值查询" class="headerlink" title="唯一索引等值查询"></a>唯一索引等值查询</h3><p>我们用唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：</p><ul><li>查询的记录存在：在用「唯一索引进行等值查询」时，next-key lock 会退化成「记录锁」。</li><li>当查询的记录不存在，在用「唯一索引进行等值查询」时，next-key lock 会退化成间隙锁。</li></ul><h4 id="记录存在的情况："><a href="#记录存在的情况：" class="headerlink" title="记录存在的情况："></a>记录存在的情况：</h4><p><img src="2.png" class="lazyload" data-srcset="2.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>会话 1 加锁变化过程如下：</p><ol><li>加锁的基本单位是 next-key lock，因此会话 1 加锁的范围是 (8,16]；</li><li>但是由于使用唯一索引进行等值查询，且查询的记录存在，所以<strong>next-key lock 退化成记录锁，因此最终加锁的范围是 id = 16 这一行</strong>。</li></ol><p>所以，会话 2 在修改 id = 16 的记录时会被锁住，而会话 3 插入 id = 9 的记录可以被正常执行。</p><h4 id="记录不存在的情况："><a href="#记录不存在的情况：" class="headerlink" title="记录不存在的情况："></a>记录不存在的情况：</h4><p><img src="3.png" class="lazyload" data-srcset="3.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>会话 1 加锁变化过程如下：</p><ol><li>加锁的基本单位是 next-key lock，因此主键索引 id 的加锁范围是 (8,16]；</li><li>但是由于查询记录不存在，next-key lock 退化成间隙锁，因此最终加锁范围是 (8,16).</li></ol><p>所以，会话 2 要往这个间隙里面插入 id = 9 的记录会被锁住，但是会话 3 修改 id = 16 是可以正常执行的，因为 id = 16 这条记录并没有加锁。</p><h3 id="唯一索引范围查询"><a href="#唯一索引范围查询" class="headerlink" title="唯一索引范围查询"></a>唯一索引范围查询</h3><p>范围查询和等值查询的加锁规则是不同的。</p><p>举个例子，下面这两条查询语句，查询的结果虽然是一样的，但是加锁的范围是不一样的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from t_test where id=8 for update;</span><br><span class="line">select * from t_test where id&gt;=8 and id&lt;9 for update;</span><br></pre></td></tr></table></figure><p><img src="4.png" class="lazyload" data-srcset="4.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>会话 1 加锁变化过程如下：</p><ol><li>最开始要找的第一行是 id = 8，因此 next-key lock (4,8]，但是由于 id 是唯一索引，且该记录是存在的，因此会退化成记录锁，也就是只会对 id = 8 这一行加锁；</li><li>由于是范围查找，就会继续往后找存在的记录，也就是会找到 id = 16 这一行停下来，然后加 next-key lock (8, 16]，但由于 id = 16 不满足 id &lt; 9，所以会退化成间隙锁，加锁范围变为 (8, 16)。</li></ol><p>所以，会话 1 这时候主键索引的锁是记录锁 id = 8 和间隙锁(8, 16)。</p><p>会话 2 由于往间隙锁里插入了 id = 9 的记录，所以会被锁住了，而 id = 8 是被加锁的，因此会话 3 的语句也会被阻塞。</p><p>由于 id = 16 并没有加锁，所以会话 4 是可以正常被执行。</p><h2 id="非唯一索引"><a href="#非唯一索引" class="headerlink" title="非唯一索引"></a>非唯一索引</h2><h3 id="非唯一索引等值查询"><a href="#非唯一索引等值查询" class="headerlink" title="非唯一索引等值查询"></a>非唯一索引等值查询</h3><p>当我们用非唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：</p><ul><li><strong>当查询的记录存在时，除了会加 next-key lock 外，还额外加间隙锁，也就是会加两把锁</strong>。</li><li><strong>当查询的记录不存在时，只会加 next-key lock，然后会退化为间隙锁，也就是只会加一把锁。</strong></li></ul><h4 id="记录存在的情况：-1"><a href="#记录存在的情况：-1" class="headerlink" title="记录存在的情况："></a>记录存在的情况：</h4><p><img src="5.png" class="lazyload" data-srcset="5.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>会话 1 加锁变化过程如下：</p><ol><li>先会对普通索引 b 加上 next-key lock，范围是(4,8];</li><li>然后因为是非唯一索引，且查询的记录是存在的，所以还会加上间隙锁，规则是向下遍历到第一个不符合条件的值才能停止，因此间隙锁的范围是(8,16)。</li></ol><p>所以，会话 1 的普通索引 b 上共有两个锁，分别是 next-key lock (4,8] 和间隙锁 (8,16) 。</p><p>那么，当会话 2 往间隙锁里插入 id = 9 的记录就会被锁住，而会话 3 和会话 4 是因为更改了 next-key lock 范围里的记录而被锁住的。</p><p>然后因为 b = 16 这条记录没有加锁，所以会话 5 是可以正常执行的。</p><h4 id="记录不存在的情况：-1"><a href="#记录不存在的情况：-1" class="headerlink" title="记录不存在的情况："></a>记录不存在的情况：</h4><p><img src="6.png" class="lazyload" data-srcset="6.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>会话 1 加锁变化过程如下：</p><ol><li>先会对普通索引 b 加上 next-key lock，范围是(8,16];</li><li>但是由于查询的记录是不存在的，所以不会再额外加个间隙锁，但是 next-key lock 会退化为间隙锁，最终加锁范围是 (8,16)。</li></ol><p>会话 2 因为往间隙锁里插入了 b = 9 的记录，所以会被锁住，而 b = 16 是没有被加锁的，因此会话 3 的语句可以正常执行。</p><h3 id="非唯一索引范围查询"><a href="#非唯一索引范围查询" class="headerlink" title="非唯一索引范围查询"></a>非唯一索引范围查询</h3><p><img src="7.png" class="lazyload" data-srcset="7.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>会话 1 加锁变化过程如下：</p><ol><li>最开始要找的第一行是 b = 8，因此 next-key lock(4,8]，但是由于 b 不是唯一索引，并不会退化成记录锁。</li><li>但是由于是范围查找，就会继续往后找存在的记录，也就是会找到 b = 16 这一行停下来，然后加 next-key lock (8, 16]，因为是普通索引查询，所以并不会退化成间隙锁。</li></ol><p>所以，会话 1 的普通索引 b 有两个 next-key lock，分别是 (4,8] 和(8, 16]。这样，你就明白为什么会话 2 、会话 3 、会话 4 的语句都会被锁住了。</p><h2 id="普通字段"><a href="#普通字段" class="headerlink" title="普通字段"></a>普通字段</h2><p>普通字段查询，会查询全表，这里锁的话就会锁住主键的所有区间。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>唯一索引等值查询：</p><ul><li>当查询的记录是存在的，next-key lock 会退化成「记录锁」。</li><li>当查询的记录是不存在的，next-key lock 会退化成「间隙锁」。</li></ul><p>非唯一索引等值查询：</p><ul><li>当查询的记录存在时，除了会加 next-key lock 外，还额外加间隙锁，也就是会加两把锁。</li><li>当查询的记录不存在时，只会加 next-key lock，然后会退化为间隙锁，也就是只会加一把锁。</li></ul><p>非唯一索引和主键索引的范围查询的加锁规则不同之处在于：</p><ul><li>唯一索引在满足一些条件的时候，next-key lock 退化为间隙锁和记录锁。</li><li>非唯一索引范围查询，next-key lock 不会退化为间隙锁和记录锁。</li></ul><p>转载于：</p><p><a href="https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&amp;mid=2247497197&amp;idx=1&amp;sn=9f82f73d876636944fb75348ef568c01&amp;scene=21#wechat_redirect">小林coding</a> </p><p><a href="https://www.cnblogs.com/liuzhihang/p/14861807.html">程序员小航</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;对记录加锁时，&lt;strong&gt;加锁的基本单位是 next-key lock&lt;/strong&gt;，它是由记录锁和间隙锁组合而成的，&lt;strong&gt;next-key lock 是前开后闭区间，而间隙锁是前开后开区间&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;但是，next-key loc</summary>
      
    
    
    
    <category term="MySQL" scheme="https://tang7o.cn/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://tang7o.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>进程切换为什么比线程切换开销大</title>
    <link href="https://tang7o.cn/2022/03/22/%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2/"/>
    <id>https://tang7o.cn/2022/03/22/%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2/</id>
    <published>2022-03-22T02:21:47.000Z</published>
    <updated>2022-04-13T13:31:49.208Z</updated>
    
    <content type="html"><![CDATA[<p>进程切换比线程切换开销大是因为进程切换时要切页表，而且往往伴随着页调度，因为进程的数据段代码段要换出去，以便把将要执行的进程的内容换进来。本来进程的内容就是线程的超集。而且线程只需要保存线程的上下文（相关寄存器状态和栈的信息）就好了，动作很小。</p><p>但是如果是不同进程内的线程互换就不好说了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;进程切换比线程切换开销大是因为进程切换时要切页表，而且往往伴随着页调度，因为进程的数据段代码段要换出去，以便把将要执行的进程的内容换进来。本来进程的内容就是线程的超集。而且线程只需要保存线程的上下文（相关寄存器状态和栈的信息）就好了，动作很小。&lt;/p&gt;
&lt;p&gt;但是如果是不同</summary>
      
    
    
    
    <category term="OS" scheme="https://tang7o.cn/categories/OS/"/>
    
    
    <category term="OS" scheme="https://tang7o.cn/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>MySQL Limit优化</title>
    <link href="https://tang7o.cn/2022/03/16/MySQL-LIMIT/"/>
    <id>https://tang7o.cn/2022/03/16/MySQL-LIMIT/</id>
    <published>2022-03-16T12:44:13.000Z</published>
    <updated>2022-04-13T13:31:48.203Z</updated>
    
    <content type="html"><![CDATA[<h2 id="耗时本质"><a href="#耗时本质" class="headerlink" title="耗时本质"></a>耗时本质</h2><p>mysql大数据量使用limit分页，随着页码的增大，查询效率越低下。</p><p>当一个表有几百万的数据的时候成了问题！</p><p>如 <code>select * from table limit 0,10</code> 这个没有问题，当 <code>limit 100000,10</code> 的时候就很慢。</p><p>原因本质：</p><ol><li>limit 语句的查询时间和其实记录（offset）的大小成正比。</li><li>mysql 的 limit 语句是很方便，但是对于记录很多：百万，千万级别的表并不适合直接使用。</li></ol><p>例如： <code>limit 10000,20</code> 的意思扫描满足条件的 10020 行，扔掉 前面的 10000 行，返回最后的 20 行，问题就在这里。<code>limit 2000000，30</code> 扫描了 2000030 行，慢的都堵死了，甚至会导致磁盘 IO 100%消耗，但是 <code>limit 30</code> 这样的语句才扫描 30 行。</p><h2 id="优化手段"><a href="#优化手段" class="headerlink" title="优化手段"></a>优化手段</h2><p>去掉或者利用 <code>limit offset,size</code> 中的 offset。</p><p>不是直接使用limit，而是首先获取到 offset 的 id 然后再使用 limit size 来获取数据。</p><h2 id="对-limit-分页问题的性能优化方法"><a href="#对-limit-分页问题的性能优化方法" class="headerlink" title="对 limit 分页问题的性能优化方法"></a>对 limit 分页问题的性能优化方法</h2><p>如果数据是连续不中断的可以使用 <code>between and</code> 来代替 limit 查询。</p><h3 id="利用表的覆盖索引来加速分页查询"><a href="#利用表的覆盖索引来加速分页查询" class="headerlink" title="利用表的覆盖索引来加速分页查询"></a>利用表的覆盖索引来加速分页查询</h3><p>覆盖索引：</p><p>就是 select 的数据列只从索引中就能获得，不必读取数据行。也就是说：<strong>查询列要被所创建的索引覆盖</strong>。</p><p>因为利用索引查找有优化算法，且数据就在查询索引上面，不用再去找相关的数据地址了，这样节省了很多时间。另外 mysql 中也有相关的索引缓存，在并发高的时候利用缓存就效果更好了。在我们的例子中，我们知道 id 字段是主键，自然就包含了默认的主键索引。</p><p>这次我们之间查询最后一页的数据（利用覆盖索引，只包含id列），如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#覆盖索引只包含id列 的时间显著优于 select * 不言而喻</span><br><span class="line">select * from order_table where company_id = 1 and mark =0 order by id desc limit 200000 ,20;</span><br><span class="line">select id from order_table where company_id = 1 and mark =0 order by id desc limit 200000 ,20;</span><br></pre></td></tr></table></figure><p>如果我们要查询所有列，有两种方法，一种是 id&gt;= 的形式，另一种就是利用 join：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#两者用的都是一个原理嘛，所以效果也差不多</span><br><span class="line">SELECT * FROM xxx WHERE ID &gt; =(select id from xxx limit 1000000, 1) order by id limit 20;</span><br><span class="line">SELECT * FROM xxx a JOIN (select id from xxx limit 1000000, 20) b ON a.ID = b.id;</span><br></pre></td></tr></table></figure><p>上述子查询的方式虽然比直接使用 Limit 要快很多，但是当数据量过大（千万级别）时，子查询需要很长时间，依旧不够快。</p><h3 id="去掉子查询"><a href="#去掉子查询" class="headerlink" title="去掉子查询"></a>去掉子查询</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#仅仅使用 id&lt;max and limit size;</span><br><span class="line">#每次查询前获取上一页最小id作为下一页的最大id使用 假设为：800000001</span><br><span class="line">#首页查询</span><br><span class="line">select * from order_table where company_id = 1 and mark =0 order by id desc limit 200000;</span><br><span class="line">#非首页查询  </span><br><span class="line">select * from order_table where company_id = 1 and mark =0 and id &lt; 800000001 order by id desc limit 200000;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;耗时本质&quot;&gt;&lt;a href=&quot;#耗时本质&quot; class=&quot;headerlink&quot; title=&quot;耗时本质&quot;&gt;&lt;/a&gt;耗时本质&lt;/h2&gt;&lt;p&gt;mysql大数据量使用limit分页，随着页码的增大，查询效率越低下。&lt;/p&gt;
&lt;p&gt;当一个表有几百万的数据的时候成了问题！</summary>
      
    
    
    
    <category term="MySQL" scheme="https://tang7o.cn/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://tang7o.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>HTTP 1.0 VS HTTP 1.1</title>
    <link href="https://tang7o.cn/2022/03/08/HTTP1-0-1-1/"/>
    <id>https://tang7o.cn/2022/03/08/HTTP1-0-1-1/</id>
    <published>2022-03-08T07:43:49.000Z</published>
    <updated>2022-04-13T13:31:48.011Z</updated>
    
    <content type="html"><![CDATA[<p>本文将从以下几个维度来对比 HTTP1.0 和 HTTP1.1:</p><ul><li>响应状态码</li><li>缓存处理</li><li>连接方式</li><li>Host 头处理</li><li>带宽优化</li></ul><h2 id="响应状态码"><a href="#响应状态码" class="headerlink" title="响应状态码"></a>响应状态码</h2><p>HTTP/1.0 仅定义了 16 种状态码。HTTP/1.1 中新加入了大量的状态码，光是错误响应码就新增了 24 种。比如说：</p><ul><li><code>100（Continue）</code>：在请求大资源前的预热请求。</li><li><code>206（Partial Content）</code>：范围请求的标识码。</li><li><code>409（Conflict）</code>：请求与当前资源的规定冲突。</li><li><code>410（Gone）</code>：资源已被永久转移，而且没有任何已知的转发地址。</li></ul><h2 id="缓存处理"><a href="#缓存处理" class="headerlink" title="缓存处理"></a>缓存处理</h2><p>缓存技术通过避免用户与源服务器的频繁交互，节约了大量的网络带宽，降低了用户接收信息的延迟。</p><h3 id="HTTP-1-0"><a href="#HTTP-1-0" class="headerlink" title="HTTP/1.0"></a>HTTP/1.0</h3><p>HTTP/1.0 提供的缓存机制非常简单。服务器端使用 <code>Expires</code> 标签来标志（时间）一个响应体，在 <code>Expires</code> 标志时间内的请求，都会获得该响应体缓存。服务器端在初次返回给客户端的响应体中，有一个 <code>Last-Modified</code> 标签，该标签标记了被请求资源在服务器的最后一次修改。在请求头中，使用 <code>If-Modifiend-Since</code> 标签，该标签标志一个时间，意为客户端向服务器进行问询：”该时间之前，我要请求的资源是否有被修改过？“通常情况下，请求头中的 <code>If-Modifiend-Sine</code> 的值即为上一次获得该资源时，响应体中的 <code>Last-Modified</code> 的值。</p><p>如果服务器即收到了请求头，并判断 <code>If-Modifiend-Sine</code> 时间后，资源确实没有被修改过，则返回给客户端一个 <code>304 not modified</code> 响应头，表示”缓存可用，你从浏览器里拿吧！“。</p><p>如果判断 <code>If-Modifiend-Sine</code> 时间后，资源被修改过，则返回给客户端一个 <code>200 OK</code> 的响应体，并附带全新的资源内容，表示”资源被修改过了，我给你一份新的“。</p><p><img src="1.png" class="lazyload" data-srcset="1.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p><img src="2.png" class="lazyload" data-srcset="2.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><h3 id="HTTP-1-1"><a href="#HTTP-1-1" class="headerlink" title="HTTP/1.1"></a>HTTP/1.1</h3><p>HTTP/1.1 的缓存机制在 HTTP/1.0 的基础上，大大增加了灵活性和扩展性。基本工作原理和 HTTP/1.0 保存不变，而是增加了更多细致的特性。其中，请求头中最常见的特性就是 <code>Cache-Control</code>，详见 MDN Web 文档 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Cache-Control">Cache-Control</a></p><h2 id="连接方式"><a href="#连接方式" class="headerlink" title="连接方式"></a>连接方式</h2><p><strong>HTTP/1.0 默认使用短链接</strong>，也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或者其他的类型的 Web 页中包含有其他 Web 资源（如 JavaScript 文件、图像文件、CSS 文件）等，每遇到这样的一个 Web 资源，浏览器就会重新建立一个 TCP 连接，这样就会导致有大量的“握手报文”和“挥手报文”占用了带宽。</p><p><strong>为了解决 HTTP/1.0 存在的资源浪费问题，HTTP/1.1 优化为默认长连接模式。</strong>采用长连接模式的请求报文会通知服务端：“我会向你请求连接，并且连接成功建立后，请不要关闭”。因此，该 TCP 连接将持续打开，为后续的客户端服务端的数据交互服务。也就是说在使用长连接的情况下，当一个网页打开完成后，客户端和服务端之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。</p><p>如果 TCP 连接一直保持的话也是对资源的浪费，因此，一些服务器软件还会支持超时时间的时间。在超时时间之内没有新的请求达到，TCP 连接才会被关闭。</p><p>有必要说明的是，HTTP/1.0 仍提供了长连接选项，在请求头中加入 <code>Connection: Keep-alive</code>。同样的，在HTTP/1.1中，如果不希望使用长连接选项，也可以在请求头中加入 <code>Connection: close</code>，这样会通知服务器端：“我不需要长连接，连接成功后即可关闭”。</p><p><strong>HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。</strong></p><p><strong>实现长连接需要客户端和服务端都支持长连接。</strong></p><h2 id="Host-头处理"><a href="#Host-头处理" class="headerlink" title="Host 头处理"></a>Host 头处理</h2><p>域名系统（DNS）允许多个主机名绑定到同一个 IP 地址上，但是 HTTP/1.0 并没有考虑这个问题，假设我们有一个资源 URL 是 <code>http://tang7o.cn/index.html</code>, HTTP/1.0 的请求报文中，将会请求的是 <code>GET /index.html HTTP/1.0</code> 也就是不会加入主机名。这样的报文发送到服务器端，服务端理解不了客户端想请求的真正网址。</p><p>因此，HTTP/1.1 在请求头中加入了 <code>Host</code> 字段。加入 <code>Host</code> 字段的报文头部将会是：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET /index.html HTTP/1.1</span><br><span class="line">Host: tang7o.cn</span><br></pre></td></tr></table></figure><p>这样，服务器就可以确定客户端想要请求的真正网址了。</p><h2 id="带宽优化"><a href="#带宽优化" class="headerlink" title="带宽优化"></a>带宽优化</h2><h3 id="范围请求"><a href="#范围请求" class="headerlink" title="范围请求"></a>范围请求</h3><p>HTTP/1.1 引入了范围请求（range request）机制，以避免带宽的浪费。当客户端想请求一个文件的一部分，或者需要继续下载一个已经下载了部分但被终止的文件，HTTP/1.1 可以在请求中加入 <code>Range</code> 头部，以请求（并只能请求字节型数据）数据的一部分。服务器可以忽略 <code>Range</code> 头部，也可以返回若干 <code>Range</code> 响应。</p><p>如果一个响应包括部分数据的话，那么将带有 <code>206（Partial Content）</code>状态码。该状态码的意义在于避免了 HTTP/1.0 代理缓存错误的把该响应认为是一个完整的数据响应，从而把他当作一个请求的响应缓存。</p><p>在范围响应中，<code>Content-Range</code> 头部标志指示出了该数据块的偏移量和数据块长度。</p><h3 id="状态码100"><a href="#状态码100" class="headerlink" title="状态码100"></a>状态码100</h3><p>HTTP/1.0 中新加入了状态码 <code>100</code>。该状态码的使用场景为，存在某些较大的文件请求，服务器可能不愿意响应这种请求，此时状态码 <code>100</code> 可以作为指示请求是否被正常响应。</p><p><img src="3.png" class="lazyload" data-srcset="3.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p><img src="4.png" class="lazyload" data-srcset="4.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>然而在 HTTP/1.0 中没有 <code>100（Continue）</code> 状态码，要想触发这一机制，可以发送一个 <code>Expect</code> 头部，其中包含一个 <code>100-continue</code> 的值。</p><h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><p>许多格式的数据在传输时都会做压缩处理。数据的压缩可以大幅优化带宽的利用。然而，HTTP/1.0 对数据压缩的选项提供的不多，不支持压缩细节的选择，也无法区分端到端压缩或者是逐跳压缩。</p><p>HTTP/1.1 则对内容编码和传输编码做了区分，内容编码总是端到端的，传输编码总是逐跳的。</p><p>HTTP/1.0 包含了 <code>Content-Encoding</code> 头部，对消息进行端到端编码。HTTP/1.1 加入了 <code>Transfer-Encoding</code> 头部可以对消息进行逐跳传输编码。HTTP/1.1 还加入了 <code>Accept-Encoding</code> 头部，是客户端来指示它能处理什么样的内容编码。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li><strong>连接方式</strong>：HTTP/1.0 默认短链接，HTTP/1.1 默认长连接。</li><li><strong>状态响应码</strong>：HTTP/1.1 中新家了大量的状态码，光是错误响应状态码就新增了 24 种。</li><li><strong>缓存处理</strong>：在 HTTP/1.0 中主要使用 header 里面的 <code>If-Modified-Since, Expires</code> 来作为缓存判断的标准，HTTP/1.1 则引入了更多的缓存控制策略，例如 <code>Entity tag, If-Unmodified-Since, If-Match, If-None-Match</code> 等更多可供选择的缓存头来控制缓存策略。</li><li><strong>带宽优化及网络连接的使用</strong>： HTTP/1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP/1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 <code>206（Partial Content）</code>，这样就方便了开发者自由的选择以便于充分利用带宽和连接。</li><li><strong>Host 头处理</strong>：HTTP/1.1 在请求头中加入了 <code>Host</code> 字段。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文将从以下几个维度来对比 HTTP1.0 和 HTTP1.1:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;响应状态码&lt;/li&gt;
&lt;li&gt;缓存处理&lt;/li&gt;
&lt;li&gt;连接方式&lt;/li&gt;
&lt;li&gt;Host 头处理&lt;/li&gt;
&lt;li&gt;带宽优化&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;响应状态码&quot;</summary>
      
    
    
    
    <category term="网络" scheme="https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP" scheme="https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/HTTP/"/>
    
    
    <category term="网络" scheme="https://tang7o.cn/tags/%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP" scheme="https://tang7o.cn/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>Redis的缓存问题</title>
    <link href="https://tang7o.cn/2022/03/07/Redis%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98/"/>
    <id>https://tang7o.cn/2022/03/07/Redis%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98/</id>
    <published>2022-03-07T03:09:14.000Z</published>
    <updated>2022-04-13T13:31:48.339Z</updated>
    
    <content type="html"><![CDATA[<h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>缓存雪崩是指在某一个时刻出现大规模的缓存失效的情况，大量的请求直接打在数据库上面，可能会导致数据库宕机，如果这时候重启数据库并不能解决根本问题，会再次造成缓存雪崩。</p><h4 id="为什么会造成缓存雪崩？"><a href="#为什么会造成缓存雪崩？" class="headerlink" title="为什么会造成缓存雪崩？"></a>为什么会造成缓存雪崩？</h4><p>一般来说，造成缓存雪崩主要有两种可能</p><ul><li>Redis 宕机了</li><li>很多 key 采取了相同的过期时间</li></ul><h4 id="如何解决缓存雪崩？"><a href="#如何解决缓存雪崩？" class="headerlink" title="如何解决缓存雪崩？"></a>如何解决缓存雪崩？</h4><ul><li>为避免 Redis 宕机造成缓存雪崩，可以搭建 Redis 集群。</li><li>尽量不要设置相同的过期时间，可以在原有的过期时间加上随机数。</li><li>服务降级，当流量达到一定的阈值时，就直接返回“系统繁忙”之类的提示，防止过多的请求直接打在数据库上，这样虽然难用，但是至少可以避免服务器宕机。</li></ul><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>缓存雪崩是大规模的 key 失效，而缓存击穿是一个热点的 key，有大量并发集中对其访问，突然间这个 key 失效了，导致大量并发请求全部打在数据库上， 导致数据库压力剧增，这种现象就叫做缓存击穿。</p><p>比较经典的例子就是商品秒杀时，大量的用户在抢某个商品时，商品的 key 突然过期失效了，所有请求都到数据库上了。</p><h4 id="如何解决缓存击穿？"><a href="#如何解决缓存击穿？" class="headerlink" title="如何解决缓存击穿？"></a>如何解决缓存击穿？</h4><ul><li>热点 key 不设置过期时间，避免 key 过期失效。</li><li>加锁，如果缓存失效的情况，只有拿到锁才能查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库宕机，不过这样会导致系统的性能变差。</li></ul><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>缓存穿透是指用户的请求没有经过缓存而直接请求到数据库上了，比如用户请求的 key 在 Redis 中不存在，或者用户恶意伪造大量不存在的 key 进行请求，都可以绕过缓存，导致数据库压力太大宕机。</p><h4 id="如何解决缓存穿透？"><a href="#如何解决缓存穿透？" class="headerlink" title="如何解决缓存穿透？"></a>如何解决缓存穿透？</h4><ul><li>参数校验，例如可以对用户 id 进行校验，直接拦截不合法的请求。</li><li>缓存空值，如果某个 key 在 Redis 中不存在，在数据库中也不存在，则把这个 key 值保存到 Redis，设置 value = “null”。</li><li>布隆过滤器，布隆过滤器可以判断这个 key 在不在数据库中，特点是：如果判断这个 key 不在数据库，那么这个 key 一定不在数据库中，如果判断这个 key 在数据库中，也不能保证这个 key 一定在数据库中。就是会有少数漏网之鱼，造成这种现象的原因是因为布隆过滤器使用了 hash 算法，对 key 进行 hash 时，不同的 key 的 hash 值一定不同，但是相同的 hash 值不能说明这两个 key 相同。</li></ul>]]></content>
    
    
    <summary type="html">什么是缓存雪崩、缓存穿透、缓存击穿，以及它们的解决方案</summary>
    
    
    
    <category term="Redis" scheme="https://tang7o.cn/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://tang7o.cn/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis并发竞争 key 问题</title>
    <link href="https://tang7o.cn/2022/03/07/Redis%E5%B9%B6%E5%8F%91/"/>
    <id>https://tang7o.cn/2022/03/07/Redis%E5%B9%B6%E5%8F%91/</id>
    <published>2022-03-07T02:16:51.000Z</published>
    <updated>2022-04-13T13:31:48.325Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 并发竞争 key 就是多个客户端操作一个 key，可能会导致数据出现问题，主要有以下几种解决方法：</p><ul><li>乐观锁，<code>watch</code> 命令可以方便的实现乐观锁。<code>watch</code> 命令会监视给的的每一个 key，当 <code>exec</code> 时如果监视的任一个 key 自从调用 <code>watch</code> 后发生过变化，则整个事务会回滚，不执行任何动作。不能在分片集群中使用。</li><li>分布式锁，适合分布式场景</li><li>时间戳，适合有序场景，比如 A 想把 key 设置为 1，B 想把 key 设置为 2，C 想把 key 设置为 3，对每个操作加上时间戳，写入前先比较自己的时间戳是不是早于现有记录的时间戳，如果早于，就不写入了。</li><li>消息队列，串行化处理。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Redis 并发竞争 key 就是多个客户端操作一个 key，可能会导致数据出现问题，主要有以下几种解决方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;乐观锁，&lt;code&gt;watch&lt;/code&gt; 命令可以方便的实现乐观锁。&lt;code&gt;watch&lt;/code&gt; 命令会监视给的的每一个 k</summary>
      
    
    
    
    <category term="Redis" scheme="https://tang7o.cn/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://tang7o.cn/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis分布式锁</title>
    <link href="https://tang7o.cn/2022/03/04/Redis%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    <id>https://tang7o.cn/2022/03/04/Redis%E5%88%86%E5%B8%83%E5%BC%8F/</id>
    <published>2022-03-04T01:56:34.000Z</published>
    <updated>2022-04-13T13:31:48.296Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是分布式锁？"><a href="#什么是分布式锁？" class="headerlink" title="什么是分布式锁？"></a>什么是分布式锁？</h3><p>分布式锁就是为了保证在分布式场景下，共享资源在同一时刻只能被一个线程访问，或者说是用来控制分布式系统之间同步访问共享资源。</p><h3 id="分布式锁有什么特性？"><a href="#分布式锁有什么特性？" class="headerlink" title="分布式锁有什么特性？"></a>分布式锁有什么特性？</h3><ul><li>互斥性：在任意时刻，同一条数据只能被一台机器的一个线程访问。</li><li>高可用性：当部分节点宕机后，客户端仍可以正常的获取锁和释放锁。</li><li>独占性：加锁和释放锁必须在同一台服务器执行，不能在一个服务器上获取锁，在另一个服务器释放锁。</li><li>防锁超时：如果客户端没有主动释放锁，服务器会在一定时间后自动释放锁，防止客户端宕机或者网络异常导致宕机。</li></ul><h3 id="分布式锁的实现方法？"><a href="#分布式锁的实现方法？" class="headerlink" title="分布式锁的实现方法？"></a>分布式锁的实现方法？</h3><p>基本思路就是要在整个系统中提供一个全局、唯一的“锁”，每个系统需要加锁时，都去尝试获取这个“锁”。</p><h3 id="Redis-如何实现分布式锁"><a href="#Redis-如何实现分布式锁" class="headerlink" title="Redis 如何实现分布式锁"></a>Redis 如何实现分布式锁</h3><p>前面写了分布式锁的特性，其实实现分布式锁就是围绕这些特性展开的。</p><p>Redis 实现分布式锁的主要命令：<strong>SETNX</strong>，该命令的作用是当 key 不存在时设置 key 的值，当 key 存在时，什么都不做。</p><p>先来看最简单的实现方式，如下图：</p><p><img src="1.png" class="lazyload" data-srcset="1.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>从上图可以看到主要两个关系步骤，加锁和解锁。</p><p>但是这个简陋的分布式锁存在很多问题，并不难满足上述介绍的分布式锁的特性，比如，当线程1执行到上图中执行业务这步时，业务代码突然出现了异常，无法进行删除锁这一步，那就G了，死锁了，其它线程也无法获取到锁了（SETNX 特性）。</p><h4 id="改进方案-1"><a href="#改进方案-1" class="headerlink" title="改进方案 1"></a>改进方案 1</h4><p>一提到异常，有人就想到了 <code>try-catch-finally</code> 了，把删除锁的操作放到 finally 代码块中，就算出现异常，也是能够正常释放锁的，执行业务出现异常这个问题解决了。但是这并不靠谱，如果 Redis 在执行业务这步宕机了呢，finally 代码块也不会执行。</p><h4 id="改进方案-2"><a href="#改进方案-2" class="headerlink" title="改进方案 2"></a>改进方案 2</h4><p>其实这个问题也好解决，只需要给锁设置一个过期时间就可以，对 key 设置过期时间在 Redis 中是常规操作了。<code>SET key value [EX seconds][PX milliseconds] [NX|XX]</code></p><ul><li>EX second: 设置键的过期时间为second秒；</li><li>PX millisecond：设置键的过期时间为millisecond毫秒；</li><li>NX：只在键不存在时，才对键进行设置操作；</li><li>XX：只在键已经存在时，才对键进行设置操作；</li><li>SET操作完成时，返回OK，否则返回nil。</li></ul><p>那现在这个方案就没问题了吗？显然没有</p><p>例如，线程 1 获取了锁，并设置了有效时间 10 秒，但是线程 1 在执行业务时超过了 10 秒，锁到期自动释放了，在释放后，线程 2 又获取了锁，在线程 2 执行业务时，线程 1 执行完业务了，随后执行了删除锁这一步，但是线程 1 的锁自动释放了，它删除的是线程 2 的锁。</p><h4 id="改进方案-3"><a href="#改进方案-3" class="headerlink" title="改进方案 3"></a>改进方案 3</h4><p>其实看起来方案 2 的问题很容易解决，只要把锁的过期时间设置的很长，就可以避免两个问题，但是这样并不可行，因为这样相当于回到最简陋的方案（会导致线程 2 一直获取不到锁（线程 1 因异常未能删除锁的情况下））。</p><p>如何解决线程 1 释放线程 2 的锁这一问题？</p><p>很简单，可以为锁加一个标识，例如生成一个 UUID，作为锁的标识，每个线程获取锁时都会生成一个不同的 UUID 作为标识，在删除锁时会进行判断，锁的标识和自己生成 UUID 相同时才能进行删除操作。</p><p>那么如何确定锁的过期时间呢？</p><p>可以在加锁时，设置一个预估的过期时间，然后开启一个守护线程，定时检测这个锁的失效时间，如果快要过期了，操作还未完成，那么就自动对锁进行“续费”。</p><p>那方案 3 就没有问题了吗？并不是，比如方案 3 的分布式锁还不具备可重入性（同一线程可以重复获取锁，解决线程需要多次进入锁内部执行任务的问题）</p><h4 id="改进方案-4"><a href="#改进方案-4" class="headerlink" title="改进方案 4"></a>改进方案 4</h4><p>参考其他重入锁的设计，通过对锁进行重入计数，加锁时加 1，解锁时减 1，计数为 0 时才能释放锁。</p><p>那现在的方案还有问题吗？其实还有，比如，线程 1 获取了锁，线程 2 没能获取到锁，那么线程 2 怎么知道线程 1 什么时候释放了锁，进而再去获取锁呢？</p><h4 id="改进方案-5"><a href="#改进方案-5" class="headerlink" title="改进方案 5"></a>改进方案 5</h4><p>方案 4 中问题，一般有两种解决方案：</p><ul><li>可以通过客户端轮询的方式，就是线程 2 过一会就过来看看是不是能获取锁了。这种方案比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。</li><li>通过 Redis 的发布订阅功能，当获取锁失败时，订阅锁信息，获取锁成功后释放时，发布释放锁信息。</li></ul><p>现在这个方案完美了吗？没有</p><p>目前讨论的都是单节点的情况，如果这个节点挂了，那么所有的客户端都获取不到锁了。</p><h4 id="改进方案-6"><a href="#改进方案-6" class="headerlink" title="改进方案 6"></a>改进方案 6</h4><p>为了实现 Redis 的分布式锁，Redis 的作者提出了 <a href="https://redis.io/topics/distlock">RedLock 算法</a>(英文好的可以直接去官网查看)。</p><p>首先介绍保证分布式锁的有效性和安全性的要求：</p><ul><li>互斥性：在任何给定时刻，只有一个客户端可以持有一个锁。</li><li>释放死锁：获取锁的客户端崩溃或者被分区，也可以释放锁。</li><li>容错性：只要大多 Redis 节点都在运行，客户端就能获取和释放锁。</li></ul><p>为什么基于故障转移实现的 Redis 分布式锁还不够用?</p><p>官网中举了一个例子：</p><p>客户端A获得主服务器上的锁，然后主服务器向从服务器复制数据的过程中崩了，导致数据没有复制到从数据库中，这时会在从服务器中选出来一个升级为主服务器，但新的主服务器中并没有客户端A设置的锁。所以客户端B也可以获取到锁，违背了上面说的<strong>互斥性</strong>。</p><p>这就解释了为什么使用 RedLock 算法。</p><h3 id="RedLock-算法"><a href="#RedLock-算法" class="headerlink" title="RedLock 算法"></a>RedLock 算法</h3><p>假设有 5 个完全独立的 Redis 服务器，多节点 Redis 实现的 RedLock 算法如下：</p><ul><li>获取当前时间戳。</li><li>客户端尝试在 5 个实例中按顺序获取锁，在所有实例中使用相同的键名和随机值。当在每个实例中设置锁时，需要将锁的获取时间设置的比锁过期时间短很多。例如，如果锁自动释放时间为 10 秒，则锁的获取时间在 5-50 毫秒。这是为了不要过长时间等待已经关闭的 Redis 实例，如果一个 Redis 实例不可用，我们应该尽快尝试下一个 Redis 实例。</li><li>客户端通过从当前时间中减去步骤 1 中获取的时间戳，计算出获取锁所需的时间。当且仅当客户端能够在大多数实例（本例至少 3 个）中获取锁，并且化费在获取锁的总时间小于锁的有效性时间，该锁则被认为已经获得。</li><li>如果获得了锁，锁真正的有效时间为锁初始设置的有效时间（过期时间）减去步骤 3 的时间，例如：锁初始的有效时间为 5s，获取锁花了 0.5s，则锁真正的有效时间为 4.5s（忽略了时钟偏移，时钟偏移指两个电脑间时间流速基本相同的情况下，两个电脑（或两个进程）时间的差值）</li><li>如果客户端由于某些原因无法获取锁（要么无法锁定 N/2 + 1 个 Redis 实例，要么锁的有效时间为负数），客户端将尝试解锁所有的 Redis 实例（即时是它认为无法锁定的 Redis 实例）</li></ul><h4 id="RedLock-算法是异步的吗？"><a href="#RedLock-算法是异步的吗？" class="headerlink" title="RedLock 算法是异步的吗？"></a>RedLock 算法是异步的吗？</h4><p>可以看成同步算法，虽然没有跨进程的同步时钟，但每个进程（多个电脑）的本地时间仍然大致以相同的速度流动，与锁的自动释放时间相比，误差较小，将其忽略的话，则可以看成同步算法。</p><h4 id="RedLock-失败重试"><a href="#RedLock-失败重试" class="headerlink" title="RedLock 失败重试"></a>RedLock 失败重试</h4><p>当客户端无法获取到锁时，应该在随机时间后重试，并且理想的客户端应该并发地将命令同时发给所有 Redis 实例。对于已经获取锁的客户端要在完成任务后及时释放锁，这样其他客户端就不需要等锁自动过期后再获取。如果在获取锁后，在主动释放锁前无法连接到 Redis 实例，那就只能等待锁自动失效了。</p><h4 id="释放锁"><a href="#释放锁" class="headerlink" title="释放锁"></a>释放锁</h4><p>释放锁很简单，只要释放所有 Redis 实例中的锁，不需要考虑是否释放成功（释放时需要判断这个锁的 vlaue 值是否自己设置的，避免释放其他客户端设置的锁）</p><h4 id="RedLock的-Safety-arguments"><a href="#RedLock的-Safety-arguments" class="headerlink" title="RedLock的 Safety arguments"></a>RedLock的 Safety arguments</h4><ul><li>假设客户端可以获取到大多数 Redis 实例，并且所有 Redis 实例具有相同的 key 和过期时间，但不同的 Redis 实例的 key 是不同的时间设置的（获取锁的时间不可能完全一致），所以过期时间也不同，假设获取第一个 Redis 实例的锁的时间为 T1,最后一个为 T2，则客户端获得锁的最小有效时间为 key 的有效时间 -（T2-T1）-时钟漂移。</li><li>为什么需要获取一半以上的 Redis 实例的锁才算获取到锁成功呢？因为如果获取不到一半也算成功的话会导致多个客户端同时获取到锁，违背了互斥性。</li><li>一个客户端锁定大多数 Redis 实例所需的时间大于或者接近锁的过期时间时，会认为锁无效，并解锁所有 Redis 实例。</li></ul><h4 id="RedLock崩溃的相关解决方法"><a href="#RedLock崩溃的相关解决方法" class="headerlink" title="RedLock崩溃的相关解决方法"></a>RedLock崩溃的相关解决方法</h4><p>场景：客户端 A 在成功获取锁后，如果所有 Redis 重启，这时客户端 B 就可以再次获取到锁，违背了互斥性。</p><p>解决方法：开启 AOF 持久化，可以解决这个问题，但是 AOF 同步到磁盘上的方式默认是每秒一次，如果 1 秒内断电，会导致 1 秒内的数据丢失，如果客户端是在这 1 秒内获得的锁，立即重启可能会导致锁的互斥性失效，解决方法是每次 Redis 无论因为什么原因停掉都要等 key 的过期时间到了再重启（延迟重启），这么做的缺点就是在等待重启这段时间内 Redis 处于关闭的状态。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;什么是分布式锁？&quot;&gt;&lt;a href=&quot;#什么是分布式锁？&quot; class=&quot;headerlink&quot; title=&quot;什么是分布式锁？&quot;&gt;&lt;/a&gt;什么是分布式锁？&lt;/h3&gt;&lt;p&gt;分布式锁就是为了保证在分布式场景下，共享资源在同一时刻只能被一个线程访问，或者说是用来控制分</summary>
      
    
    
    
    <category term="Redis" scheme="https://tang7o.cn/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://tang7o.cn/tags/Redis/"/>
    
    <category term="分布式" scheme="https://tang7o.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>服务器关闭,客户端继续写会发生什么？</title>
    <link href="https://tang7o.cn/2022/03/01/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%85%B3%E9%97%AD-%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%BB%A7%E7%BB%AD%E5%86%99%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F/"/>
    <id>https://tang7o.cn/2022/03/01/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%85%B3%E9%97%AD-%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%BB%A7%E7%BB%AD%E5%86%99%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F/</id>
    <published>2022-03-01T02:44:44.000Z</published>
    <updated>2022-04-13T13:31:49.038Z</updated>
    
    <content type="html"><![CDATA[<p>当服务器进程被终止时，会关闭其打开的所有文件描述符，此时就会向客户端发送一个 FIN 的报文,客户端则响应一个 ACK 报文,但是这样只完成了“四次挥手”的前两次挥手，也就是说这样只实现了半关闭，客户端仍然可以向服务器写入数据。</p><p>但是当客户端向服务器写入数据时，由于服务器端的套接字进程已经终止，此时连接的状态已经异常了，所以服务端进程不会向客户端发送 ACK  报文，而是发送了一个 RST 报文请求将处于异常状态的连接复位；如果客户端还要继续向服务端发送数据，系统会发出一个 SIGPIPE 信号给进程，告诉进程这个连接已经断开了，不要再写了。</p><p>根据信号的默认处理规则 SIGPIPE 信号的默认执行动作是 terminate(终止、退出),所以客户端会退出。</p>]]></content>
    
    
    <summary type="html">服务器关闭，客户端继续发送报文，会发生什么呢？</summary>
    
    
    
    <category term="网络" scheme="https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/"/>
    
    <category term="TCP" scheme="https://tang7o.cn/categories/%E7%BD%91%E7%BB%9C/TCP/"/>
    
    
    <category term="网络" scheme="https://tang7o.cn/tags/%E7%BD%91%E7%BB%9C/"/>
    
    <category term="TCP" scheme="https://tang7o.cn/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>HashMap为什么使用红黑叔而不是其他数据结构</title>
    <link href="https://tang7o.cn/2022/03/01/HashMap%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E7%BA%A2%E9%BB%91%E6%A0%91%E8%80%8C%E4%B8%8D%E6%98%AF%E5%85%B6%E4%BB%96%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>https://tang7o.cn/2022/03/01/HashMap%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E7%BA%A2%E9%BB%91%E6%A0%91%E8%80%8C%E4%B8%8D%E6%98%AF%E5%85%B6%E4%BB%96%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2022-03-01T01:22:09.000Z</published>
    <updated>2022-04-13T13:31:48.024Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为什么要使用红黑树以及什么时候使用红黑树？"><a href="#为什么要使用红黑树以及什么时候使用红黑树？" class="headerlink" title="为什么要使用红黑树以及什么时候使用红黑树？"></a>为什么要使用红黑树以及什么时候使用红黑树？</h3><p>向 HashMap 中添加数据时不可避免的会产生 Hash 冲突，而 HashMap 使用拉链法来解决 Hash 冲突，这就导致在 Hash 冲突较多的时候，会严重影响 HashMap 的查询效率（链表查询时间复杂度为O(n))，因此引入了红黑树（查询时间复杂度O(log n))这一数据结构来优化。</p><p><strong>那么什么时候会使用红黑树呢？</strong></p><p>在链表长度达到 8 并且 HashMap 存储的数据量大于 64 时，会将链表转化为红黑树。</p><p><strong>为什么不一开始就直接用红黑树呢？</strong></p><p>红黑树是二叉平衡树的一种，在插入和删除数据时红黑树需要通过旋转来保持“平衡”，这一过程是要付出代价的。而且红黑树节点的大小为链表节点的 2 倍，在节点太少时红黑树查找性能优势并不明显。</p><h3 id="为什么不适用其他数据结构？"><a href="#为什么不适用其他数据结构？" class="headerlink" title="为什么不适用其他数据结构？"></a>为什么不适用其他数据结构？</h3><p>如上所述，引入红黑树的目的是为了优化查询效率，但是能够优化查询效率的数据结构又不止红黑树一种，为什么不适用其他的数据结构呢？</p><p>例如二叉树、平衡二叉树、B树、B+树这些数据结构查询效率也很高，为什么不适用他们呢？</p><h4 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h4><p>二叉树存在数据倾斜问题，极端情况下会退化成链表（只有左节点或只有右节点），不够稳定。</p><h4 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h4><p>平衡二叉树和红黑树查询时间复杂度都是O（log n)。但是平衡二叉树有更加严格的”平衡“标准，在插入或者删除数据时，平衡二叉树需要更多的旋转才能达到平衡。</p><h4 id="B树、B-树"><a href="#B树、B-树" class="headerlink" title="B树、B+树"></a>B树、B+树</h4><p>B树和B+树的节点都能存储多个数据，在数据量不是很多的情况下，数据会”挤在“一个节点里面。这个时候遍历效率就退化成了链表。</p>]]></content>
    
    
    <summary type="html">众所周知，JDK1.8 及之后版本 HashMap 使用数组+链表+红黑树的数据结构，那么为什么引入了红黑树呢？为什么使用红黑树而不是其他的数据结构呢？</summary>
    
    
    
    <category term="Java" scheme="https://tang7o.cn/categories/Java/"/>
    
    
    <category term="Java" scheme="https://tang7o.cn/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 一条 SQL 语句的执行过程</title>
    <link href="https://tang7o.cn/2021/11/23/MySQL-ZXGC/"/>
    <id>https://tang7o.cn/2021/11/23/MySQL-ZXGC/</id>
    <published>2021-11-23T02:37:56.000Z</published>
    <updated>2022-04-13T13:31:48.246Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MySQL-驱动"><a href="#MySQL-驱动" class="headerlink" title="MySQL 驱动"></a>MySQL 驱动</h2><p>我们的系统在和 MySQL 数据库进行通信的时候，总不可能是平白无故的就能接受和发送请求，就算是你没有做什么操作，那总该是有其他的“人”帮我们做了一些事情，基本上使用过 MySQL 数据库的程序员多多少少都会知道 MySQL 驱动这个概念的。就是这个 MySQL 驱动在底层帮助我们做了对数据库的连接，只有建立连接了，才能有后面的交互。看下图表示：</p><p><img src="1.png" class="lazyload" data-srcset="1.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>这样的话，在系统和 MySQL 进行交互之前，MySQL 驱动会帮我们建立好连接，然后我们只需要发送 SQL 语句就可以执行 CRUD 了。一次 SQL 请求就会建立一个连接，多个请求就会建立多个连接，那么问题来了，我们系统肯定不是一个人在使用的，换句话说肯定是存在多个请求同时去争抢连接的情况。我们的 web 系统一般都是部署在 tomcat 容器中的，而 tomcat 是可以并发处理多个请求的，这就会导致多个请求会去建立多个连接，然后使用完再都去关闭，这样会有什么问题呢？如下图：</p><p><img src="2.png" class="lazyload" data-srcset="2.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>java 系统在通过 MySQL 驱动和 MySQL 数据库连接的时候是基于 TCP/IP 协议的，所以如果每个请求都是新建连接和销毁连接，那这样势必会造成不必要的浪费和性能的下降，也就是说上面的多线程请求的时候频繁的创建和销毁连接显然是不合理的。必然会大大的降低我们系统的性能，但是如果给你提供一些固定的用来连接的线程，这样是不是就不需要反复的创建和销毁连接了呢？相信懂行的朋友会会心一笑，没错，就是数据库连接池。</p><p><strong>数据库连接池</strong>：维护一定的连接数，方便系统获取连接，使用就去池子中获取，用完放回去就可以了，我们不需要关心连接的创建和销毁，也不需要关心线程池是怎么去维护这些连接的。</p><p><img src="3.png" class="lazyload" data-srcset="3.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>常见的数据库连接池有 Druid、C3P0、DBCP，连接池实现原理在这里就不深入讨论了，采用连接池大大节省了不断创建与销毁线程的开销，这就是有名的「池化」思想，不管是线程池还是 HTTP 连接池，都能看到它的身影。</p><h2 id="数据库连接池"><a href="#数据库连接池" class="headerlink" title="数据库连接池"></a>数据库连接池</h2><p>到这里，我们已经知道的是我们的系统在访问 MySQL 数据库的时候，建立的连接并不是每次请求都会创建的，而是从数据库连接池中去获取，这样就解决了因为反复的创建和销毁连接带来的性能损耗问题了。不过这里有个小问题，业务系统是并发的，而 MySQL 接受请求的线程呢，只有一个？</p><p>其实 MySQL 的架构体系中也已经提供了这样的一个池子，也是数据库连接池。双方都是通过数据库连接池来管理各个连接的，这样一方面是线程之前不需要争抢连接，更重要的是不需要反复的创建和销毁连接。</p><p><img src="4.png" class="lazyload" data-srcset="4.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>至此系统和 MySQL 数据库之间的连接问题已经说说明清楚了。那么 MySQL 数据库中这些连接是怎么来处理的，又是谁来处理的呢？</p><h2 id="网络连接必须由线程来处理"><a href="#网络连接必须由线程来处理" class="headerlink" title="网络连接必须由线程来处理"></a>网络连接必须由线程来处理</h2><p>对计算机基础稍微有一点了解的同学都是知道的，网络中的连接都是由线程来处理的，所谓网络连接说白了就是一次请求，每次请求都有相应的线程去处理。也就是说对于 SQL 语句的请求在 MySQL 中是由一个个线程去处理的。</p><p><img src="5.png" class="lazyload" data-srcset="5.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>那这些线程会怎么去处理这些请求？会做哪些事情？</p><h2 id="SQL-接口"><a href="#SQL-接口" class="headerlink" title="SQL 接口"></a>SQL 接口</h2><p>MySQL 中处理请求的线程在获取到请求以后获取 SQL 语句去交给 SQL 接口处理。</p><h2 id="查询解析器"><a href="#查询解析器" class="headerlink" title="查询解析器"></a>查询解析器</h2><p>假设现在有这样一个 SQL。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT stuName,age,sex FROM students WHERE id=1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>但是这个 SQL 是写给我们人看的，机器哪会知道你在说什么？这个时候解析器就上场了。他会将 SQL 接口传递过来的 SQL 语句进行解析，翻译成 MySQL 自己能认识的语言，至于怎么解析的就不需要再深究了，无非是自己的一套规则。</p><p><img src="6.png" class="lazyload" data-srcset="6.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>现在 SQL 已经被解析成 MySQL 认识的样子了，那下一步不就是执行了吗？理论上来说是这样的，但是 MySQL 的强大远不止如此，它还会帮我们选择最优的查询路径。</p><p>什么叫最优的查询路径？就是 MySQL 会按照自己认为的效率最高的方式去执行查询。</p><p>具体是怎么做到的呢？这就要说到 MySQL 的查询优化器了。</p><h2 id="MySQL-查询优化器"><a href="#MySQL-查询优化器" class="headerlink" title="MySQL 查询优化器"></a>MySQL 查询优化器</h2><p>查询优化器内部具体怎么实现的我们并不关心，我们需要知道的是 MySQL 会帮我们去使用它自己认为最好的方式去优化这条 SQL 语句，并且生成一条条的执行计划，比如你创建了多个索引，MySQL 会依据成本最小原则来选择使用响应的索引，这里的成本主要包括两个方面，IO 成本和 CPU 成本。</p><p><strong>IO 成本：</strong>即从磁盘把数据加载到内存的成本，默认情况下，读取数据页的 IO 成本是 1，MySQL 是以页的形式读取数据的，即当用到某个数据时，并不会只读取这个数据，而会把这个数据相邻的数据也一起读到内存中，这就是有名的程序局部性原理，所以 MySQL 每次会读取一整页，一页的成本是 1。所以 IO 的成本主要和页的大小有关。</p><p><strong>CPU 成本：</strong>将数据读入内存后，还需要杰测数据是否满足条件和排序等 CPU 操作的成本，显然它和行数有关，默认情况下，检测记录的成本为 0.2.</p><p>MySQL 优化器会计算「IO 成本 + CPU 成本」最小的那个索引来执行。</p><p><img src="7.png" class="lazyload" data-srcset="7.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>优化器执行选出最优索引等步骤后，会调用存储引擎接口，开始去执行被 MySQL 解析过和优化过的 SQL 语句。</p><h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><p>查询优化器会调用存储引擎的接口，去执行 SQL，也就是说真正执行 SQL 的动作是在存储引擎中完成的。数据是被存放放在内存或者是磁盘中的（存储引擎是一个非常重要的组件，后面会详细介绍）</p><h2 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h2><p>执行器是一个非常重要的组件，因为前面那些组件的操作最终必须通过执行器去调用存储引擎的接口才能被执行。执行器最终根据一系列的执行计划去调用存储引擎的接口去完成 SQL 的执行。</p><p><img src="8.png" class="lazyload" data-srcset="8.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><h2 id="初识存储引擎"><a href="#初识存储引擎" class="headerlink" title="初识存储引擎"></a>初识存储引擎</h2><p>我们以一个更新的 SQL 语句来说明，SQL 如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UPDATE students SET stuName = &#x27;张三&#x27; WHERE id = 1</span><br></pre></td></tr></table></figure><p>当我们系统发出这样的语句去交给 MySQL 的时候，MySQL 会按照我们上面介绍的一系列的流程最终通过执行器调用存储引擎去执行，流程图就是上面那个。在执行这个 SQL 的时候 SQL 语句对应的数据要么在内存中，要么是在磁盘中，如果在磁盘中操作，那这样的随机 IO 读写的速度肯定是让人无法接受的，所以每次在执行 SQL 的时候，都会将数据加载到内存中，这块内存就是 InnoDB 中一个非常重要的组件：<strong>缓冲池 Buffer Pool</strong>。</p><h2 id="Buffer-Pool"><a href="#Buffer-Pool" class="headerlink" title="Buffer Pool"></a>Buffer Pool</h2><p>Buffer Poll（缓冲池）是 InnoDB 存储引擎中非常重要的内存结构，顾名思义，缓冲池其实就是类似 Redis 一样的作用，因为我们都知道 MySQL 的数据最终是存储在磁盘中的，如果没有这个 Buffer Poll 那么我们每次的数据库请求都会在磁盘中查找，这样必然会存才 IO 操作，这肯定是无法接受的。但是如果有了 Buffer Poll 就是我们在第一次查询的时候会将查询的结果存到 Buffer Poll 中，这样后面再有请求的时候就会先从缓冲池中查询，如果没有再去磁盘中查找，然后放到 Buffer Poll 中，如下图：</p><p><img src="9.png" class="lazyload" data-srcset="9.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>按照上面的图，这条 SQL 语句的执行步骤大概是这样的：</p><ul><li>InnoDB 存储引擎会在缓冲池中查找 <code>id = 1</code> 的这条数据是否存在。</li><li>发现不存在，那么就会去磁盘中加载，并将其放在缓冲池中。</li><li>该条记录会被加上一个独占锁（总部能你在修改的时候别人也在该吧）</li></ul><h2 id="undo-日志文件：记录数据被修改前的样子"><a href="#undo-日志文件：记录数据被修改前的样子" class="headerlink" title="undo 日志文件：记录数据被修改前的样子"></a>undo 日志文件：记录数据被修改前的样子</h2><p>undo 顾名思义，就是没有做，没有发生的意思。undo log 就是没有发生事情（原本事情是什么样子）的一些日志。</p><p>我们刚刚已经说了，在准备更新一条语句的时候，该条语句已经被加载到 Buffer Pool 中来，实际上这里还有这样的操作，就是在将该条语句加载到 Buffer Poll 中的时候同时会往 undo 日志文件中插入一条日志，也就是将 <code>id = 1</code> 这条记录原来的值记录下来。</p><p><strong>这样做的目的是什么？</strong></p><p>InnoDB 存储引擎最大的特点就是支持事务，如果本次更新失败，也就是事务失败，那么该事务中的所有操作都必须回滚到执行前的样子，也就是说当事务失败的时候，也不会对原始数据有影响，如下图：</p><p><img src="10.png" class="lazyload" data-srcset="10.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>到这一步，我们执行的 SQL 语句已经被加载到 Buffer Pool 中了，然后开始更新这条语句，更新的操作实际是在 Buffer Pool 中执行的。那么问题来了，按照我们平时开发的一套理论缓冲池中的数据和数据库中的数据不一致的时候，我们就认为缓存中的数据是脏数据，那么此时 Buffer Pool 中的数据岂不是成了脏数据？没错，目前这条数据就是脏数据，Buffer Pool 中的记录是张三，数据库中的记录是李四，这种情况 MySQL 是怎么处理的呢？</p><h2 id="redo-日志文件：记录数据被修改后的样子"><a href="#redo-日志文件：记录数据被修改后的样子" class="headerlink" title="redo 日志文件：记录数据被修改后的样子"></a>redo 日志文件：记录数据被修改后的样子</h2><p>除了从磁盘中加载文件和将操作前的记录保存到 undo 日志中，其他的操作是在内存中完成的，内存中数据的特点就是：断电丢失。如果此时 MySQL 所在的服务器宕机了，那么 Buffer Pool 中的数据会全部丢失的。这个时候 redo 日志文件就需要出来大显神通了。</p><p><strong>画外音：redo 日志文件是 InnoDB 特有的，它是存储引擎级别的，不是 MySQL 级别的。</strong></p><p>redo 记录的数据修改之后的样子，不管事务是否提交都会记录下来，例如，此时要做的是<code>update students set stuName=&#39;小强&#39; where id=1;</code>那么这条操作就会被记录到 redo log buffer 中，啥？怎么又出来一个 redo log buffer，很简单，MySQL 为了提高效率，所以将这些操作都先放在内存中去完成，然后会在某个会时机将其持久化到磁盘中。</p><p><img src="11.png" class="lazyload" data-srcset="11.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>截至目前，我们应该熟悉了 MySQL 的执行器调用存储引擎是怎么将一条 SQL 加载到缓冲池和记录哪些日志的，流程如下：</p><ul><li>准备更新一条 SQL 语句</li><li>MySQL（InnoDB）会先去缓冲池（Buffer Pool）中去查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载到缓冲池（Buffer Pool）中。</li><li>在加载到 Buffer Poll 中的同时，会将这条数据的原始记录保存到 undo 日志文件中。</li><li>InnoDB 会在 Buffer Pool 中执行更新操作。</li><li>更新后的数据会记录在 redo log buffer 中。</li></ul><p>上面说的步骤都是在正常情况下的操作，但是程序的设计和优化并不仅是为了这些正常情况去做的，也是为了<strong>那些临界区和极端情况下出现的问题</strong>去优化设计的。</p><p>这个时候如果服务器宕机了，那么缓存中的数据还是丢失了。真烦，竟然数据总是丢失，那能不能不要放在内存中，直接保存到磁盘呢？很显然不行，因为在上面也已经介绍了，在内存中操作目的是为了提高效率。</p><p>此时，如果 MySQL 真的宕机了，那么没有关系的，因为 MySQL 会认为本次事务是失败的，所以数据依旧是更新前的样子，并不会有任何的影响。</p><p>好了，语句也更新好了那么需要将更新的值提交啊，也就是需要提交本次的事务了，因为只要事务成功提交了，才会将最后的变更保存到数据库，在提交事务前仍然会具有相关的其他操作。</p><p>将 redo log buffer 中的数据持久化到磁盘中，就是将 redo log buffer 中的数据写到 redo log 磁盘文件中，一般情况下，redo log buffer 数据写入磁盘的策略是立即刷入磁盘（具体策略情况在下面小总结处会详细介绍）</p><p><img src="12.png" class="lazyload" data-srcset="12.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>如果 redo log buffer 刷入磁盘后，数据库服务器宕机了，那么我们更新的数据怎么办？此时数据是在内存中，数据岂不是丢失了？不，这次数据就不会丢失了，因为 redo log buffer 中的数据已经被写入磁盘了，已经持久化了，就是数据库宕机了，在下次重启的时候 MySQL 也会将 redo 日志文件内容恢复到 Buffer pool 中（这边我理解的是和 Redis 的持久化机制是差不多的，在 Redis 启动的时候会检查 rdb 或者 aof 或者两者都检查，根据持久化的文件来将数据恢复到内存中）</p><p>到处为止，<strong>从执行器开始调用存储引擎接口做了哪些事情呢？</strong></p><ul><li>准备一条 SQL 语句。</li><li>MySQL（InnoDB）会先去缓冲池（Buffer Pool）中去查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载到缓冲池（Buffer Pool）中。</li><li>在加载到 Buffer Poll 中的同时，会将这条数据的原始记录保存到 undo 日志文件中。</li><li>InnoDB 会在 Buffer Pool 中执行更新操作。</li><li>更新后的数据会记录在 redo log buffer 中。</li><li>MySQL 提交事务的时候，会将 redo log buffer 中的数据写入到 redo 日志文件中，刷磁盘可以通过 <code>innodb_flush_log_at_trx_commit</code> 参数来设置。<ul><li>值为 0 表示不刷入磁盘</li><li>值为 1 表示立即刷入磁盘</li><li>值为 2 表示先刷到 os cache</li></ul></li><li>MySQL 重启时会将 redo 日志恢复到缓冲池中。</li></ul><p>截至到目前位置，MySQL 的执行器调用存储引擎的接口去执行「执行计划」提供的 SQL 的时候 InnoDB 做了哪些事情也就差基本差不多了，但是这还没完。下面还需要介绍下 MySQL 级别的日志 bin log。</p><h2 id="bin-log-日志文件：记录整个操作过程"><a href="#bin-log-日志文件：记录整个操作过程" class="headerlink" title="bin log 日志文件：记录整个操作过程"></a>bin log 日志文件：记录整个操作过程</h2><p>上面介绍到的 redo log 是 InnoDB 存储引擎特有的日志文件，而 bin log 是属于 MySQL 级别的日志。redo log 记录的东西是偏向于物理性质的，如：“对上面数据，做了什么修改”。bin log 是偏向于逻辑性质的，类似于：“对 students 表中 id 为 1 的记录做了更新操作”两者的主要特点总结如下。</p><div class="table-container"><table><thead><tr><th>性质</th><th>redo log</th><th>bin log</th></tr></thead><tbody><tr><td>文件大小</td><td>大小固定（配置中也可以设置，一般默认的就足够了）</td><td>可以通过配置参数 <code>max_bin log_size</code> 修改每个 bin log 的大小（但是一般不建议修改）。</td></tr><tr><td>实现方式</td><td>InnoDB 引擎实现的（也就是说是 InnoDB  存储引擎独有的）</td><td>MySQL 层实现的，所有引擎都可以使用。</td></tr><tr><td>记录方式</td><td>循环写的方式记录，当写到结尾时，会回到开头循环写日志。</td><td>追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上。</td></tr><tr><td>使用场景</td><td>适用于崩溃恢复（crash-safe）（这一点其实非常类似 Redis 的持久化特征）</td><td>适用于主从复制和数据恢复。</td></tr></tbody></table></div><p><strong>bin log 文件是如何刷入磁盘的？</strong></p><p>bin log 的刷盘是有相关的策略的，策略可以通过 <code>sync_bin log</code> 来修改，默认为 0，表示先写入 os cache，也就是在提交事务的时候，数据不会直接刷到磁盘中，这样如果宕机 bin log 数据仍然会丢失。所以建议将 <code>sync_bin log</code> 设置为 1 表示直接将数据写入到磁盘文件中。</p><p>刷入 bin log 有以下几种模式：</p><ul><li><strong>STATMENT</strong></li></ul><p>基于 SQL 语句的复制（statement-based replication, SBR)，每一条会修改数据的 SQL 语句会记录到 bin log 中。</p><p>【优点】：不需要记录每一行的变化，减少了 bin log 的日志量，节约了 IO，从而提高了性能。</p><p>【缺点】：在某些情况下会导致主从数据不一致，比如执行 <code>sysdat()</code>、<code>sleep()</code> 等。</p><ul><li><strong>ROW</strong></li></ul><p>基于行的复制（row-based replication, RBR），不记录每条SQL语句的上下文信息，仅需记录哪条数据被修改了。</p><p>【优点】：不会出现某些特定情况下的存储过程、或 function、或 trigger 的调用和触发无法被正确复制的问题。</p><p>【缺点】：会产生大量的日志，尤其是 <code>alter table</code> 的时候会让日志暴涨。</p><ul><li><strong>MIXED</strong></li></ul><p>基于 STATMENT 和 ROW 两种模式的混合复制（mixed-based replication, MBR），一般的复制使用 STATEMENT 模式保存 bin log，对于 STATEMENT 模式无法复制的操作使用 ROW 模式保存 bin log。</p><p>那既然 bin log 也是日志文件，那它是在什么时候记录数据呢？</p><p>其实 MySQL 在提交事务的时候，不仅仅会将 redo log buffer 中的数据写入 redo log 文件中，同时也会将本次修改的数据记录到 bin log 文件中，同时会将本次修改的 bin log 文件名和修改的内容在 bin log 中的位置记录到 redo log 中，最好还会在 redo log 写入 commit 标记，这样就表示本次事务被成功的提交了。</p><p><img src="13.png" class="lazyload" data-srcset="13.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>如果在数据被写入到 bin log 文件的时候，数据库宕机了，数据还会丢失吗？</p><p>首先可以确定的是，只要 redo log 最后没有 commit 标记，说明本次事务一定是失败的。但是数据是没有丢失的，因为已经记录到 redo log 的磁盘文件中了。在 MySQL 重启的时候，就会将 redo log 的数据恢复（加载）到 Buffer pool 中。</p><p>好了，到目前为止，一个更新操作我们基本介绍的差不多了，但是你有没有感觉少了哪些事情还没有做？是不是你也发现这个时候被更新的记录仅仅是在内存中执行的，哪怕是宕机又恢复了也仅仅是将更新后的记录加载到 Buffer Pool 中，这个时候 MySQL 数据库中的这条记录依旧是旧值，也就是说内存中的数据在我们看来依旧是脏数据，那这个时候怎么办呢？</p><p>其实 MySQL 会有一个后台线程，它会在某个时机将我们 Buffer Pool 中的脏数据刷到 MySQL 数据库中，这样就将内存和数据库中的数据保持统一了。</p><p><img src="14.png" class="lazyload" data-srcset="14.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><h2 id="本文总结"><a href="#本文总结" class="headerlink" title="本文总结"></a>本文总结</h2><p>到此，关于 Buffer Pool、redo log buffer 和 undo log、redo log、bin log 概念以及关系就基本差不多了。</p><p>我们再回顾下</p><ul><li>Buffer Pool 是 MySQL 的一个非常重要的组件，因为针对数据库的增删改操作都是在 Buffer Pool 中完成的</li><li>undo log 记录的是数据操作前的样子</li><li>redo log 记录的是数据被操作后的样子（redo log 是 InnoDB 存储引擎特有）</li><li>bin log 记录的是整个操作记录（这个对于主从复制具有非常重要的意义）</li></ul><p>从准备更新一条数据到事务的提交的流程描述</p><ul><li>首先执行器根据 MySQL 的执行计划来查询数据，先是从缓存池中查询数据，如果没有就会去数据库中查询，如果查询到了就将其放到缓存池中</li><li>在数据被缓存到缓存池的同时，会写入 undo log 日志文件</li><li>更新的动作是在 Buffer Pool 中完成的，同时会将更新后的数据添加到 redo log buffer 中。</li><li>完成以后就可以提交事务，在提交的同时会做以下三件事<ul><li>将 redo log buffer 中的数据刷入到 redo log 文件中。</li><li>将本次操作记录写入到 bin log 文件中。</li><li>将 bin log 文件名字和更新内容在 bin log 中的位置记录到 redo log 中，同时在 redo log 最后添加 commit 标记。</li></ul></li></ul><p>至此表示整个更新事务已经完成。</p><h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><ul><li>作者：码海</li><li>原文链接：<a href="https://blog.csdn.net/weixin_41385912/article/details/112975752">传送门</a></li></ul>]]></content>
    
    
    <summary type="html">天天和数据库打交道，一天能写上几十条 SQL 语句，但你知道我们的系统是如何和数据库交互的吗？MySQL 如何帮我们存储数据、又是如何帮我们管理事务？是不是感觉真的除了写几个「select * from dual」外基本脑子一片空白？这篇文章就将带你走进 MySQL 的世界，让你彻底了解系统到底是如何和 MySQL 交互的，MySQL 在接受到我们发送的 SQL 语句时又分别做了哪些事情。</summary>
    
    
    
    <category term="MySQL" scheme="https://tang7o.cn/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://tang7o.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 性能优化</title>
    <link href="https://tang7o.cn/2021/11/19/MySQL-XNYH/"/>
    <id>https://tang7o.cn/2021/11/19/MySQL-XNYH/</id>
    <published>2021-11-19T00:17:24.000Z</published>
    <updated>2022-04-13T13:31:48.217Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用-Explain-进行分析"><a href="#使用-Explain-进行分析" class="headerlink" title="使用 Explain 进行分析"></a>使用 Explain 进行分析</h2><p>Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。</p><p>比较重要的字段有:</p><ul><li>select_type : 查询类型，有简单查询、联合查询、子查询等</li><li>key : 使用的索引</li><li>rows : 扫描的行数</li></ul><h2 id="优化数据访问"><a href="#优化数据访问" class="headerlink" title="优化数据访问"></a>优化数据访问</h2><h3 id="1-减少请求的数据量"><a href="#1-减少请求的数据量" class="headerlink" title="1. 减少请求的数据量"></a>1. 减少请求的数据量</h3><ul><li>只返回必要的列: 最好不要使用 SELECT * 语句。</li><li>只返回必要的行: 使用 LIMIT 语句来限制返回的数据。</li><li>缓存重复查询的数据: 使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。</li></ul><h3 id="2-减少服务器端扫描的行数"><a href="#2-减少服务器端扫描的行数" class="headerlink" title="2. 减少服务器端扫描的行数"></a>2. 减少服务器端扫描的行数</h3><p>最有效的方式是使用索引来覆盖查询。</p><h2 id="重构查询方式"><a href="#重构查询方式" class="headerlink" title="重构查询方式"></a>重构查询方式</h2><h3 id="1-切分大查询"><a href="#1-切分大查询" class="headerlink" title="1. 切分大查询"></a>1. 切分大查询</h3><p>一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。</p><h3 id="2-分解大连接查询"><a href="#2-分解大连接查询" class="headerlink" title="2. 分解大连接查询"></a>2. 分解大连接查询</h3><p>将一个大连接查询分解成对每一个表进行一次单表查询，然后将结果在应用程序中进行关联，这样做的好处有:</p><ul><li>让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。</li><li>分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。</li><li>减少锁竞争；</li><li>在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。</li><li>查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;使用-Explain-进行分析&quot;&gt;&lt;a href=&quot;#使用-Explain-进行分析&quot; class=&quot;headerlink&quot; title=&quot;使用 Explain 进行分析&quot;&gt;&lt;/a&gt;使用 Explain 进行分析&lt;/h2&gt;&lt;p&gt;Explain 用来分析 SELEC</summary>
      
    
    
    
    <category term="MySQL" scheme="https://tang7o.cn/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://tang7o.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 引擎</title>
    <link href="https://tang7o.cn/2021/11/16/MySQL-YQ/"/>
    <id>https://tang7o.cn/2021/11/16/MySQL-YQ/</id>
    <published>2021-11-16T12:46:12.000Z</published>
    <updated>2022-04-13T13:31:48.231Z</updated>
    
    <content type="html"><![CDATA[<h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><p>是 MySQL 默认的事务型存储引擎，<strong>只有在需要它不支持的特性时，才考虑使用其它存储引擎</strong>。</p><p>实现了四个标准的隔离级别，默认级别为可重复读。在可重复读的级别下，通过多版本并发控制（MVCC）+间隙锁（Next-Key Locking）防止幻读。</p><p>基于聚簇索引（主索引）建立，在主索引中保存数据。与其他存储引擎有很大的区别，聚簇索引对主键查询有很高的性能，不过它的二级索引（非主键索引）必须包含主键列。所以如果主键列很大的话，索引会很大。</p><h3 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h3><p>在5.1之前，MyISAM 是默认的引擎，MyISAM 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。</p><p>提供了大量的特性，包括压缩表、空间数据索引等。</p><p>但是 MyISAM 不支持事务和行级锁，而且在崩溃后无法安全恢复。即使后续版本中 MyISAM 支持了事务，但是很多人的概念中依然是不支持事务的引擎。</p><p>不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。</p><h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><h4 id="事务和外键"><a href="#事务和外键" class="headerlink" title="事务和外键"></a>事务和外键</h4><p>InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。</p><p>InnoDB 支持外键。</p><h4 id="锁和并发"><a href="#锁和并发" class="headerlink" title="锁和并发"></a>锁和并发</h4><p>MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。</p><p>MyISAM 读写互相阻塞：不仅会在写入的时候阻塞读取，MyISAM 还会在读取的时候阻塞写入，但读本身并不会阻塞另外的读。</p><p>InnoDB 读写阻塞与事务隔离级别相关。</p><h4 id="索引和存储"><a href="#索引和存储" class="headerlink" title="索引和存储"></a>索引和存储</h4><p>MyISAM 和 InnoDB 的索引都采用了 B+ 树的结构。</p><p>MyISAM 的索引和数据是分开的，是<strong>非聚簇索引。</strong>叶子节点存放索引键和数据记录的地址，如下图所示：</p><p><img src="1.png" class="lazyload" data-srcset="1.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>MyISAM 引擎将数据存储成三个文件，以表名命名，扩展名指出文件类型。</p><ul><li>.frm 文件存储表定义。</li><li>.MYD 文件存储数据。</li><li>.MYI 文件存储索引。</li></ul><p>而 InnoDB 引擎的数据存储在聚簇索引（主键建立的索引）的叶子节点中，如下图所示：</p><p><img src="2.png" class="lazyload" data-srcset="2.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>InnoDB 的非聚簇索引的叶子节点存储了该条记录的主键。如下图所示：</p><p><img src="3.png" class="lazyload" data-srcset="3.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>因此使用非聚簇索引查询数据时，还需要利用聚簇索引再查询一遍（回表查询）。但是有一种情况例外：你要查询的信息包含在索引内（覆盖索引）。</p><p><strong>注意：MyISAM 表是保存成文件的形式，在跨平台的数据转移中使用MyISAM存储会省去不少的麻烦</strong>。</p><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><ul><li>MyISAM 引擎保存了表中数据的行数，查询时可以直接读取。InnoDB 引擎需要扫描一遍表来计算行数。<strong>但是如果查询语句中包含了 <code>where</code> 条件时，两种引擎的操作是一样的。</strong></li><li><code>DELETE FROM table</code> 时，InnoDB 不会重新建立表，而是一行一行的删除。</li><li>如果执行大量的 <code>SELECT</code>，MyISAM 是更好的选择，如果你的数据执行大量的 <code>INSERT</code> 或 <code>UPDATE</code>，出于性能方面的考虑，应该使用 <code>InnoDB</code> 表。</li></ul>]]></content>
    
    
    <summary type="html">MyISAM 引擎和 InnoDB 引擎分别为 MySQL 5.1 前后的默认引擎，它们之间有什么区别？</summary>
    
    
    
    <category term="MySQL" scheme="https://tang7o.cn/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://tang7o.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL事务ACID实现原理</title>
    <link href="https://tang7o.cn/2021/11/13/MySQL-ACID/"/>
    <id>https://tang7o.cn/2021/11/13/MySQL-ACID/</id>
    <published>2021-11-13T11:40:15.000Z</published>
    <updated>2022-04-13T13:31:48.190Z</updated>
    
    <content type="html"><![CDATA[<h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>实现原理：利用 undo log。</p><p>undo log 名为回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的 sql 语句，他需要记录你要回滚的相应日志信息：</p><ul><li>当你 delete 一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert 这条旧数据</li><li>当你 update 一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行 update 操作</li><li>当年insert一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行 delete 操作</li></ul><p>undo log 记录了这些回滚需要的信息，当事务执行失败或调用了 rollback ，导致事务需要回滚，便可以利用 undo log 中的信息将数据回滚到修改之前的样子。</p><h3 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h3><p>实现原理：利用 redo log。</p><p>MySQL 先把磁盘上的数据加载到内存，在内存中进行修改，再刷回磁盘。如果此时突然宕机，内存中的数据将会丢失。</p><p>如何解决这个问题？</p><p>事务提交前直接把数据写入磁盘？这样做存在以下的问题：</p><ul><li>只修改一个页面里的一个字节，就要将整个页面刷入磁盘，太浪费资源了。毕竟一个页面 16kb 大小，你只改其中一点点东西，就要将 16kb 的内容刷入磁盘，听着也不合理。</li><li>毕竟一个事务里的 SQL 可能牵涉到多个数据页的修改，而这些数据页可能不是相邻的，也就是属于随机 IO。显然操作随机 IO，速度会比较慢。</li></ul><p>于是，采用 redo log 解决上面的问题。当修改数据时，不仅在内存中修改，还会在 redo log 中记录这次操作。当事务提交的时候，会将 redo log 日志进行刷盘（redo log 一部分在内存中，一部分在磁盘上）。当数据库宕机重启的时候，会将 redo log 的内容恢复到数据库中，再根据 undo log 和 bin log 来决定回滚还是提交数据。</p><p><strong>采用 redo log 的好处（相对直接将数据写入磁盘）：</strong></p><ul><li>redo log 体积小，只记录了哪一页修改了什么，刷盘快。</li><li>redo log 是一直往末尾追加，属于顺序 IO。效率更高。</li></ul><h3 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h3><p>实现原理：锁 + MVCC。</p><p>锁很简单，就是事务在修改数据的时候需要获取锁、上锁之类的操作。</p><p>MVCC：多版本并发控制（Multi Version Concurrency Control），一个行记录数据有多个版本对快照数据，这些快照数据在 undo log 中。</p><p>如果一个事务读取的行正在做 DELELE 或者 UPDATE 操作，读取操作不会等行上的锁释放，而是读取该行的快照版本。</p><h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>数据库通过原子性、隔离性、持久性来保证一致性。也就是说ACID四大特性之中，C（一致性）是目的，A（原子性）、I（隔离性）、D（持久性）是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现AID三大特性，才有可能实现一致性。</p><p>数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等。</p><p>应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致。</p>]]></content>
    
    
    <summary type="html">简单的记录了MySQL事务ACID的实现原理。</summary>
    
    
    
    <category term="MySQL" scheme="https://tang7o.cn/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://tang7o.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Redis事务</title>
    <link href="https://tang7o.cn/2021/11/11/Redis%E4%BA%8B%E5%8A%A1/"/>
    <id>https://tang7o.cn/2021/11/11/Redis%E4%BA%8B%E5%8A%A1/</id>
    <published>2021-11-11T13:32:15.000Z</published>
    <updated>2022-04-13T13:31:48.282Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 通过 MULTI、EXEC、WATCH 等命令来实现事务功能。事务提供一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制。</p><p>以下是一个事务的执行过程，该事务首先以一个 MULTI 命令为开始，接着将多个命令放入事务中，最后由 EXEC 命令将这个事务提交给服务器执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; SET &quot;name&quot; &quot;Practical Common Lisp&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; GET &quot;name&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; SET &quot;author&quot; &quot;Peter Seibel&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; GET &quot;author&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; EXEC</span><br><span class="line">1) OK</span><br><span class="line">2) &quot;Practical Common Lisp&quot;</span><br><span class="line">3) OK</span><br><span class="line">4) &quot;Peter Seibel&quot;</span><br></pre></td></tr></table></figure><h2 id="事务的实现"><a href="#事务的实现" class="headerlink" title="事务的实现"></a>事务的实现</h2><p>一个事务从开始到结束通常会经历以下三个阶段：</p><ol><li>事务开始。</li><li>命令入队。</li><li>事务执行。</li></ol><h3 id="事务开始"><a href="#事务开始" class="headerlink" title="事务开始"></a>事务开始</h3><p>MULTI 命令的执行标志着事务的开始：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>MULTI 命令可以将执行该命令的客户端从非事务状态切换到事务状态，这一切换是通过在客户端状态的 flags 属性中打开 REDIS_MULTI 标识来完成的，具体实现可以用以下伪代码来表示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">MULTI</span><span class="params">()</span>:</span></span><br><span class="line"><span class="function">#打开事务标识识</span></span><br><span class="line"><span class="function">client.flags |=</span> REDIS_MULTI</span><br><span class="line">#返回OK回复</span><br><span class="line"><span class="built_in">replyOK</span>()</span><br></pre></td></tr></table></figure><h3 id="命令入队"><a href="#命令入队" class="headerlink" title="命令入队"></a>命令入队</h3><p>当一个客户端还处于非事务状态时，这个客户端发送的命令会立即被服务器执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; SET &quot;name&quot; &quot;Practical Common Lisp&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; GET &quot;name&quot;</span><br><span class="line">&quot;Practical Common Lisp&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; SET &quot;author&quot; &quot;Peter Seibel&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; GET &quot;author&quot;</span><br><span class="line">&quot;Peter Seibel&quot;</span><br></pre></td></tr></table></figure><p>与此不同的是，当一个客户端切换到事务状态之后，服务器会根据这个客户端发来的不同命令执行不同的操作：</p><ul><li>如果命令为 EXEC、DISCARD、WATCH、MULTI四 个命令中的其中一个，那么服务器会立即执行这个命令。</li><li>其他的命令不会立即执行，而是将这个命令放入一个事务队列里面，然后向客户端返回 QUEUED 回复。</li></ul><p><img src="1.png" class="lazyload" data-srcset="1.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><h3 id="事务队列"><a href="#事务队列" class="headerlink" title="事务队列"></a>事务队列</h3><p>每个 Redis 客户端都有自己的事务状态，这个事务状态保存在客户端状态的 mstate 属性中：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">redisClient</span> &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//事务状态</span></span><br><span class="line">    multiState mstate; <span class="comment">/* MULTI/EXEC state */</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125; redisClient;</span><br></pre></td></tr></table></figure><p>事务状态包含一个事务对象，以及一个已入队命令的计数器（事务队列的长度）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">multiState</span> &#123;</span><br><span class="line">    <span class="comment">//事务队列，FIFO顺序</span></span><br><span class="line">    multiCmd *commands;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//已入队命令计数</span></span><br><span class="line">    <span class="type">int</span> count;</span><br><span class="line">&#125; multiState;</span><br></pre></td></tr></table></figure><p>事务队列是一个 multiCmd 类型的数组，数组中每个 multiCmd 结构都保存来一个已入队的命令的相关信息，包含指向命令实现函数的指针、命令参数，以及参数的数量：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">multiCmd</span> &#123;</span><br><span class="line">    <span class="comment">//参数</span></span><br><span class="line">    robj **argv;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//参数数量</span></span><br><span class="line">    <span class="type">int</span> argc;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//命令指针</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">redisCommand</span> *cmd;</span><br><span class="line">&#125; multiCmd;</span><br></pre></td></tr></table></figure><h3 id="执行事务"><a href="#执行事务" class="headerlink" title="执行事务"></a>执行事务</h3><p>当一个处于事务状态的客户端向服务器发送 EXEC 命令时，这个 EXEC 命令会立即被执行。服务器会遍历客户端的事务队列，执行队列中的所有命令，最后将执行的结果全部返回给客户端。</p><p>EXEC 的实现原理可以用以下伪代码来描述：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">def EXEC():</span><br><span class="line">    # 创建空白的回复队列</span><br><span class="line">    reply_queue = []</span><br><span class="line">    </span><br><span class="line">    # 遍历事务队列中的每个项</span><br><span class="line">    # 读取命令的参数、参数个数、以及要执行的命令</span><br><span class="line">    for argv, argc, cmd in client.mstate.commands:</span><br><span class="line">        # 执行命令，并取得命令的返回值</span><br><span class="line">        reply = execute_command(cmd, argv, argc)</span><br><span class="line">        # 将返回值加到回复队列末尾</span><br><span class="line">        reply_queue.append(reply)</span><br><span class="line">        </span><br><span class="line">    # REDIS_MULTI 标识，让客户端回到非事务状态</span><br><span class="line">    client.flags &amp; = ~REDIS_MULTI</span><br><span class="line">    </span><br><span class="line">    # 清空客户端的事务状态，包括：</span><br><span class="line">    # 1）清零入队命令计数器</span><br><span class="line">    # 2）释放事务队列</span><br><span class="line">    client.mstate.count = 0</span><br><span class="line">    release_transaction_queue(client.mstate.commands)</span><br><span class="line">    </span><br><span class="line">    # 将事务的执行结果返回给客户端</span><br><span class="line">    send_reply_to_client(client, reply_queue)</span><br></pre></td></tr></table></figure><h2 id="WATCH-命令的实现"><a href="#WATCH-命令的实现" class="headerlink" title="WATCH 命令的实现"></a>WATCH 命令的实现</h2><p>WATCH 命令是一个乐观锁，它可以在 EXEC 命令执行前，监视任意数量的键，并在 EXEC 命令执行时，检查被监视的键是否至少有一个被修改过，如果是，服务器拒绝执行事务，并向客户端返回代表事务执行失败的空回复。</p><p><strong>注意：EXEC 命令开始执行后遍历事务队列执行事务，因此事务中的修改不对 WATCH 造成影响。</strong></p><h3 id="使用-WATCH-命令监视数据库键"><a href="#使用-WATCH-命令监视数据库键" class="headerlink" title="使用 WATCH 命令监视数据库键"></a>使用 WATCH 命令监视数据库键</h3><p>每个 Redis 数据库都保存着一个 watched_keys 字典，这个字典的键是某个被 WATCH 命令监视的数据库键，而字典的值则是一个链表，链表中记录了所有监视相应数据库键的客户端：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">redisDb</span> &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//正在被WATCH命令监视的键</span></span><br><span class="line">    dict *watched_keys;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125; redisDb;</span><br></pre></td></tr></table></figure><p>通过 watched_keys 字典，服务器可以清楚的指导那些数据库键正在被监视，以及哪些客户端正在监视这些数据库键。</p><p>假设当前客户端为 c10086,数据库 watched_keys 字典状态为下图所示：</p><p><img src="2.png" class="lazyload" data-srcset="2.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>当 c10086 执行以下命令后：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; WATCH &quot;name&quot; &quot;age&quot;</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>数据库 watched_keys 字典状态变为下图所示：</p><p><img src="3.png" class="lazyload" data-srcset="3.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><h3 id="监视机制的触发"><a href="#监视机制的触发" class="headerlink" title="监视机制的触发"></a>监视机制的触发</h3><p>所有对数据库进行修改的命令，在执行之前都会调用 <code>multi.c/touchWatchKey</code> 函数对 watched_keys 字典进行检查，查看是否有客户端正在监视要修改的键，如果有的话，<code>touchWatchKey</code> 函数会将监视被修改键的客户端的 <code>REDIS_DIRTY_CAS</code> 标识打开，标识该客户端的事务安全性已经被破坏。</p><p><code>touchWatchKey</code> 函数的定义可以用以下伪代码来描述：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def touchWatchKey(db, key):</span><br><span class="line">    # 如果键 key 存在于数据库的 watched_keys 字典中</span><br><span class="line">    # 那么说明至少有一个客户端在监视这个 key</span><br><span class="line">    if key in db.watched_keys:</span><br><span class="line">    # 遍历所有监视 key 的客户端</span><br><span class="line">        for client in db.watched_keys[key]:</span><br><span class="line">            # 打开 REDIS_DIRTY_CAS 标识</span><br><span class="line">            client.flags |= REDIS_DIRTY_CAS</span><br></pre></td></tr></table></figure><h3 id="判断事务是否安全"><a href="#判断事务是否安全" class="headerlink" title="判断事务是否安全"></a>判断事务是否安全</h3><p>当服务器接收到客户端发来的 EXEC 命令时，服务器会根据这个客户端是否打开了 <code>REDIS_DIRTY_CAS</code> 标识来决定是否执行事务：</p><p><img src="4.png" class="lazyload" data-srcset="4.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><h2 id="事务的-ACID-性质"><a href="#事务的-ACID-性质" class="headerlink" title="事务的 ACID 性质"></a>事务的 ACID 性质</h2><p>在 Redis 中，事务总是具有原子性（Atomicity）、一致性（Consistency）和隔离性（Isolation），某种特定的持久化情况下具有持久性（Durability）。</p><h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>事务具有原子性是指，数据库将事务中的多个操作当作一个整体来执行，要么都执行，要么就一个也不执行。</p><p>对于 Redis 的事务功能来说，事务队列中的命令要么全部执行，要么就一个都不执行，因此，Redis 的事务是具有原子性的。</p><p>例子，成功执行的事务，事务的命令都会被执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; SET msg &quot;hello&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; GET msg</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; EXEC</span><br><span class="line">1) OK</span><br><span class="line">2) &quot;hello&quot;</span><br></pre></td></tr></table></figure><p>例子，执行失败的事务，这个事务因为命令入队出错而被服务器拒绝执行，事务的命令都不会执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">redis&gt; SET msg &quot;hello&quot;</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; GET</span><br><span class="line">(error) ERR wrong number of arguments for &#x27;get&#x27; command</span><br><span class="line">redis&gt; GET msg</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; EXEC</span><br><span class="line">(error) EXECABORT Transaction discarded because of previous errors.</span><br></pre></td></tr></table></figure><p>Redis 事务和传统的关系数据库事务最大的区别在于：Redis 不支持事务回滚机制，即时事务队列中的某个命令在<strong>执行期间</strong>出现了错误，整个事务也会继续执行下去，直到事务执行完毕。</p><p>例子，即时 RPUSH 命令在<strong>执行期间</strong>出现了错误，事务的后续命令也会继续执行下去，并且之前执行的命令也不会有任何影响：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; SET msg &quot;hello&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; SADD fruit &quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; RPUSH msg &quot;good bye&quot; &quot;bye bye&quot; # 错误的对字符串键 msg 执行列表键的操作</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; SADD alphabet &quot;a&quot; &quot;b&quot; &quot;c&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; EXEC</span><br><span class="line">1) (integer) 3</span><br><span class="line">2) (error) WRONGTYPE Operation against a key holding the wrong kind of value</span><br><span class="line">3) (integer) 3</span><br></pre></td></tr></table></figure><blockquote><p>Redis 的作者在事务功能的文章中解释说：不支持事务回滚是因为这种复杂的功能和 Redis 追求简单高效的设计主旨不相符，并且他认为，Redis 事务的执行时错误通常都是编译错误产生的，这种错误通常只会出现在开发环境中，而很少在实际的生产环境中出现，所以他认为没有必要为 Redis 开发事务回滚功能。</p></blockquote><h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>事务具有一致性指的是，如果数据库在执行事务之前是一致的，那么在执行事务之后，无论事务是否执行成功，数据库也应该仍然是一致的。</p><p>“一致”是指数据符合数据库本身的定义和要求，没有包含非法或无效的错误数据。</p><p>Redis 通过谨慎的错误检测和简单的设计来保证事务的一致性，以下三部分分别介绍三个 Redis 事务可能出错的地方，并说明 Redis 是如何处理这些错误，从而确保事务的一致性。</p><h4 id="1-入队错误"><a href="#1-入队错误" class="headerlink" title="1.入队错误"></a>1.入队错误</h4><p>如果一个事务在入队命令的过程中，出现了命令不存在，或者命令的格式不正确等情况，那么 Redis 将拒绝执行这个事务。</p><p>例子，因为客户端尝试向事务入队一个不存在的命令 Tang7O，所以客户端提交的事务会被服务器拒绝执行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; SET msg &quot;hello&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; YAHOOOO</span><br><span class="line">(error) ERR unknown command &#x27;Tang7O&#x27;</span><br><span class="line"></span><br><span class="line">redis&gt; GET msg</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; EXEC</span><br><span class="line">(error) EXECABORT Transaction discarded because of previous errors.</span><br></pre></td></tr></table></figure><p>因为服务器会拒绝执行入队错误的事务，因此 Redis 事务的一致性不会被带有入队错误的事务影响。</p><blockquote><p>Redis 2.6.5 以前的版本，即时有命令在入队过程中发生了错误，事务一样可以执行，不过被执行的命令只包括哪些正确入队的命令。</p></blockquote><h4 id="2-执行错误"><a href="#2-执行错误" class="headerlink" title="2.执行错误"></a>2.执行错误</h4><p>除了入队时可能发生错误外，事务还可能在执行过程中发生错误。</p><ul><li>执行过程中发生的错误都是一些不能在入队时被服务器发现的错误，这些错误只会在命令实际执行时被触发。</li><li>即使在事务的执行过程中发生了错误，服务器也不会中断事务的执行，它会继续执行事务中余下的其他命令，并且已经执行的命令不会被出错的命令影响。</li></ul><p>例子，用列表键的 RPUSH 命令操作字符串键。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; SET msg &quot;hello&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; SADD fruit &quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; RPUSH msg &quot;good bye&quot; &quot;bye bye&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; SADD alphabet &quot;a&quot; &quot;b&quot; &quot;c&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; EXEC</span><br><span class="line">1) (integer) 3</span><br><span class="line">2) (error) WRONGTYPE Operation against a key holding the wrong kind of value</span><br><span class="line">3) (integer) 3</span><br></pre></td></tr></table></figure><p>因为在事务执行的过程中，出错的命令会被服务器识别出来，并进行响应的处理，所以不会对事务的一致性产生影响。</p><h4 id="3-服务器停机"><a href="#3-服务器停机" class="headerlink" title="3.服务器停机"></a>3.服务器停机</h4><p>如果 Redis 服务器在事务执行过程中停机，那么根据服务器所使用的持久化模式，可能有以下情况出现：</p><ul><li><p><strong>无持久化</strong>：重启之后数据库是空白的，因此数据总是一致的。</p></li><li><p><strong>RDB 持久化</strong>：事务中途停机不会导致不一致性，因为服务器可以根据现有的 RDB 文件来恢复数据，从而将数据库还原到一个一致性状态。如果找不到可供使用的 RDB 文件，那么重启之后数据库将是空白的，而空白数据库总是一致的。</p></li><li><strong>AOF 持久化</strong>：服务器可以根据现有的 AOF 文件来恢复数据，从而将数据库还原到一个一致性状态。找不到可供使用的 AOF 文件，那么重启之后数据库将是空白的，而空白数据库总是一致的。</li></ul><h3 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h3><p>事务的隔离性是指：即时数据库有多个事务并发地执行，各个事务之间也不会互相影响，并且在并发的状态下执行的事务和串行执行事务的结果完全相同。</p><p>因为 Redis 使用单线程来执行事务，并且服务器保证，在执行事务期间不会对事务进行中断，因此，Redis 的事务总是以串行的方式进行的，并且事务也总是具有隔离性的。</p><h3 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h3><p>事务的持久性是指：当一个事务执行完毕时，执行这个事务所获得的结果已经被保存到永久性存储介质（比如硬盘）里面，即时服务器在事务执行完毕之后停机，执行事务所得的结果也不会丢失。</p><p>因为 Redis 的事务不过是简单地用队列包裹起了一组 Redis 命令，Redis 并没有为事务提供任何额外的持久化功能，所以 Redis 事务的持久性由 Redis  所使用的持久化模式来决定：</p><ul><li><p><strong>无持久化</strong>：事务不具有持久性，一旦服务器停机，包括事务数据在内的所有数据都将丢失。</p></li><li><p><strong>RDB 持久化</strong>：服务器只在特定的保存条件被满足时才会执行 BGSAVE 命令，对数据库进行保存操作，并且异步执行的 BGSAVE 不能保证事务数据第一时间被保存到硬盘里面，因此 RDB 持久模式下的事务也不具有持久性。</p></li><li><p><strong>AOF 持久化</strong>：</p><ul><li><p>appendfsync 选项的值为 always 时，程序总会在执行命令之后调用同步（sync）函数，将命令数据真正的保存到池盘里面，这种配置下的事务是具有持久性的。</p></li><li><p>appendfsync 选项的值为 everysec 时，程序会每秒同步一次命令数据到磁盘。因此停机可能会恰好发生在等待同步的那一秒内，这可能会造成事务数据丢失，所以这种配置下事务不具有持久性。</p></li><li>appendfsync 选项的值为 no 时，程序会交由操作系统来决定何时将命令数据同步到硬盘。因此事务数据可能在等待同步的过程中丢失，所以这种模式下不具有持久性。</li></ul></li></ul><p>不论 Redis 在什么模式下运作，在一个事务的后面加上 SAVE 命令总是可以保证事务的持久性：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; SET msg &quot;hello&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; SAVE</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; EXEC</span><br><span class="line">1) OK</span><br><span class="line">2) OK</span><br></pre></td></tr></table></figure><p>不过因为这种做法的效率太低，所以不具有实用性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Redis 通过 MULTI、EXEC、WATCH 等命令来实现事务功能。事务提供一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制。&lt;/p&gt;
&lt;p&gt;以下是一个事务的执行过程，该事务首先以一个 MULTI 命令为开始，接着将多个命令放入事务中，最后由 EXEC </summary>
      
    
    
    
    <category term="Redis" scheme="https://tang7o.cn/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://tang7o.cn/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>深入理解 Redis 复制</title>
    <link href="https://tang7o.cn/2021/11/05/%E6%9B%B4%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis%E5%A4%8D%E5%88%B6/"/>
    <id>https://tang7o.cn/2021/11/05/%E6%9B%B4%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis%E5%A4%8D%E5%88%B6/</id>
    <published>2021-11-05T01:16:24.000Z</published>
    <updated>2022-04-13T13:31:49.009Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为什么主从复制使用-RDB-而不使用-AOF？"><a href="#为什么主从复制使用-RDB-而不使用-AOF？" class="headerlink" title="为什么主从复制使用 RDB 而不使用 AOF？"></a>为什么主从复制使用 RDB 而不使用 AOF？</h3><p>1、RDB 文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。而 AOF 文件记录的是每一次写操作的命令，写操作越多文件会变的很大，其中还包括很多对同一个 key 的冗余操作。在主从全数据同步时，传输 RDB 文件可以尽量降低对主库机器网络宽带的消耗，从库在加载 RDB 文件时，一是文件小，读取整个文件的速度会很快，二是因为 RDB 文件存储的都是二进制数据，从库直接按照 RDB 协议解析还原数据即可，速度会非常快，而 AOF 需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度比 RDB 会慢很多，所以使用 RDB 进行主从复制。</p><p>2、假设要使用 AOF 做全量复制，意味着必须打开 AOF 功能，打开 AOF 就要选择文件刷盘的策略，选择不当会严重影响 Redis 性能，而 RDB 只有在需要定时备份和主从全量复制数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启 AOF 的。</p><h3 id="当主服务器不进行持久化时复制的安全性"><a href="#当主服务器不进行持久化时复制的安全性" class="headerlink" title="当主服务器不进行持久化时复制的安全性"></a>当主服务器不进行持久化时复制的安全性</h3><blockquote><p>在进行主从复制设置时，强烈建议在主服务器上开启持久化，当不能这么做时，比如考虑到延迟的问题，应该将实例配置为避免自动重启。</p></blockquote><p><strong>为什么不持久化的主服务器自动重启非常危险呢</strong>？为了更好的理解这个问题，看下面这个失败的例子，其中主服务器和从服务器中数据库都被删除了。</p><ul><li>我们设置节点 A 为主服务器，关闭持久化，节点 B 和 C 从节点 A 复制数据。</li><li>这是出现了一个崩溃，但 Redis 具有自动重启系统，重启了进程，因为关闭了持久化，节点重启后只有一个空的数据集。</li><li>节点 B 和 C 从节点 A 进行复制，现在节点 A 是空的，所以节点 B 和 C 上的复制数据也会被删除。</li><li>当在高可用系统中使用 Redis Sentinel，关闭主服务器的持久化，并且运行自动重启后，这种情况是很危险的。比如主服务器可能在很短的时间就完成了重启，以至于 Sentinel 都无法检测到这次失败，那么上面说的这种失败的情况就发生了。</li></ul><p>如果数据比较重要，并且在使用主从复制时关闭了主服务器持久化功能的场景中，都应该禁止实例自动重启。</p><h3 id="为什么还会有从库的从库的设计？"><a href="#为什么还会有从库的从库的设计？" class="headerlink" title="为什么还会有从库的从库的设计？"></a>为什么还会有从库的从库的设计？</h3><p>通过分析主从库间的第一次数据同步的过程，你可以看到，一次全量复制中，对于主库来说，需要完成两个耗时的操作：<strong>生成 RDB 文件和传输 RDB 文件。</strong></p><p>如果从库数量过多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量复制。fork 这个操作会阻塞主进程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络宽带，同样会给主库的资源使用带来压力。那么，有没有好的解决方法可用分担主库压力呢？</p><p>其实是有的，这就是“主-从-从”模式。</p><p>在刚才的介绍的主从库模式中，所有的从库都是和主库连接，所有的全量复制也都是和主库进行的。现在，我们可用通过“主-从-从”模式<strong>将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。</strong></p><p>简单来说，我们在部署主从集群的时候，可用手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他非从库。然后，我们可用再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，使它们和刚才所选的从库，建立起主从关系。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">replicaof 所选从库的IP 6379</span><br></pre></td></tr></table></figure><p>这样一来，从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行了，这样可用减轻主库上的压力，如下图所示：</p><p><img src="/home/zzt/blog/source/_posts/更深入理解Redis复制/1.jpg" class="lazyload" data-srcset="/home/zzt/blog/source/_posts/更深入理解Redis复制/1.jpg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt=""></p><p>级联的“主-从-从”模式好了，到这里，我们了解了主从库间通过全量复制实现数据同步的过程，以及通过“主-从-从”模式分担主库压力的方式。那么，一旦主库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可用避免频繁建立连接的开销。</p><h3 id="读写分离及其中的问题"><a href="#读写分离及其中的问题" class="headerlink" title="读写分离及其中的问题"></a>读写分离及其中的问题</h3><p>在主从复制基础上实现的读写分离，可用实现 Redis 的读负载均衡：由主节点提高写服务，由一个或多个从节点提供读服务（多个从节点既可以提高数据冗余程度，也可以最大化读负载能力）；在读负载较大的应用场景下，可用大大提高 Redis 服务器的并发量。下面介绍在使用 Redis 读写分离时，需要注意的问题。</p><ul><li><strong>延迟与不一致问题</strong></li></ul><p>前面已经讲到，由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过 offset）判断，如果节点延迟过大，通知应用不再通过该节点读取数据；使用集群同步扩展写负载和读复制等。</p><ul><li><strong>数据过期问题</strong></li></ul><p>在单机 Redis 中，存在两种删除策略：</p><ul><li><code>惰性删除</code>：服务器不会主动删除数据，只有当客户查询某个数据时，服务器判断该数据是否过期，如果过期则删除。</li><li><code>定期删除</code>：服务器执行定时任务删除过期数据，但是考虑到内存和 CPU 的折中（删除会释放内存，但是频繁的删除操作对 CPU 不友好），该删除的频率和执行时间都受到了限制。</li></ul><p>在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过 Redis 从节点读取数据时，很容易读到已经过期的数据。</p><p>Redis 3.2 中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已经过期，则不返回给客户端；</p><ul><li><strong>故障切换问题</strong></li></ul><p>在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的 Redis 节点；当主节点或从节点出现问题而发生变更时；需要及时修改应用程序读写 Redis 数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。</p><ul><li><strong>总结</strong></li></ul><p>在使用读写分离之前，可用考虑其他方法增加 Redis 的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用 Redis 集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主节点的故障切换尽可能自动化，并减少对应用程序的侵入。</p>]]></content>
    
    
    <summary type="html">通过几个问题更加深入的理解Redis的主从复制。</summary>
    
    
    
    <category term="Redis" scheme="https://tang7o.cn/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://tang7o.cn/tags/Redis/"/>
    
  </entry>
  
</feed>
